{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício: Modelo de linguagem (Bengio 2003) - MLP + Embeddings"
      ],
      "metadata": {
        "id": "cJ4M0Jbi7MVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parâmetros"
      ],
      "metadata": {
        "id": "xRm4Ls8Z1sMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Livros (testando com dom casmurro, memórias póstumas e quincas borda, pra dar pelo menos 20.000 palavras)\n",
        "#urls = [\"https://www.gutenberg.org/cache/epub/55752/pg55752.txt\", \"https://www.gutenberg.org/cache/epub/54829/pg54829.txt\", \"https://www.gutenberg.org/cache/epub/55682/pg55682.txt\"]\n",
        "\n",
        "# Livros (O Guarani)\n",
        "urls = [\"https://www.gutenberg.org/ebooks/67724.txt.utf-8\", \"https://www.gutenberg.org/ebooks/67725.txt.utf-8\"]\n",
        "\n",
        "# Dados do vocabulário\n",
        "UNK = \"<unk>\"\n",
        "vocab_size_desejado_sem_UNK = 3000 # Não considera o UNK\n",
        "vocab_size = vocab_size_desejado_sem_UNK + 1\n",
        "\n",
        "# Dados de treinamento\n",
        "context_size = 9 # número de palavras de entrada. O target é a próxima palavra\n",
        "num_epochs = 50 # usado pra fazer overfit no modelo e ajudar na verificação do treinamento\n",
        "test_size = 0.2\n",
        "seed = 18\n",
        "batch_size=128\n",
        "m = 64 # tamanho dos embeddings\n",
        "h = 200 # tamanho da camada oculta\n",
        "lr = 0.06\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "-jgzz8Ds1wAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamentos dos dados\n",
        "\n",
        "## Download e agrupamento em parágrafos"
      ],
      "metadata": {
        "id": "7q5P64Abv23C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYDt0_9svZye",
        "outputId": "f7986455-6172-47f2-d695-231865929524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- Livro 1 ---------------\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK O GUARANY: ROMANCE BRAZILEIRO, VOL. 1 (OF 2) ***\n",
            "J. DE ALENCAR\n",
            "ROMANCE BRAZILEIRO\n",
            "QUINTA EDIÇÃO\n",
            "TOMO PRIMEIRO\n",
            "RIO DE JANEIRO\n",
            "B.-L. GARNIER, LIVREIRO-EDITOR\n",
            "71, RUA DO OUVIDOR, 71\n",
            "PARIS.--E. MELLIER, 17, RUA SÉGUIER.\n",
            "Ficão reservados os direitos de propriedade.\n",
            "Publicando este livro em 1857, se disse ser aquella primeira edição uma prova typographica, que algum dia talvez o autor se dispuzesse a rever.\n",
            "Esta nova edição devia dar satisfação do empenho, que a extrema benevolencia do publico ledor, tão minguado ainda, mudou em bem para divida de reconhecimento.\n",
            "Mais do que podia fiou de si o autor. Relendo a obra depois de annos, achou elle tão mau e incorrecto quando escrevera, que para bem corrigir, fora mister escrever de novo. Para tanto lhe carece o tempo e sobra o tedio de um labor ingrato.\n",
            "Cingio-se pois ás pequenas emendas que toleravão o plano da obra e o desalinho de um estylo não castigado.\n",
            "INDICE PRIMEIRA PARTE OS AVENTUREIROS I.--Scenario.........................................   5 II.--Lealdade........................................  13 III.--A bandeira.....................................  23 IV.--A Luta..........................................  35 V.--Loura e morena...................................  45 VI.--A Volta.........................................  57 VII.--A prece........................................  63 VIII.--Tres linhas...................................  81 IX.--Amor............................................  91 X.--Ao alvorecer..................................... 101 XI.--No banho........................................ 111 XII.--A onça......................................... 121 XIII.--Revelação..................................... 133 XIV.--A india........................................ 145 XV.--Os tres......................................... 157 SEGUNDA PARTE PERY I.--O Carmelita...................................... 175 II.--Yara!........................................... 191 III.--Genio do mal................................... 205 IV.--Cecy............................................ 217 V.--Vilania.......................................... 231 VI.--Nobreza......................................... 243 VII.--No precipicio.................................. 257 VIII.--O bracelete................................... 269 IX.--Testamento...................................... 281 X.--Despedida........................................ 293 XI.--Travessura...................................... 305 XII.--As mensagens de Pery........................... 317 XIII.--Trama......................................... 329 XIV.--A chacara...................................... 341 Notas................................................ 353\n",
            "PRIMEIRA PARTE\n",
            "OS AVENTUREIROS\n",
            "De um dos cabeços da _Serra dos Órgãos_ deslisa um fio d'agua que se dirige para norte, e engrossado com os mananciaes, que recebe no seu curso de dez leguas, torna-se rio caudal.\n",
            "É o _Paquequer_: soltando de cascata em cascata, enroscando-se como uma serpente, vai depois se espreguiçar na varzea e embeber no Parahyba, que rola magestosamente em seu vasto leito.\n",
            "Dir-se-hia que vassallo e tributario desse rei das aguas, o pequeno rio, altivo e sobranceiro contra os rochedos, curva-se humildemente aos pés do suzerano. Perde então a belleza selvatica; suas ondas são calmas e serenas como as de um lago, e não se revoltão contra os barcos e as canôas que resvalão sobre ellas: escravo submisso, soffre o latego do senhor.\n",
            "-------------- Livro 2 ---------------\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK O GUARANY: ROMANCE BRAZILEIRO, VOL. 2 (OF 2) ***\n",
            "J. DE ALENCAR\n",
            "ROMANCE BRAZILEIRO\n",
            "QUINTA EDIÇÃO\n",
            "TOMO SEGUNDO\n",
            "RIO DE JANEIRO\n",
            "B.-L. GARNIER, LIVREIRO-EDITOR\n",
            "71, RUA DO OUVIDOR, 71\n",
            "PARIS.--E. MELLIER, 17, RUA SÉGUIER.\n",
            "Ficão reservados os direitos de propriedade.\n",
            "INDICE TERCEIRA PARTE OS AYMORÉS I.--A Partida........................................   3 II.--Preparativos....................................  15 III.--Verme e flôr...................................  27 IV.--Na treva........................................  39 V.--Deos dispõe......................................  51 VI.--Revolta.........................................  65 VII.--Os selvagens...................................  77 VIII.--Desanimo......................................  89 IX.--Esperança.......................................  99 X.--Na brecha........................................ 111 XI.--O frade......................................... 121 XII.--Desobediencia.................................. 131 XIII.--Combate....................................... 141 XIV.--O prisioneiro.................................. 151 QUARTA PARTE A CATASTROPHE I.--Arrependimento................................... 163 II.--O sacrificio.................................... 173 III.--Sortida........................................ 185 IV.--Revelação....................................... 197 V.--O paiol.......................................... 207 VI.--Tregoa.......................................... 217 VII.--Peleja......................................... 227 VIII.--Noiva......................................... 238 IX.--O castigo....................................... 247 X.--Christão......................................... 257 XI.--Epilogo......................................... 269 Notas................................................ 327\n",
            "TERCEIRA PARTE\n",
            "Na segunda-feira, erão seis horas da manhã, quando D. Antonio de Mariz chamou seu filho.\n",
            "O velho fidalgo velara uma boa parte da noite; ou escrevendo ou reflectindo sobre os perigos que ameaçavão sua familia.\n",
            "Pery lhe havia contado todas as particularidades de seu encontro com os Aymorés; e o cavalheiro, que conhecia a ferocidade e espirito vingativo dessa raça selvagem, esperava a cada momento ser atacado.\n",
            "Por isso, de acordo com Alvaro, D. Diogo, com seu escudeiro Ayres Gomes, tinha tomado todas as medidas de precaução que as circumstancias e sua longa experiencia lhe aconselhavão.\n",
            "Quando seu filho entrou, o velho fidalgo acabava de sellar duas cartas que escrevêra na vespera.\n",
            "--Meu filho, disse elle com uma ligeira emoção, reflecti essa noite sobre o que nos pode acontecer, e assentei que deves partir hoje mesmo para S. Sebastião.\n",
            "--Não é possivel, senhor!... Afastais-me de vós justamente quando correis um perigo?\n",
            "--Sim! É justamente quando um grande perigo nos ameaça, que eu, chefe da casa, entendo ser do meu dever salvar o representante do meu nome e meu herdeiro legitimo, o protector de minha familia orphã.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def carregar_paragrafos_livro(url, n_linhas_para_print=20):\n",
        "  # Baixar o arquivo de texto\n",
        "  response = requests.get(url)\n",
        "  texto = response.text\n",
        "\n",
        "  # Encontrar o início e o fim do conteúdo principal do livro\n",
        "  inicio = texto.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")\n",
        "  fim = texto.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
        "\n",
        "  # Extrair o conteúdo principal do livro\n",
        "  conteudo = texto[inicio:fim].replace('\\r','')\n",
        "\n",
        "  # Dividir o conteúdo em parágrafos e processar o conteúdo\n",
        "  paragrafos = []\n",
        "\n",
        "  # Cada parágrafo é separado por dois \\n\n",
        "  # Dentro de cada parágrafo, junta as linhas (remove) e faz um trim\n",
        "  # Apenas considera os parágrafos que tem pelo menos 10 caracteres\n",
        "  for paragrafo in conteudo.split(\"\\n\\n\"):\n",
        "    paragrafo = paragrafo.replace('\\n', ' ').strip()\n",
        "    if len(paragrafo) > 10:\n",
        "      paragrafos.append(paragrafo)\n",
        "\n",
        "  for p in paragrafos[0:n_linhas_para_print]:\n",
        "    print(p)\n",
        "\n",
        "  return paragrafos\n",
        "\n",
        "paragrafos = []\n",
        "for i, url in enumerate(urls, 1):\n",
        "  print(f'-------------- Livro {i} ---------------')\n",
        "  paragrafos.extend(carregar_paragrafos_livro(url))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizador\n",
        "\n",
        "Define um tokenizador simples. A ideia desse tokenizador é manter as palavras e os sinais de pontuação. Quero testar gerar tokens também para os sinais de pontuação.\n",
        "\n",
        "*Gerado com ChatGPT.*"
      ],
      "metadata": {
        "id": "Pa9xkSle06bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenizar(texto):\n",
        "  texto = texto.lower()\n",
        "\n",
        "  # Define a expressão regular que captura palavras e sinais de pontuação\n",
        "  padrao = r'\\w+|[^\\w\\s]'\n",
        "\n",
        "  # Usa o método findall para encontrar todas as ocorrências que se encaixam no padrão\n",
        "  tokens = re.findall(padrao, texto)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "print(tokenizar('Teste. Será que vai manter a pontuação?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyRd2ylAyO89",
        "outputId": "2ceb3672-b45c-4d2a-caab-0b58690cf70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['teste', '.', 'será', 'que', 'vai', 'manter', 'a', 'pontuação', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração do vocabulário\n",
        "\n",
        "Agora vamos gerar o vocabulário."
      ],
      "metadata": {
        "id": "py_qYd1b18mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from collections import Counter\n",
        "counter = Counter()\n",
        "\n",
        "def gerar_vocabulario(paragrafos, vocab_size_sem_UNK):\n",
        "  for p in paragrafos:\n",
        "    # Update com os tokens de cada parágrafo\n",
        "    counter.update(tokenizar(p))\n",
        "\n",
        "  # Considera apenas as palavras mais frequentes. Adiciona, na posição 0, o token UNK\n",
        "  most_frequent_words = [UNK] + sorted(counter, key=counter.get, reverse=True)[:vocab_size_sem_UNK]\n",
        "  # vocab é um mapa de palavras para o índice correspondente. O mapa leva a palavra para um índice entre [0, vocab_size]\n",
        "  # (o tamanho é vocab_size + 1), com o índice 0 apontando para UNK\n",
        "  vocab = {word: i for i, word in enumerate(most_frequent_words)}\n",
        "\n",
        "  return len(most_frequent_words), vocab, most_frequent_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYMsMQV919LN",
        "outputId": "f17a91a9-5cfd-475e-8f12-a54f7de9015c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11 µs, sys: 3 µs, total: 14 µs\n",
            "Wall time: 16.5 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, vocab, most_frequent_words = gerar_vocabulario(paragrafos, vocab_size_desejado_sem_UNK)\n",
        "\n",
        "print('Tamanho do vocabulário (considera UNK): ', vocab_size)\n",
        "\n",
        "print('Posição 0: ', most_frequent_words[0])\n",
        "print('Índice do UNK: ', vocab[UNK])\n",
        "print('------------')\n",
        "print('Posição 200: ', most_frequent_words[200])\n",
        "print(f'Índice de {most_frequent_words[200]}: ', vocab[most_frequent_words[200]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmwhcpZF4hqH",
        "outputId": "c7fe1042-62cc-410c-9802-595147aca0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do vocabulário (considera UNK):  3001\n",
            "Posição 0:  <unk>\n",
            "Índice do UNK:  0\n",
            "------------\n",
            "Posição 200:  janella\n",
            "Índice de janella:  200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder de frases"
      ],
      "metadata": {
        "id": "RoLvU4XC9IZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sentence, vocab):\n",
        "  # Obs.: tem que usar o mesmo tokenizador que foi gerado o vocabulário\n",
        "  return [vocab.get(word, 0) for word in tokenizar(sentence)]"
      ],
      "metadata": {
        "id": "0JCO2quC6Wtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sentence(sentence, most_frequent_words):\n",
        "  words = [most_frequent_words[code] for code in sentence]\n",
        "  return ' '.join(words)"
      ],
      "metadata": {
        "id": "OBNbtpkF97sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do encode/decode\n",
        "frase = \"E ele pegou a árvore e arrancou do chão.\"\n",
        "\n",
        "frase_encodada = encode_sentence(frase, vocab)\n",
        "frase_reconstruida = decode_sentence(frase_encodada, most_frequent_words)\n",
        "\n",
        "print('Original:')\n",
        "print(frase)\n",
        "print('Encodada:')\n",
        "print(frase_encodada)\n",
        "print('Reconstruída:')\n",
        "print(frase_reconstruida)\n",
        "print(\"--------------------------------------\")\n",
        "\n",
        "frase = \"E no seminario me disseram que não.\"\n",
        "\n",
        "frase_encodada = encode_sentence(frase, vocab)\n",
        "frase_reconstruida = decode_sentence(frase_encodada, most_frequent_words)\n",
        "\n",
        "print('Original:')\n",
        "print(frase)\n",
        "print('Encodada:')\n",
        "print(frase_encodada)\n",
        "print('Reconstruída:')\n",
        "print(frase_reconstruida)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-qN55c5-i8Z",
        "outputId": "c970cdf2-bdd0-429e-f877-2bbbaa70a342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "E ele pegou a árvore e arrancou do chão.\n",
            "Encodada:\n",
            "[8, 0, 0, 4, 0, 8, 1651, 12, 378, 1]\n",
            "Reconstruída:\n",
            "e <unk> <unk> a <unk> e arrancou do chão .\n",
            "--------------------------------------\n",
            "Original:\n",
            "E no seminario me disseram que não.\n",
            "Encodada:\n",
            "[8, 25, 0, 44, 0, 5, 13, 1]\n",
            "Reconstruída:\n",
            "e no <unk> me <unk> que não .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "NYphluu6AOnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada parágrafo, é necessário gerar os dados de treinamento. Supondo que a frase é \"eu gosto de pizza.\" e vamos usar uma janela de contexto igual a 2, a ideia é que essa frase gere o seguinte conjunto de treinamento:\n",
        "\n",
        "input -> target\n",
        "\n",
        "[UNK, \"eu\"] -> \"gosto\" (ESSE CASO NÃO SERÁ CONSIDERADO POR ENQUANTO)\n",
        "\n",
        "[\"eu\", \"gosto\"] -> \"de\"\n",
        "\n",
        "[\"gosto\", \"de\"] -> \"pizza\"\n",
        "\n",
        "[\"de\", \"pizza\"] -> \".\""
      ],
      "metadata": {
        "id": "FYjJsO8BByxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gera_inputs_e_targets_para_array(array, n):\n",
        "  # Faz uma janela deslizante de tamanho n no array\n",
        "\n",
        "  janelas = []\n",
        "  targets = []\n",
        "\n",
        "  for i in range(len(array) - n):\n",
        "    janela = array[i:i+n]\n",
        "    janelas.append(janela)\n",
        "    targets.append(array[i+n])\n",
        "\n",
        "  return janelas, targets\n",
        "\n",
        "# Exemplo de uso\n",
        "exemplo = \"eu gosto de pizza .\".split()\n",
        "\n",
        "for n in range(1, 4):\n",
        "  print(f'Testando para janela de tamanho {n}')\n",
        "  inputs, targets = gera_inputs_e_targets_para_array(exemplo, n)\n",
        "\n",
        "  # Testa\n",
        "  for input_target in zip(inputs, targets):\n",
        "    print(f'{input_target[0]} -> {input_target[1]}')\n",
        "  print('------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUUUqSSaCeIO",
        "outputId": "115b4fd0-e846-48ce-a8f3-580240c4c7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando para janela de tamanho 1\n",
            "['eu'] -> gosto\n",
            "['gosto'] -> de\n",
            "['de'] -> pizza\n",
            "['pizza'] -> .\n",
            "------------------------------\n",
            "Testando para janela de tamanho 2\n",
            "['eu', 'gosto'] -> de\n",
            "['gosto', 'de'] -> pizza\n",
            "['de', 'pizza'] -> .\n",
            "------------------------------\n",
            "Testando para janela de tamanho 3\n",
            "['eu', 'gosto', 'de'] -> pizza\n",
            "['gosto', 'de', 'pizza'] -> .\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa com um parágrafo real e o tamanho do contexto configurado\n",
        "i = 60\n",
        "inputs, targets = gera_inputs_e_targets_para_array(tokenizar(paragrafos[i]), context_size)\n",
        "print(paragrafos[i])\n",
        "for input_target in zip(inputs, targets):\n",
        "  print(f'{input_target[0]} -> {input_target[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlO4K7-WFShp",
        "outputId": "d325d6c2-8ef8-45b2-fad1-fe96fec6a11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depois, vendo que esta expedição não se realisava, e que seu braço e sua coragem de nada valião ao rei de Portugal, jurou que ao menos lhe guardaria fidelidade até a morte. Tomou os seus penates, o seu brasão, as suas armas, a sua familia, e foi estabelecer-se naquella sesmaria que lhe concedera Mem de Sá. Ahi, de pé sobre a eminencia em que ia assentar o seu novo solar, D. Antonio de Mariz erguendo o vulto direito, e lançando um olhar sobranceiro pelos vastos horizontes que abrião em torno, exclamou:\n",
            "['depois', ',', 'vendo', 'que', 'esta', 'expedição', 'não', 'se', 'realisava'] -> ,\n",
            "[',', 'vendo', 'que', 'esta', 'expedição', 'não', 'se', 'realisava', ','] -> e\n",
            "['vendo', 'que', 'esta', 'expedição', 'não', 'se', 'realisava', ',', 'e'] -> que\n",
            "['que', 'esta', 'expedição', 'não', 'se', 'realisava', ',', 'e', 'que'] -> seu\n",
            "['esta', 'expedição', 'não', 'se', 'realisava', ',', 'e', 'que', 'seu'] -> braço\n",
            "['expedição', 'não', 'se', 'realisava', ',', 'e', 'que', 'seu', 'braço'] -> e\n",
            "['não', 'se', 'realisava', ',', 'e', 'que', 'seu', 'braço', 'e'] -> sua\n",
            "['se', 'realisava', ',', 'e', 'que', 'seu', 'braço', 'e', 'sua'] -> coragem\n",
            "['realisava', ',', 'e', 'que', 'seu', 'braço', 'e', 'sua', 'coragem'] -> de\n",
            "[',', 'e', 'que', 'seu', 'braço', 'e', 'sua', 'coragem', 'de'] -> nada\n",
            "['e', 'que', 'seu', 'braço', 'e', 'sua', 'coragem', 'de', 'nada'] -> valião\n",
            "['que', 'seu', 'braço', 'e', 'sua', 'coragem', 'de', 'nada', 'valião'] -> ao\n",
            "['seu', 'braço', 'e', 'sua', 'coragem', 'de', 'nada', 'valião', 'ao'] -> rei\n",
            "['braço', 'e', 'sua', 'coragem', 'de', 'nada', 'valião', 'ao', 'rei'] -> de\n",
            "['e', 'sua', 'coragem', 'de', 'nada', 'valião', 'ao', 'rei', 'de'] -> portugal\n",
            "['sua', 'coragem', 'de', 'nada', 'valião', 'ao', 'rei', 'de', 'portugal'] -> ,\n",
            "['coragem', 'de', 'nada', 'valião', 'ao', 'rei', 'de', 'portugal', ','] -> jurou\n",
            "['de', 'nada', 'valião', 'ao', 'rei', 'de', 'portugal', ',', 'jurou'] -> que\n",
            "['nada', 'valião', 'ao', 'rei', 'de', 'portugal', ',', 'jurou', 'que'] -> ao\n",
            "['valião', 'ao', 'rei', 'de', 'portugal', ',', 'jurou', 'que', 'ao'] -> menos\n",
            "['ao', 'rei', 'de', 'portugal', ',', 'jurou', 'que', 'ao', 'menos'] -> lhe\n",
            "['rei', 'de', 'portugal', ',', 'jurou', 'que', 'ao', 'menos', 'lhe'] -> guardaria\n",
            "['de', 'portugal', ',', 'jurou', 'que', 'ao', 'menos', 'lhe', 'guardaria'] -> fidelidade\n",
            "['portugal', ',', 'jurou', 'que', 'ao', 'menos', 'lhe', 'guardaria', 'fidelidade'] -> até\n",
            "[',', 'jurou', 'que', 'ao', 'menos', 'lhe', 'guardaria', 'fidelidade', 'até'] -> a\n",
            "['jurou', 'que', 'ao', 'menos', 'lhe', 'guardaria', 'fidelidade', 'até', 'a'] -> morte\n",
            "['que', 'ao', 'menos', 'lhe', 'guardaria', 'fidelidade', 'até', 'a', 'morte'] -> .\n",
            "['ao', 'menos', 'lhe', 'guardaria', 'fidelidade', 'até', 'a', 'morte', '.'] -> tomou\n",
            "['menos', 'lhe', 'guardaria', 'fidelidade', 'até', 'a', 'morte', '.', 'tomou'] -> os\n",
            "['lhe', 'guardaria', 'fidelidade', 'até', 'a', 'morte', '.', 'tomou', 'os'] -> seus\n",
            "['guardaria', 'fidelidade', 'até', 'a', 'morte', '.', 'tomou', 'os', 'seus'] -> penates\n",
            "['fidelidade', 'até', 'a', 'morte', '.', 'tomou', 'os', 'seus', 'penates'] -> ,\n",
            "['até', 'a', 'morte', '.', 'tomou', 'os', 'seus', 'penates', ','] -> o\n",
            "['a', 'morte', '.', 'tomou', 'os', 'seus', 'penates', ',', 'o'] -> seu\n",
            "['morte', '.', 'tomou', 'os', 'seus', 'penates', ',', 'o', 'seu'] -> brasão\n",
            "['.', 'tomou', 'os', 'seus', 'penates', ',', 'o', 'seu', 'brasão'] -> ,\n",
            "['tomou', 'os', 'seus', 'penates', ',', 'o', 'seu', 'brasão', ','] -> as\n",
            "['os', 'seus', 'penates', ',', 'o', 'seu', 'brasão', ',', 'as'] -> suas\n",
            "['seus', 'penates', ',', 'o', 'seu', 'brasão', ',', 'as', 'suas'] -> armas\n",
            "['penates', ',', 'o', 'seu', 'brasão', ',', 'as', 'suas', 'armas'] -> ,\n",
            "[',', 'o', 'seu', 'brasão', ',', 'as', 'suas', 'armas', ','] -> a\n",
            "['o', 'seu', 'brasão', ',', 'as', 'suas', 'armas', ',', 'a'] -> sua\n",
            "['seu', 'brasão', ',', 'as', 'suas', 'armas', ',', 'a', 'sua'] -> familia\n",
            "['brasão', ',', 'as', 'suas', 'armas', ',', 'a', 'sua', 'familia'] -> ,\n",
            "[',', 'as', 'suas', 'armas', ',', 'a', 'sua', 'familia', ','] -> e\n",
            "['as', 'suas', 'armas', ',', 'a', 'sua', 'familia', ',', 'e'] -> foi\n",
            "['suas', 'armas', ',', 'a', 'sua', 'familia', ',', 'e', 'foi'] -> estabelecer\n",
            "['armas', ',', 'a', 'sua', 'familia', ',', 'e', 'foi', 'estabelecer'] -> -\n",
            "[',', 'a', 'sua', 'familia', ',', 'e', 'foi', 'estabelecer', '-'] -> se\n",
            "['a', 'sua', 'familia', ',', 'e', 'foi', 'estabelecer', '-', 'se'] -> naquella\n",
            "['sua', 'familia', ',', 'e', 'foi', 'estabelecer', '-', 'se', 'naquella'] -> sesmaria\n",
            "['familia', ',', 'e', 'foi', 'estabelecer', '-', 'se', 'naquella', 'sesmaria'] -> que\n",
            "[',', 'e', 'foi', 'estabelecer', '-', 'se', 'naquella', 'sesmaria', 'que'] -> lhe\n",
            "['e', 'foi', 'estabelecer', '-', 'se', 'naquella', 'sesmaria', 'que', 'lhe'] -> concedera\n",
            "['foi', 'estabelecer', '-', 'se', 'naquella', 'sesmaria', 'que', 'lhe', 'concedera'] -> mem\n",
            "['estabelecer', '-', 'se', 'naquella', 'sesmaria', 'que', 'lhe', 'concedera', 'mem'] -> de\n",
            "['-', 'se', 'naquella', 'sesmaria', 'que', 'lhe', 'concedera', 'mem', 'de'] -> sá\n",
            "['se', 'naquella', 'sesmaria', 'que', 'lhe', 'concedera', 'mem', 'de', 'sá'] -> .\n",
            "['naquella', 'sesmaria', 'que', 'lhe', 'concedera', 'mem', 'de', 'sá', '.'] -> ahi\n",
            "['sesmaria', 'que', 'lhe', 'concedera', 'mem', 'de', 'sá', '.', 'ahi'] -> ,\n",
            "['que', 'lhe', 'concedera', 'mem', 'de', 'sá', '.', 'ahi', ','] -> de\n",
            "['lhe', 'concedera', 'mem', 'de', 'sá', '.', 'ahi', ',', 'de'] -> pé\n",
            "['concedera', 'mem', 'de', 'sá', '.', 'ahi', ',', 'de', 'pé'] -> sobre\n",
            "['mem', 'de', 'sá', '.', 'ahi', ',', 'de', 'pé', 'sobre'] -> a\n",
            "['de', 'sá', '.', 'ahi', ',', 'de', 'pé', 'sobre', 'a'] -> eminencia\n",
            "['sá', '.', 'ahi', ',', 'de', 'pé', 'sobre', 'a', 'eminencia'] -> em\n",
            "['.', 'ahi', ',', 'de', 'pé', 'sobre', 'a', 'eminencia', 'em'] -> que\n",
            "['ahi', ',', 'de', 'pé', 'sobre', 'a', 'eminencia', 'em', 'que'] -> ia\n",
            "[',', 'de', 'pé', 'sobre', 'a', 'eminencia', 'em', 'que', 'ia'] -> assentar\n",
            "['de', 'pé', 'sobre', 'a', 'eminencia', 'em', 'que', 'ia', 'assentar'] -> o\n",
            "['pé', 'sobre', 'a', 'eminencia', 'em', 'que', 'ia', 'assentar', 'o'] -> seu\n",
            "['sobre', 'a', 'eminencia', 'em', 'que', 'ia', 'assentar', 'o', 'seu'] -> novo\n",
            "['a', 'eminencia', 'em', 'que', 'ia', 'assentar', 'o', 'seu', 'novo'] -> solar\n",
            "['eminencia', 'em', 'que', 'ia', 'assentar', 'o', 'seu', 'novo', 'solar'] -> ,\n",
            "['em', 'que', 'ia', 'assentar', 'o', 'seu', 'novo', 'solar', ','] -> d\n",
            "['que', 'ia', 'assentar', 'o', 'seu', 'novo', 'solar', ',', 'd'] -> .\n",
            "['ia', 'assentar', 'o', 'seu', 'novo', 'solar', ',', 'd', '.'] -> antonio\n",
            "['assentar', 'o', 'seu', 'novo', 'solar', ',', 'd', '.', 'antonio'] -> de\n",
            "['o', 'seu', 'novo', 'solar', ',', 'd', '.', 'antonio', 'de'] -> mariz\n",
            "['seu', 'novo', 'solar', ',', 'd', '.', 'antonio', 'de', 'mariz'] -> erguendo\n",
            "['novo', 'solar', ',', 'd', '.', 'antonio', 'de', 'mariz', 'erguendo'] -> o\n",
            "['solar', ',', 'd', '.', 'antonio', 'de', 'mariz', 'erguendo', 'o'] -> vulto\n",
            "[',', 'd', '.', 'antonio', 'de', 'mariz', 'erguendo', 'o', 'vulto'] -> direito\n",
            "['d', '.', 'antonio', 'de', 'mariz', 'erguendo', 'o', 'vulto', 'direito'] -> ,\n",
            "['.', 'antonio', 'de', 'mariz', 'erguendo', 'o', 'vulto', 'direito', ','] -> e\n",
            "['antonio', 'de', 'mariz', 'erguendo', 'o', 'vulto', 'direito', ',', 'e'] -> lançando\n",
            "['de', 'mariz', 'erguendo', 'o', 'vulto', 'direito', ',', 'e', 'lançando'] -> um\n",
            "['mariz', 'erguendo', 'o', 'vulto', 'direito', ',', 'e', 'lançando', 'um'] -> olhar\n",
            "['erguendo', 'o', 'vulto', 'direito', ',', 'e', 'lançando', 'um', 'olhar'] -> sobranceiro\n",
            "['o', 'vulto', 'direito', ',', 'e', 'lançando', 'um', 'olhar', 'sobranceiro'] -> pelos\n",
            "['vulto', 'direito', ',', 'e', 'lançando', 'um', 'olhar', 'sobranceiro', 'pelos'] -> vastos\n",
            "['direito', ',', 'e', 'lançando', 'um', 'olhar', 'sobranceiro', 'pelos', 'vastos'] -> horizontes\n",
            "[',', 'e', 'lançando', 'um', 'olhar', 'sobranceiro', 'pelos', 'vastos', 'horizontes'] -> que\n",
            "['e', 'lançando', 'um', 'olhar', 'sobranceiro', 'pelos', 'vastos', 'horizontes', 'que'] -> abrião\n",
            "['lançando', 'um', 'olhar', 'sobranceiro', 'pelos', 'vastos', 'horizontes', 'que', 'abrião'] -> em\n",
            "['um', 'olhar', 'sobranceiro', 'pelos', 'vastos', 'horizontes', 'que', 'abrião', 'em'] -> torno\n",
            "['olhar', 'sobranceiro', 'pelos', 'vastos', 'horizontes', 'que', 'abrião', 'em', 'torno'] -> ,\n",
            "['sobranceiro', 'pelos', 'vastos', 'horizontes', 'que', 'abrião', 'em', 'torno', ','] -> exclamou\n",
            "['pelos', 'vastos', 'horizontes', 'que', 'abrião', 'em', 'torno', ',', 'exclamou'] -> :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa com um parágrafo real, mas agora ele encodado e o tamanho do contexto configurado\n",
        "inputs, targets = gera_inputs_e_targets_para_array(encode_sentence(paragrafos[i], vocab), context_size)\n",
        "print(paragrafos[i])\n",
        "for input_target in zip(inputs, targets):\n",
        "  print(f'{input_target[0]} -> {input_target[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM9NAFzaGIPf",
        "outputId": "09694b57-46c0-4d96-9907-2494e3ae89c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depois, vendo que esta expedição não se realisava, e que seu braço e sua coragem de nada valião ao rei de Portugal, jurou que ao menos lhe guardaria fidelidade até a morte. Tomou os seus penates, o seu brasão, as suas armas, a sua familia, e foi estabelecer-se naquella sesmaria que lhe concedera Mem de Sá. Ahi, de pé sobre a eminencia em que ia assentar o seu novo solar, D. Antonio de Mariz erguendo o vulto direito, e lançando um olhar sobranceiro pelos vastos horizontes que abrião em torno, exclamou:\n",
            "[61, 2, 275, 5, 119, 999, 13, 9, 0] -> 2\n",
            "[2, 275, 5, 119, 999, 13, 9, 0, 2] -> 8\n",
            "[275, 5, 119, 999, 13, 9, 0, 2, 8] -> 5\n",
            "[5, 119, 999, 13, 9, 0, 2, 8, 5] -> 20\n",
            "[119, 999, 13, 9, 0, 2, 8, 5, 20] -> 204\n",
            "[999, 13, 9, 0, 2, 8, 5, 20, 204] -> 8\n",
            "[13, 9, 0, 2, 8, 5, 20, 204, 8] -> 18\n",
            "[9, 0, 2, 8, 5, 20, 204, 8, 18] -> 362\n",
            "[0, 2, 8, 5, 20, 204, 8, 18, 362] -> 7\n",
            "[2, 8, 5, 20, 204, 8, 18, 362, 7] -> 252\n",
            "[8, 5, 20, 204, 8, 18, 362, 7, 252] -> 0\n",
            "[5, 20, 204, 8, 18, 362, 7, 252, 0] -> 28\n",
            "[20, 204, 8, 18, 362, 7, 252, 0, 28] -> 552\n",
            "[204, 8, 18, 362, 7, 252, 0, 28, 552] -> 7\n",
            "[8, 18, 362, 7, 252, 0, 28, 552, 7] -> 1082\n",
            "[18, 362, 7, 252, 0, 28, 552, 7, 1082] -> 2\n",
            "[362, 7, 252, 0, 28, 552, 7, 1082, 2] -> 0\n",
            "[7, 252, 0, 28, 552, 7, 1082, 2, 0] -> 5\n",
            "[252, 0, 28, 552, 7, 1082, 2, 0, 5] -> 28\n",
            "[0, 28, 552, 7, 1082, 2, 0, 5, 28] -> 236\n",
            "[28, 552, 7, 1082, 2, 0, 5, 28, 236] -> 30\n",
            "[552, 7, 1082, 2, 0, 5, 28, 236, 30] -> 0\n",
            "[7, 1082, 2, 0, 5, 28, 236, 30, 0] -> 1425\n",
            "[1082, 2, 0, 5, 28, 236, 30, 0, 1425] -> 156\n",
            "[2, 0, 5, 28, 236, 30, 0, 1425, 156] -> 4\n",
            "[0, 5, 28, 236, 30, 0, 1425, 156, 4] -> 147\n",
            "[5, 28, 236, 30, 0, 1425, 156, 4, 147] -> 1\n",
            "[28, 236, 30, 0, 1425, 156, 4, 147, 1] -> 296\n",
            "[236, 30, 0, 1425, 156, 4, 147, 1, 296] -> 16\n",
            "[30, 0, 1425, 156, 4, 147, 1, 296, 16] -> 45\n",
            "[0, 1425, 156, 4, 147, 1, 296, 16, 45] -> 0\n",
            "[1425, 156, 4, 147, 1, 296, 16, 45, 0] -> 2\n",
            "[156, 4, 147, 1, 296, 16, 45, 0, 2] -> 6\n",
            "[4, 147, 1, 296, 16, 45, 0, 2, 6] -> 20\n",
            "[147, 1, 296, 16, 45, 0, 2, 6, 20] -> 0\n",
            "[1, 296, 16, 45, 0, 2, 6, 20, 0] -> 2\n",
            "[296, 16, 45, 0, 2, 6, 20, 0, 2] -> 24\n",
            "[16, 45, 0, 2, 6, 20, 0, 2, 24] -> 89\n",
            "[45, 0, 2, 6, 20, 0, 2, 24, 89] -> 264\n",
            "[0, 2, 6, 20, 0, 2, 24, 89, 264] -> 2\n",
            "[2, 6, 20, 0, 2, 24, 89, 264, 2] -> 4\n",
            "[6, 20, 0, 2, 24, 89, 264, 2, 4] -> 18\n",
            "[20, 0, 2, 24, 89, 264, 2, 4, 18] -> 168\n",
            "[0, 2, 24, 89, 264, 2, 4, 18, 168] -> 2\n",
            "[2, 24, 89, 264, 2, 4, 18, 168, 2] -> 8\n",
            "[24, 89, 264, 2, 4, 18, 168, 2, 8] -> 87\n",
            "[89, 264, 2, 4, 18, 168, 2, 8, 87] -> 0\n",
            "[264, 2, 4, 18, 168, 2, 8, 87, 0] -> 3\n",
            "[2, 4, 18, 168, 2, 8, 87, 0, 3] -> 9\n",
            "[4, 18, 168, 2, 8, 87, 0, 3, 9] -> 622\n",
            "[18, 168, 2, 8, 87, 0, 3, 9, 622] -> 0\n",
            "[168, 2, 8, 87, 0, 3, 9, 622, 0] -> 5\n",
            "[2, 8, 87, 0, 3, 9, 622, 0, 5] -> 30\n",
            "[8, 87, 0, 3, 9, 622, 0, 5, 30] -> 0\n",
            "[87, 0, 3, 9, 622, 0, 5, 30, 0] -> 0\n",
            "[0, 3, 9, 622, 0, 5, 30, 0, 0] -> 7\n",
            "[3, 9, 622, 0, 5, 30, 0, 0, 7] -> 998\n",
            "[9, 622, 0, 5, 30, 0, 0, 7, 998] -> 1\n",
            "[622, 0, 5, 30, 0, 0, 7, 998, 1] -> 239\n",
            "[0, 5, 30, 0, 0, 7, 998, 1, 239] -> 2\n",
            "[5, 30, 0, 0, 7, 998, 1, 239, 2] -> 7\n",
            "[30, 0, 0, 7, 998, 1, 239, 2, 7] -> 331\n",
            "[0, 0, 7, 998, 1, 239, 2, 7, 331] -> 39\n",
            "[0, 7, 998, 1, 239, 2, 7, 331, 39] -> 4\n",
            "[7, 998, 1, 239, 2, 7, 331, 39, 4] -> 1793\n",
            "[998, 1, 239, 2, 7, 331, 39, 4, 1793] -> 22\n",
            "[1, 239, 2, 7, 331, 39, 4, 1793, 22] -> 5\n",
            "[239, 2, 7, 331, 39, 4, 1793, 22, 5] -> 90\n",
            "[2, 7, 331, 39, 4, 1793, 22, 5, 90] -> 0\n",
            "[7, 331, 39, 4, 1793, 22, 5, 90, 0] -> 6\n",
            "[331, 39, 4, 1793, 22, 5, 90, 0, 6] -> 20\n",
            "[39, 4, 1793, 22, 5, 90, 0, 6, 20] -> 185\n",
            "[4, 1793, 22, 5, 90, 0, 6, 20, 185] -> 2511\n",
            "[1793, 22, 5, 90, 0, 6, 20, 185, 2511] -> 2\n",
            "[22, 5, 90, 0, 6, 20, 185, 2511, 2] -> 31\n",
            "[5, 90, 0, 6, 20, 185, 2511, 2, 31] -> 1\n",
            "[90, 0, 6, 20, 185, 2511, 2, 31, 1] -> 47\n",
            "[0, 6, 20, 185, 2511, 2, 31, 1, 47] -> 7\n",
            "[6, 20, 185, 2511, 2, 31, 1, 47, 7] -> 70\n",
            "[20, 185, 2511, 2, 31, 1, 47, 7, 70] -> 646\n",
            "[185, 2511, 2, 31, 1, 47, 7, 70, 646] -> 6\n",
            "[2511, 2, 31, 1, 47, 7, 70, 646, 6] -> 697\n",
            "[2, 31, 1, 47, 7, 70, 646, 6, 697] -> 458\n",
            "[31, 1, 47, 7, 70, 646, 6, 697, 458] -> 2\n",
            "[1, 47, 7, 70, 646, 6, 697, 458, 2] -> 8\n",
            "[47, 7, 70, 646, 6, 697, 458, 2, 8] -> 647\n",
            "[7, 70, 646, 6, 697, 458, 2, 8, 647] -> 11\n",
            "[70, 646, 6, 697, 458, 2, 8, 647, 11] -> 91\n",
            "[646, 6, 697, 458, 2, 8, 647, 11, 91] -> 2470\n",
            "[6, 697, 458, 2, 8, 647, 11, 91, 2470] -> 199\n",
            "[697, 458, 2, 8, 647, 11, 91, 2470, 199] -> 0\n",
            "[458, 2, 8, 647, 11, 91, 2470, 199, 0] -> 2082\n",
            "[2, 8, 647, 11, 91, 2470, 199, 0, 2082] -> 5\n",
            "[8, 647, 11, 91, 2470, 199, 0, 2082, 5] -> 1810\n",
            "[647, 11, 91, 2470, 199, 0, 2082, 5, 1810] -> 22\n",
            "[11, 91, 2470, 199, 0, 2082, 5, 1810, 22] -> 446\n",
            "[91, 2470, 199, 0, 2082, 5, 1810, 22, 446] -> 2\n",
            "[2470, 199, 0, 2082, 5, 1810, 22, 446, 2] -> 163\n",
            "[199, 0, 2082, 5, 1810, 22, 446, 2, 163] -> 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ParagrafosDataset(Dataset):\n",
        "  def __init__(self, paragrafos, vocab, context_size):\n",
        "    # Salva o vocabulário\n",
        "    self.vocab = vocab\n",
        "    # Cria os inputs e target\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for p in paragrafos:\n",
        "      # O primeiro passo é pegar cada frase do parágrafo e encodar\n",
        "      p_tokenizado = encode_sentence(p, self.vocab)\n",
        "      # Só faz sentido considerar frases que tem no mínimo (context_size + 1) tokens\n",
        "      if (len(p_tokenizado) <= context_size):\n",
        "        continue\n",
        "\n",
        "      # Agora vamos gerar os dados de treinamento para esse parágrafo\n",
        "      p_inputs, p_targets = gera_inputs_e_targets_para_array(p_tokenizado, context_size)\n",
        "\n",
        "      # Adiciona independentemente se tiver UKN ou não no input ou target\n",
        "      inputs.extend(p_inputs)\n",
        "      targets.extend(p_targets)\n",
        "\n",
        "      # Apenas adiciona se o input ou o target não tiver nenhum UNK (código 0)\n",
        "      #for p_um_input, p_um_target in zip(p_inputs, p_targets):\n",
        "      #  if (0 not in p_um_input and p_um_target != 0):\n",
        "      #    inputs.append(p_um_input)\n",
        "      #    targets.append(p_um_target)\n",
        "\n",
        "    # Mantém em cache\n",
        "    self.inputs = torch.tensor(inputs)\n",
        "    self.targets = torch.tensor(targets)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5gvB84ZAQyX",
        "outputId": "7505e0cd-80ff-4534-b7f9-e6b65b43fec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.45 s, sys: 321 ms, total: 1.77 s\n",
            "Wall time: 3.39 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste_paragrafos = [\"Depois, vendo que esta expedição não se realisava, e que seu braço e sua coragem de nada valião ao rei de Portugal\"]\n",
        "teste_dataset = ParagrafosDataset(teste_paragrafos, vocab, context_size)\n",
        "\n",
        "print('Imprimindo o dataset')\n",
        "for dados in teste_dataset:\n",
        "  print(dados)\n",
        "\n",
        "print('-------------------------')\n",
        "print('Como deveria estar (testando se o dataset está considerando corretamente os parágrafos. Tem que descartar os que tem UNK (0)):')\n",
        "for p in teste_paragrafos:\n",
        "  # Faz o encode do parágrafo\n",
        "  p_encodado = encode_sentence(p, vocab)\n",
        "  inputs, targets = gera_inputs_e_targets_para_array(p_encodado, context_size)\n",
        "  for inputs_targets in zip(inputs, targets):\n",
        "    print(torch.tensor(inputs_targets[0]), torch.tensor(inputs_targets[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScJGPiMVH4xs",
        "outputId": "6c427bc3-11f0-4bb3-bfc5-a7a119640b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imprimindo o dataset\n",
            "(tensor([ 61,   2, 275,   5, 119, 999,  13,   9,   0]), tensor(2))\n",
            "(tensor([  2, 275,   5, 119, 999,  13,   9,   0,   2]), tensor(8))\n",
            "(tensor([275,   5, 119, 999,  13,   9,   0,   2,   8]), tensor(5))\n",
            "(tensor([  5, 119, 999,  13,   9,   0,   2,   8,   5]), tensor(20))\n",
            "(tensor([119, 999,  13,   9,   0,   2,   8,   5,  20]), tensor(204))\n",
            "(tensor([999,  13,   9,   0,   2,   8,   5,  20, 204]), tensor(8))\n",
            "(tensor([ 13,   9,   0,   2,   8,   5,  20, 204,   8]), tensor(18))\n",
            "(tensor([  9,   0,   2,   8,   5,  20, 204,   8,  18]), tensor(362))\n",
            "(tensor([  0,   2,   8,   5,  20, 204,   8,  18, 362]), tensor(7))\n",
            "(tensor([  2,   8,   5,  20, 204,   8,  18, 362,   7]), tensor(252))\n",
            "(tensor([  8,   5,  20, 204,   8,  18, 362,   7, 252]), tensor(0))\n",
            "(tensor([  5,  20, 204,   8,  18, 362,   7, 252,   0]), tensor(28))\n",
            "(tensor([ 20, 204,   8,  18, 362,   7, 252,   0,  28]), tensor(552))\n",
            "(tensor([204,   8,  18, 362,   7, 252,   0,  28, 552]), tensor(7))\n",
            "(tensor([  8,  18, 362,   7, 252,   0,  28, 552,   7]), tensor(1082))\n",
            "-------------------------\n",
            "Como deveria estar (testando se o dataset está considerando corretamente os parágrafos. Tem que descartar os que tem UNK (0)):\n",
            "tensor([ 61,   2, 275,   5, 119, 999,  13,   9,   0]) tensor(2)\n",
            "tensor([  2, 275,   5, 119, 999,  13,   9,   0,   2]) tensor(8)\n",
            "tensor([275,   5, 119, 999,  13,   9,   0,   2,   8]) tensor(5)\n",
            "tensor([  5, 119, 999,  13,   9,   0,   2,   8,   5]) tensor(20)\n",
            "tensor([119, 999,  13,   9,   0,   2,   8,   5,  20]) tensor(204)\n",
            "tensor([999,  13,   9,   0,   2,   8,   5,  20, 204]) tensor(8)\n",
            "tensor([ 13,   9,   0,   2,   8,   5,  20, 204,   8]) tensor(18)\n",
            "tensor([  9,   0,   2,   8,   5,  20, 204,   8,  18]) tensor(362)\n",
            "tensor([  0,   2,   8,   5,  20, 204,   8,  18, 362]) tensor(7)\n",
            "tensor([  2,   8,   5,  20, 204,   8,  18, 362,   7]) tensor(252)\n",
            "tensor([  8,   5,  20, 204,   8,  18, 362,   7, 252]) tensor(0)\n",
            "tensor([  5,  20, 204,   8,  18, 362,   7, 252,   0]) tensor(28)\n",
            "tensor([ 20, 204,   8,  18, 362,   7, 252,   0,  28]) tensor(552)\n",
            "tensor([204,   8,  18, 362,   7, 252,   0,  28, 552]) tensor(7)\n",
            "tensor([  8,  18, 362,   7, 252,   0,  28, 552,   7]) tensor(1082)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gera datasets de treinamento e de teste:\n",
        "\n",
        "- Vou fazer a consideração de que a proporção é no total de parágrafos, e não no total do conjunto de dados. Como cada parágrafo tem um total de frases/palavras diferentes, o conjunto final não ficará com a proporção exatamente conforme esperado inicialmente. Entretanto, pensando que em um texto as coisas são mais ou menos distribuídas, espera-se que, no final, a proporção seja mais ou menos conforme a desejada.\n",
        "\n",
        "- Depois de fazer isso, é necessário gerar novamente o vocabulário, mas considerando apenas o conjunto de treinamento."
      ],
      "metadata": {
        "id": "XdUXho43Jidi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_paragrafos, val_paragrafos = train_test_split(paragrafos, test_size=test_size, random_state=seed)"
      ],
      "metadata": {
        "id": "ru5uXQrcNWSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera novamente o vocabulário, mas agora usando apenas os parágrafos de treinamento\n",
        "vocab_size, vocab, most_frequent_words = gerar_vocabulario(train_paragrafos, vocab_size_desejado_sem_UNK)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3RenZRsN5VQ",
        "outputId": "2a268dc6-fc4f-4589-c9c9-fab38c337a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera os dataset de treino e validação\n",
        "train_data = ParagrafosDataset(train_paragrafos, vocab, context_size)\n",
        "val_data = ParagrafosDataset(val_paragrafos, vocab, context_size)"
      ],
      "metadata": {
        "id": "VCUUQ7szKRcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'len(val_data): {len(val_data)}')\n",
        "print(f'len(train_data): {len(train_data)}')\n",
        "print(f'Proporção de teste: {len(val_data)/(len(train_data)+len(val_data))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiaXj6ejONol",
        "outputId": "93b62113-67db-484e-a502-a2d1f79fba8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(val_data): 19221\n",
            "len(train_data): 79004\n",
            "Proporção de teste: 0.19568337999490965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "liF-kSH_On0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzFrxS_uOm2G",
        "outputId": "a996c813-ecb7-4837-c41b-53bae4a7045e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 244 µs, sys: 43 µs, total: 287 µs\n",
            "Wall time: 294 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "jqxPAD1AOuhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LanguageModel(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, context_size, m, h):\n",
        "    super(LanguageModel, self).__init__()\n",
        "\n",
        "    self.C = nn.Embedding(vocab_size, m)\n",
        "    self.d_plus_H = nn.Linear(in_features=context_size*m, out_features=h, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.b_plus_U = nn.Linear(in_features=h, out_features=vocab_size, bias=True)\n",
        "    # Modelo do artigo:\n",
        "    #self.U = nn.Linear(in_features=h, out_features=vocab_size, bias=False)\n",
        "    #self.b_plus_W = nn.Linear(in_features=context_size*m, out_features=vocab_size, bias=True)\n",
        "\n",
        "  def forward(self, w):\n",
        "    # A fórmula é:\n",
        "    # y = b + Wx + U*tanh(d + Hx)\n",
        "    #\n",
        "    # No exercício, o professor pediu para usar ReLU no lugar de tanh. Além disso,\n",
        "    # comentou para usar duas camadas lineares. Então provavelmente estamos\n",
        "    # fazendo é:\n",
        "    # y = b + U*relu(d + Hx)\n",
        "    # Que é similar ao original, mas considerando W = 0\n",
        "\n",
        "    # x é uma entrada de tamanho context_size (no artigo é chamada de n)\n",
        "    # O primeiro passo é manter os embeddings de x\n",
        "    x = self.C(w)\n",
        "    if x.dim() == 3: # Usando batchs\n",
        "      batch_size, _, _ = x.shape\n",
        "      x = x.view(batch_size, -1)\n",
        "    elif x.dim() == 2: # Calculando sem usar batch, usando um tensor direto\n",
        "      x = x.view(-1)\n",
        "    # O segundo passo é fazer (d + Hx). Isso é uma transformação linear\n",
        "    # A entrada é x (tamanho n*m) e a saída vai ser h (definida)\n",
        "    o = self.d_plus_H(x)\n",
        "    # O artigo calcula com tangente hiperbólica, mas o professor pediu com ReLU\n",
        "    o = self.relu(o)\n",
        "    # Passando pela segunda camada\n",
        "    return self.b_plus_U(o)\n",
        "    # return self.U(o) + self.b_plus_W(x) # Modelo do artigo\n",
        "\n",
        "# Model instantiation\n",
        "model = LanguageModel(vocab_size, context_size, m, h)"
      ],
      "metadata": {
        "id": "dovvTW4XOvXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Testes com as dimensões\n",
        "# Gera um embeddings\n",
        "C = nn.Embedding(vocab_size, m)\n",
        "# Considera que a entrada é um vetor de índice (tem que ser do tamanho de context_size) e calcula os embeddings\n",
        "x = C(torch.tensor(np.random.randint(0, 10, size=context_size)))\n",
        "print(x.shape)\n",
        "# Achata o vetor\n",
        "x = x.view(-1)\n",
        "print(x.shape)\n",
        "# Cria a primeira camada\n",
        "d_plus_H = nn.Linear(in_features=context_size*m, out_features=h, bias=True)\n",
        "o = d_plus_H(x)\n",
        "print(o.shape)\n",
        "# Passa por ReLu\n",
        "o = nn.ReLU()(o)\n",
        "print(o.shape)\n",
        "# Última camada\n",
        "b_plus_U = nn.Linear(in_features=h, out_features=vocab_size, bias=True)\n",
        "o = b_plus_U(o)\n",
        "print(o.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCLjYOiXQNrW",
        "outputId": "2f0669db-866a-4a67-e983-5a145bc79b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 64])\n",
            "torch.Size([576])\n",
            "torch.Size([200])\n",
            "torch.Size([200])\n",
            "torch.Size([3001])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "yhu-jQ_eVa3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "  print('GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "else:\n",
        "  print('using CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3SNZIrtVcFn",
        "outputId": "e59f1e8e-ae06-4e33-e164-5097fab23f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calcula_loss_e_perplexidade(model, loader):\n",
        "  criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "  with torch.no_grad(): # Garante que nenhum gradiente seja calculado\n",
        "    model.eval()  # Coloca o modelo no modo de avaliação (não treinamento)\n",
        "    loss = 0.0\n",
        "    acc = 0\n",
        "    for inputs, targets in tqdm(loader, desc='Calculando loss e perplexidade'):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      # Acumula a perda\n",
        "      loss += criterion(outputs, targets)\n",
        "      acc += len(targets)\n",
        "\n",
        "    loss = loss/acc\n",
        "    ppl = math.exp(loss)\n",
        "\n",
        "    return loss, ppl"
      ],
      "metadata": {
        "id": "X0rfAqUuaw3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálcula a loss e a perplexidade antes do treinamento"
      ],
      "metadata": {
        "id": "ClSr-oYKtP4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_loss_ppl(msg, loss, ppl):\n",
        "  print(f'{msg}. Loss: {loss:.2f}. Perplexidade: {ppl:.2f}\\n')"
      ],
      "metadata": {
        "id": "HrlQb7-9t8Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model instantiation\n",
        "model = LanguageModel(vocab_size, context_size, m, h)\n",
        "model.to(device)\n",
        "\n",
        "# Primeiro testa em um dataloader pequeno:\n",
        "dataset_pequeno = ParagrafosDataset(paragrafos[0:15], vocab, context_size)\n",
        "loader_pequeno = DataLoader(dataset_pequeno, batch_size=2, shuffle=False)\n",
        "\n",
        "loss, ppl = calcula_loss_e_perplexidade(model, loader_pequeno)\n",
        "print_loss_ppl('\\nAntes de iniciar o treinamento', loss, ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3ILXfvGvnpA",
        "outputId": "2e036417-d1b4-43cb-b75f-85ec611e3979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 743/743 [00:01<00:00, 416.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Antes de iniciar o treinamento. Loss: 8.10. Perplexidade: 3293.62\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "print_loss_ppl('\\nAntes de iniciar o treinamento', loss, ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6iJjuQXtUxT",
        "outputId": "426ec9a6-4573-433b-865d-1e70186390e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 413.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Antes de iniciar o treinamento. Loss: 8.03. Perplexidade: 3081.14\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "def treina_modelo(model, optimizer, train_loader, val_loader, num_epochs=num_epochs):\n",
        "  print(f'------------------ ANTES DE INICIAR O TREINAMENTO ------------------')\n",
        "  loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "  print_loss_ppl(f'[TRAIN]', loss, ppl)\n",
        "\n",
        "  loss, ppl = calcula_loss_e_perplexidade(model, val_loader)\n",
        "  print_loss_ppl(f'[EVAL]', loss, ppl)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()  # Start time of the epoch\n",
        "    print(f'------------------ [ÉPOCA {epoch+1}/{num_epochs}] ------------------')\n",
        "    for inputs, targets in tqdm(train_loader, desc='Treinando modelo'):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      # Calcula loss no batch\n",
        "      loss = criterion(outputs, targets)\n",
        "      # Backward and optimize\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    end_time = time.time()  # End time of the epoch\n",
        "    epoch_duration = end_time - start_time  # Duration of epoch\n",
        "\n",
        "    print(f'Elapsed time: {epoch_duration:.2f} sec')\n",
        "\n",
        "    loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "    print_loss_ppl(f'[TRAIN]', loss, ppl)\n",
        "\n",
        "    loss, ppl = calcula_loss_e_perplexidade(model, val_loader)\n",
        "    print_loss_ppl(f'[EVAL]', loss, ppl)\n",
        "\n",
        "    checkpoint_path = f\"modelo_epoca_{epoch+1}.pth\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, checkpoint_path)"
      ],
      "metadata": {
        "id": "s1WxymABVjIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def escrever_frase(modelo, vocab, most_frequent_words, entrada, context_size, n_proximas_palavras, descartar_ukn=True):\n",
        "  if (n_proximas_palavras == 0):\n",
        "    return entrada\n",
        "  else:\n",
        "    # Faz o encode da frase de entrada e considera apenas as últimas 'context_size'\n",
        "    inputs = encode_sentence(entrada, vocab)\n",
        "    # Pega só as context_size últimas\n",
        "    inputs = inputs[len(inputs)-context_size:len(inputs)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output = model(torch.tensor(inputs).to(device))\n",
        "      softmax = nn.functional.softmax(output, dim=0)\n",
        "      if descartar_ukn:\n",
        "        valores, indices = softmax.topk(2, dim=0)\n",
        "        melhor_not_ukn = indices[0].item() if indices[0].item() != 0 else indices[1].item()\n",
        "        predicao = most_frequent_words[melhor_not_ukn]\n",
        "      else:\n",
        "        argmax = softmax.argmax(dim=0)\n",
        "        predicao = most_frequent_words[argmax]\n",
        "\n",
        "  return escrever_frase(modelo, vocab, most_frequent_words, f'{entrada} {predicao}', context_size, n_proximas_palavras-1)"
      ],
      "metadata": {
        "id": "oFm7XMKfOhzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinicializa o modelo\n",
        "model = LanguageModel(vocab_size, context_size, m, h)\n",
        "model.to(device)\n",
        "\n",
        "# Escreve uma frase com o modelo sem estar treinado\n",
        "frase = \"O espectaculo que se ofereceu aos seus olhos causou\"\n",
        "print(escrever_frase(model, vocab, most_frequent_words, frase, context_size, 10))\n",
        "\n",
        "# Treina o modelo\n",
        "#optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "treina_modelo(model, optimizer, train_loader, val_loader, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkDNWpS5OiZk",
        "outputId": "7406b759-ca64-4831-8f1f-90727ab201f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O espectaculo que se ofereceu aos seus olhos causou vacillou loucura fidelidade imprevisto pequenas entrava pello bolsa bolsa elevou\n",
            "------------------ ANTES DE INICIAR O TREINAMENTO ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 339.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 8.02. Perplexidade: 3049.40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 889.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.02. Perplexidade: 3045.94\n",
            "\n",
            "------------------ [ÉPOCA 1/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 368.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.68 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 551.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.60. Perplexidade: 99.03\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 617.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.04. Perplexidade: 154.36\n",
            "\n",
            "------------------ [ÉPOCA 2/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 484.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 843.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.12. Perplexidade: 61.28\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 864.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.91. Perplexidade: 135.64\n",
            "\n",
            "------------------ [ÉPOCA 3/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 491.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.26 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 843.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.76. Perplexidade: 42.83\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 926.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.98. Perplexidade: 145.24\n",
            "\n",
            "------------------ [ÉPOCA 4/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 487.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 870.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.38. Perplexidade: 29.31\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 928.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.10. Perplexidade: 164.08\n",
            "\n",
            "------------------ [ÉPOCA 5/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 495.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.25 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 861.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.06. Perplexidade: 21.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 883.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.30. Perplexidade: 200.73\n",
            "\n",
            "------------------ [ÉPOCA 6/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 439.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.42 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 568.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.72. Perplexidade: 15.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 590.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.49. Perplexidade: 241.66\n",
            "\n",
            "------------------ [ÉPOCA 7/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 429.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.44 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 864.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.52. Perplexidade: 12.39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 910.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.76. Perplexidade: 318.38\n",
            "\n",
            "------------------ [ÉPOCA 8/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 496.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.25 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 868.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.24. Perplexidade: 9.40\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 907.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.01. Perplexidade: 407.12\n",
            "\n",
            "------------------ [ÉPOCA 9/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 487.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 879.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.14. Perplexidade: 8.46\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 893.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.34. Perplexidade: 569.47\n",
            "\n",
            "------------------ [ÉPOCA 10/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 495.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.25 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 854.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.94. Perplexidade: 6.98\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 881.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.60. Perplexidade: 733.86\n",
            "\n",
            "------------------ [ÉPOCA 11/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 497.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.25 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 675.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.85. Perplexidade: 6.37\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 598.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.93. Perplexidade: 1019.42\n",
            "\n",
            "------------------ [ÉPOCA 12/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 384.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.62 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 842.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.71. Perplexidade: 5.52\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 891.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.11. Perplexidade: 1228.10\n",
            "\n",
            "------------------ [ÉPOCA 13/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 497.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.25 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 847.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.66. Perplexidade: 5.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 877.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.39. Perplexidade: 1622.77\n",
            "\n",
            "------------------ [ÉPOCA 14/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 494.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.26 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 880.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.56. Perplexidade: 4.74\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 904.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.61. Perplexidade: 2011.52\n",
            "\n",
            "------------------ [ÉPOCA 15/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 492.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.26 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 880.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.46. Perplexidade: 4.30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 913.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.87. Perplexidade: 2624.11\n",
            "\n",
            "------------------ [ÉPOCA 16/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 482.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 879.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.39. Perplexidade: 4.00\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 886.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.16. Perplexidade: 3507.79\n",
            "\n",
            "------------------ [ÉPOCA 17/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 354.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.75 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 716.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.39. Perplexidade: 4.00\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 858.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.47. Perplexidade: 4747.86\n",
            "\n",
            "------------------ [ÉPOCA 18/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 474.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 860.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.31. Perplexidade: 3.70\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 860.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.68. Perplexidade: 5887.41\n",
            "\n",
            "------------------ [ÉPOCA 19/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 491.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.27 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 833.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.32. Perplexidade: 3.75\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 926.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.97. Perplexidade: 7869.18\n",
            "\n",
            "------------------ [ÉPOCA 20/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 478.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 850.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.23. Perplexidade: 3.44\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 921.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.19. Perplexidade: 9815.68\n",
            "\n",
            "------------------ [ÉPOCA 21/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 487.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 851.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.12. Perplexidade: 3.07\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 887.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.51. Perplexidade: 13470.78\n",
            "\n",
            "------------------ [ÉPOCA 22/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 382.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.62 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 548.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.09. Perplexidade: 2.98\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 843.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.76. Perplexidade: 17311.62\n",
            "\n",
            "------------------ [ÉPOCA 23/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 484.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 841.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.06. Perplexidade: 2.89\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 872.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.10. Perplexidade: 24329.88\n",
            "\n",
            "------------------ [ÉPOCA 24/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 476.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 850.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.03. Perplexidade: 2.80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 858.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.35. Perplexidade: 31278.73\n",
            "\n",
            "------------------ [ÉPOCA 25/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 478.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 843.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.98. Perplexidade: 2.65\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 823.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.74. Perplexidade: 46295.27\n",
            "\n",
            "------------------ [ÉPOCA 26/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 460.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.35 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 812.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.97. Perplexidade: 2.63\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 899.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.07. Perplexidade: 64296.68\n",
            "\n",
            "------------------ [ÉPOCA 27/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 407.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.53 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 550.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.94. Perplexidade: 2.57\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 657.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.48. Perplexidade: 97081.58\n",
            "\n",
            "------------------ [ÉPOCA 28/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 480.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 809.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.86. Perplexidade: 2.36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 888.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.63. Perplexidade: 112690.62\n",
            "\n",
            "------------------ [ÉPOCA 29/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 484.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 844.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.84. Perplexidade: 2.32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 859.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.05. Perplexidade: 171311.86\n",
            "\n",
            "------------------ [ÉPOCA 30/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 489.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.27 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 836.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.80. Perplexidade: 2.24\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 887.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.36. Perplexidade: 232799.55\n",
            "\n",
            "------------------ [ÉPOCA 31/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 481.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 604.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.80. Perplexidade: 2.23\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 795.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.70. Perplexidade: 326821.15\n",
            "\n",
            "------------------ [ÉPOCA 32/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:02<00:00, 260.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 2.38 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 636.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.75. Perplexidade: 2.13\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 843.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.13. Perplexidade: 501934.78\n",
            "\n",
            "------------------ [ÉPOCA 33/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 440.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.41 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 742.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.75. Perplexidade: 2.11\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 741.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.48. Perplexidade: 717207.13\n",
            "\n",
            "------------------ [ÉPOCA 34/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 425.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.46 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 739.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.70. Perplexidade: 2.01\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 783.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.75. Perplexidade: 940613.61\n",
            "\n",
            "------------------ [ÉPOCA 35/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 443.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.40 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 791.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.67. Perplexidade: 1.96\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 816.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 14.17. Perplexidade: 1429365.13\n",
            "\n",
            "------------------ [ÉPOCA 36/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 466.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.33 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 784.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.68. Perplexidade: 1.97\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 542.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 14.59. Perplexidade: 2173017.08\n",
            "\n",
            "------------------ [ÉPOCA 37/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 344.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.80 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 835.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.63. Perplexidade: 1.89\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 830.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 15.06. Perplexidade: 3455336.52\n",
            "\n",
            "------------------ [ÉPOCA 38/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 450.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.38 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 801.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.62. Perplexidade: 1.87\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 780.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 15.21. Perplexidade: 4042800.17\n",
            "\n",
            "------------------ [ÉPOCA 39/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 481.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 848.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.57. Perplexidade: 1.77\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 705.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 15.68. Perplexidade: 6465263.87\n",
            "\n",
            "------------------ [ÉPOCA 40/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 490.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.27 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 852.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.56. Perplexidade: 1.75\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 903.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 15.90. Perplexidade: 8027296.43\n",
            "\n",
            "------------------ [ÉPOCA 41/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 478.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 829.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.53. Perplexidade: 1.70\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 759.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 16.42. Perplexidade: 13488614.15\n",
            "\n",
            "------------------ [ÉPOCA 42/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 347.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.78 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 725.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.51. Perplexidade: 1.66\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 889.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 16.92. Perplexidade: 22347776.67\n",
            "\n",
            "------------------ [ÉPOCA 43/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 488.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.27 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 816.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.52. Perplexidade: 1.68\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 924.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 17.32. Perplexidade: 33348174.14\n",
            "\n",
            "------------------ [ÉPOCA 44/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 477.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 814.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.50. Perplexidade: 1.64\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 857.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 17.64. Perplexidade: 45972007.81\n",
            "\n",
            "------------------ [ÉPOCA 45/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 486.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 858.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.47. Perplexidade: 1.60\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 914.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 17.82. Perplexidade: 55030734.97\n",
            "\n",
            "------------------ [ÉPOCA 46/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 489.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.27 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 889.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.46. Perplexidade: 1.58\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 841.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 18.56. Perplexidade: 114920761.45\n",
            "\n",
            "------------------ [ÉPOCA 47/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 386.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.61 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:01<00:00, 572.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.47. Perplexidade: 1.60\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 899.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 18.94. Perplexidade: 167564381.80\n",
            "\n",
            "------------------ [ÉPOCA 48/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 481.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 860.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.47. Perplexidade: 1.60\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 854.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 19.32. Perplexidade: 244954646.10\n",
            "\n",
            "------------------ [ÉPOCA 49/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 488.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.27 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 870.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.41. Perplexidade: 1.51\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 813.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 19.74. Perplexidade: 374745032.45\n",
            "\n",
            "------------------ [ÉPOCA 50/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 618/618 [00:01<00:00, 481.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 618/618 [00:00<00:00, 816.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.45. Perplexidade: 1.57\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 151/151 [00:00<00:00, 791.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 20.18. Perplexidade: 582021694.07\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recupera_modelo(model, epoca):\n",
        "  # Recupera o modelo salvo na época x\n",
        "  checkpoint_path = f\"modelo_epoca_{epoca}.pth\"\n",
        "  # Carregar o estado do checkpoint\n",
        "  checkpoint = torch.load(checkpoint_path)\n",
        "  # Aplicar o estado do modelo e otimizador carregados\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "YURYSHvB6RPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O conjunto foi treinado com 50 épocas numa tentativa de fazer um overfit do modelo e verificar se ele consegue reproduzir mais ou menos o conjunto de treinamento:"
      ],
      "metadata": {
        "id": "7DdXMftlVkrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfit no modelo pra ver se ele consegue decorar as frases do conjunto de treinamento\n",
        "def completa_frase_do_conjunto(context_size, paragrafos, indices, idx_modelo_overfit):\n",
        "  for i in indices:\n",
        "    frase_esperada = paragrafos[i]\n",
        "    palavras_na_frase = frase_esperada.split(' ')\n",
        "    palavras_na_frase = palavras_na_frase[0:context_size]\n",
        "\n",
        "    if len(palavras_na_frase) == context_size:\n",
        "      frase = ' '.join(palavras_na_frase)\n",
        "      recupera_modelo(model, idx_modelo_overfit)\n",
        "      print('-----------------------------------------------------------------')\n",
        "      print(f'Testando para o índice {i}')\n",
        "      print(f'Modelo da epoca {idx_modelo_overfit}:')\n",
        "      print('Início:  ', frase)\n",
        "      print('Correta: ', frase_esperada)\n",
        "      print('Gerada:  ', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=False))\n",
        "\n",
        "completa_frase_do_conjunto(context_size, train_paragrafos, [1, 2, 4, 5, 8, 9, 18, 20, 21, 30], num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au0YUwHCSyBU",
        "outputId": "315f370f-c9a7-467e-99b8-4c8e12342fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1\n",
            "Modelo da epoca 50:\n",
            "Início:   O espectaculo que se offereceu aos seus olhos causou-lhe\n",
            "Correta:  O espectaculo que se offereceu aos seus olhos causou-lhe uma sorpreza extraordinária; não esperava de certo ver o que se passava a dez passos delle.\n",
            "Gerada:   O espectaculo que se offereceu aos seus olhos causou-lhe uma sorpreza direito , não , e elle adormecida senão em cecilia , ou o outra da tarde , e sem que tenha - a a vida - me por\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 2\n",
            "Modelo da epoca 50:\n",
            "Início:   Era que a revelação physica que acabava de illuminar\n",
            "Correta:  Era que a revelação physica que acabava de illuminar o seu olhar, não era senão o resultado dessa outra revelação moral que esclarecêra o seu espirito; dantes via com os olhos do corpo, agora via com os olhos da alma.\n",
            "Gerada:   Era que a revelação physica que acabava de illuminar o seu olhar , não era senão o resultado dessa outra revelação moral que o dedicação como quebrar surgio se esta terra , e terrivel ! tão ao céo .\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 4\n",
            "Modelo da epoca 50:\n",
            "Início:   --Inda bem que me approvais. Precisava amar; precisava de\n",
            "Correta:  --Inda bem que me approvais. Precisava amar; precisava de uma affeição que me prendesse á vida. Não sei como, não sei quando, comecei a amar-vos; mas em silencio, no fundo de minha alma.\n",
            "Gerada:   --Inda bem que me approvais. Precisava amar; precisava de uma affeição que me não se não lo morto da posição . diogo cecilia gomes ; e no meio esclarecido do que sentia havia aquella touça da segunda que passava\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 5\n",
            "Modelo da epoca 50:\n",
            "Início:   O cavalheiro explicou-lhe como se aproveitára da ida de\n",
            "Correta:  O cavalheiro explicou-lhe como se aproveitára da ida de D. Diogo ao Rio de Janeiro para expulsar o italiano sem rumor e sem escandalo. Então o indio por sua vez contou ao moço o que tinha ouvido na touça de cardos; o projecto que formára de matar os tres aventureiros naquelle manhã; e finalmente a carta que lhe escrevêra por intermedio de Cecilia, para, no caso de succumbir elle, saber o cavalheiro quem erão os inimigos.\n",
            "Gerada:   O cavalheiro explicou-lhe como se aproveitára da ida de d . diogo ao rio de janeiro para defender tempo a parar se livre ? perigo a casa de um doces - la de entre as folhas e a alma\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 8\n",
            "Modelo da epoca 50:\n",
            "Início:   Pery levantou os hombros e mettendo as pistolas na\n",
            "Correta:  Pery levantou os hombros e mettendo as pistolas na cinta passou entre elles com a cabeça alta, o olhar sobrançeiro, e acompanhou sua senhora.\n",
            "Gerada:   Pery levantou os hombros e mettendo as pistolas na cinta passou entre elles com a cabeça alta , o olhar do fidalgo a dous passos sorrindo azul se pertencia , as suas armas de fogo uma sorpreza onde não\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 9\n",
            "Modelo da epoca 50:\n",
            "Início:   Emquanto atravessava o espaço que o separava do seu\n",
            "Correta:  Emquanto atravessava o espaço que o separava do seu aposento, formulou um projecto e tomou uma resolução. Metteu n'uma pequena bolsa de seda uma caixinha de joias; e, envolvendo-se no seu manto, costeou a casa e aproximou-se do pequeno jardim que entestava com o gabinete de Cecilia.\n",
            "Gerada:   Emquanto atravessava o espaço que o separava do seu aposento , formulou um projecto e tomou uma resolução . metteu n ' uma pequena bolsa de seda uma caixinha de madeira ; o que parecia ao tronco da vespera\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 18\n",
            "Modelo da epoca 50:\n",
            "Início:   A menina soltou um grito de susto e entrou\n",
            "Correta:  A menina soltou um grito de susto e entrou rapidamente no jardim. Alvaro apanhou no ar a pequena flôr que se escapára dos dedos de Cecilia e beijou-a julgando que ninguem alli estava. Quando o cavalheiro deo com os olhos na moça, ficou tão perturbado que deixou cahir o jasmim sem sentir.\n",
            "Gerada:   A menina soltou um grito de susto e entrou rapidamente no jardim . alvaro apanhou no ar a pequena flôr que se lembrou , e que os vosso alcance . algum pois . tal soffrer ! . . -\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 20\n",
            "Modelo da epoca 50:\n",
            "Início:   --A senhora não quer que Pery parta, disse ella\n",
            "Correta:  --A senhora não quer que Pery parta, disse ella com um arzinho de rainha, e fazendo um gesto com a cabeça.\n",
            "Gerada:   --A senhora não quer que Pery parta, disse ella com um arzinho de rainha de algodão para ver que os indios porque elle toda a india : pery . por que fosse - a de ver o indio tinha\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 21\n",
            "Modelo da epoca 50:\n",
            "Início:   Um quarto de hora depois vierão ter com elle\n",
            "Correta:  Um quarto de hora depois vierão ter com elle Bento Simões e Ruy Soeiro.\n",
            "Gerada:   Um quarto de hora depois vierão ter com elle bento simões e ruy soeiro . não é que , ella tivesse mulher - lhe , e uma menos faca ; sem que se abria a seus pés . podes\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 30\n",
            "Modelo da epoca 50:\n",
            "Início:   A menina, depois do primeiro momento de sorpreza em\n",
            "Correta:  A menina, depois do primeiro momento de sorpreza em que adivinhou o ciume de Isabel e o seu amor por Alvaro, conseguio dominar-se. Tinha a nobre altivez da castidade; não quiz deixar ver a sua prima o que sentia nesse momento; era boa tambem, amava Isabel, e não desejava magoa-la.\n",
            "Gerada:   A menina, depois do primeiro momento de sorpreza em que adivinhou o ciume de isabel e as arvores ? ruy a uma causa das filhos , e rapidamente ; podia trahir - todos ; o momento , não tinha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testa com uma fase qualquer, mas considerando todos os modelos gerados nas primeiras 10 épocas (só pra ver o que ele está gerando):"
      ],
      "metadata": {
        "id": "CI359dZqWgSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase = \"Se se tratasse de sua vida, Pery teria sangue\"\n",
        "print(frase)\n",
        "for epoca in range(1, 11):\n",
        "  recupera_modelo(model, epoca)\n",
        "  #print(f'Modelo da epoca {epoca}:', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=False))\n",
        "  print(f'Modelo da epoca {epoca}:', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCcGxi9yAkxS",
        "outputId": "32a529d7-bdef-4f3c-e619-961c4cbe41ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se se tratasse de sua vida, Pery teria sangue\n",
            "Modelo da epoca 1: Se se tratasse de sua vida, Pery teria sangue , e que a sua senhora . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "Modelo da epoca 2: Se se tratasse de sua vida, Pery teria sangue ; mas não me a senhora , e não me um momento de que se tinha . se se em torno , e o cavalheiro em que se lhe ;\n",
            "Modelo da epoca 3: Se se tratasse de sua vida, Pery teria sangue a menina de um . que se elevava a menina , e o seu seu companheiro ; que o seu seu espirito , que o seu seu espirito , que\n",
            "Modelo da epoca 4: Se se tratasse de sua vida, Pery teria sangue que a onça dos que o dia se a voz , e o italiano se passava que o dia se elle se , e o italiano que elle se se\n",
            "Modelo da epoca 5: Se se tratasse de sua vida, Pery teria sangue a tua de perigo . nem se a alma do que a um momento a senhora que a menina e a sua mulher , e a sua alma nobre que\n",
            "Modelo da epoca 6: Se se tratasse de sua vida, Pery teria sangue para o italiano . . . tu só ! . . . . . . . . . . . . . . . . . . . . .\n",
            "Modelo da epoca 7: Se se tratasse de sua vida, Pery teria sangue para a lembrança . . . tu me amas . - - a onça . . . . . . . . . . . . . . . .\n",
            "Modelo da epoca 8: Se se tratasse de sua vida, Pery teria sangue de um momento de quatro se lembrou uma idéa de que se lhe podia dado - se a distancia do fidalgo : a sua fortuna , quando me destacava a\n",
            "Modelo da epoca 9: Se se tratasse de sua vida, Pery teria sangue para a lembrança . . . tu me amas ; mas a vida . » mattos . porque . ou a minha mulher . pery tinha voltado essa tribu .\n",
            "Modelo da epoca 10: Se se tratasse de sua vida, Pery teria sangue ? a elle dos olhos , erguendo , que ninguem de ter esse ; se elle a isabel , e o a sua mão um grande , e o rosto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continua alguns parágrafos da base de avaliação usando o modelo treinado na época que deu menor perplexidade no conjunto de treino."
      ],
      "metadata": {
        "id": "xg_4GKJpYpHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoca_do_modelo = 2\n",
        "completa_frase_do_conjunto(context_size, val_paragrafos, [1, 2, 4, 5, 8, 9, 18, 20, 21, 30], epoca_do_modelo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cam_jypxYqW1",
        "outputId": "7752df58-2ef2-4a95-954e-6fd55a39978c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1\n",
            "Modelo da epoca 2:\n",
            "Início:   Se se tratasse de sua vida, Pery teria sangue\n",
            "Correta:  Se se tratasse de sua vida, Pery teria sangue frio; mas Cecilia corria um perigo, e portanto não reflectio, não calculou.\n",
            "Gerada:   Se se tratasse de sua vida, Pery teria sangue <unk> , que se passava de um amigo , de um grito ; mas não se a um momento de um amigo , e que o seu thesouro , e\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 2\n",
            "Modelo da epoca 2:\n",
            "Início:   Alvaro nem se apercebeu do que acabava de passar;\n",
            "Correta:  Alvaro nem se apercebeu do que acabava de passar; lançando um olhar para seus homens que batião-se valentemente com os Aymorés fez um aceno a Ayres Gomes.\n",
            "Gerada:   Alvaro nem se apercebeu do que acabava de passar; <unk> - se com um pouco de um momento de um , que se estava ao de sua senhora . a pery , e que a sua vida e não\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 4\n",
            "Modelo da epoca 2:\n",
            "Início:   No intimo de sua alma quasi que approvava a\n",
            "Correta:  No intimo de sua alma quasi que approvava a resolução de Pery; mas não podia afazer-se á idéa de perder seu amigo, seu companheiro, a unica affeição que talvez ainda lhe restava no mundo.\n",
            "Gerada:   No intimo de sua alma quasi que approvava a sua vida . não me , e não podia um momento de sua mulher . . . se a mão , e que a sua vida e não me .\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 5\n",
            "Modelo da epoca 2:\n",
            "Início:   Temos differentes especies de cactus; os mais lindos são\n",
            "Correta:  Temos differentes especies de cactus; os mais lindos são o branco, o rosa e o amarello, a que os indigenas chamavão _urumbeba_. Todos elles abrem á meia noite e fechão ao despontar do sol.\n",
            "Gerada:   Temos differentes especies de cactus; os mais lindos são <unk> , as suas armas ; mas não podia a sua vida ; não me não se tinha . a que me , e não se , que não podia\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 8\n",
            "Modelo da epoca 2:\n",
            "Início:   O enfermo agonisava sempre; os soluços extremos da vida\n",
            "Correta:  O enfermo agonisava sempre; os soluços extremos da vida que se apaga como a lampada que bruxoleia, agitavão apenas o corpo enregelado.\n",
            "Gerada:   O enfermo agonisava sempre; os soluços extremos da vida ; não se não me a sua vida ; não me não me a pery , e não me um momento de que se tinha . se se em torno\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 9\n",
            "Modelo da epoca 2:\n",
            "Início:   Não é neste lugar que elle deve ser visto;\n",
            "Correta:  Não é neste lugar que elle deve ser visto; sim tres ou quatro leguas acima de sua foz, onde é livre ainda, como o filho indomito desta patria da liberdade.\n",
            "Gerada:   Não é neste lugar que elle deve ser visto; não podia o que se tinha , e que o seu , e não se , e não podia o seu amor ; a sua vida ; mas que se\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 18\n",
            "Modelo da epoca 2:\n",
            "Início:   --Bom, acabemos de uma vez; o que Roberio Dias\n",
            "Correta:  --Bom, acabemos de uma vez; o que Roberio Dias julgava offerecer em Madrid a Felippe II, amigos, está aqui!\n",
            "Gerada:   --Bom, acabemos de uma vez; o que Roberio Dias , e o indio em um momento , e que se passava de um amigo de cecilia , e não se se de sua senhora . se não me a\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 20\n",
            "Modelo da epoca 2:\n",
            "Início:   Quanto a D. Antonio de Mariz, sentira uma intima\n",
            "Correta:  Quanto a D. Antonio de Mariz, sentira uma intima satisfação ouvindo as palavras do moço: seus escrupulos cessavão desde que seus homens espontaneamente se offerecião para realisar aquella difficil empreza.\n",
            "Gerada:   Quanto a D. Antonio de Mariz, sentira uma intima de um homem , e que a sua vida e não me . . não me , não me - se de um , com um , que não se\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 21\n",
            "Modelo da epoca 2:\n",
            "Início:   Com effeito, nada mais loução do que essa alcova,\n",
            "Correta:  Com effeito, nada mais loução do que essa alcova, em que os brocateis de seda se confundião com as lindas pennas de nossas aves, enlaçadas em grinaldas e festões pela orla do tecto e pela cupola do cortinado de um leito collocado sobre um tapete de pelles de animaes selvagens.\n",
            "Gerada:   Com effeito, nada mais loução do que essa alcova, <unk> , que não podia o seu , e não se não de sua mulher . se não me a sua vida ; não me não me a pery ,\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 30\n",
            "Modelo da epoca 2:\n",
            "Início:   A cidade lhe apparecia apenas como uma recordação da\n",
            "Correta:  A cidade lhe apparecia apenas como uma recordação da primeira infancia, como um sonho do berço; deixara o Rio de Janeiro aos cinco annos, e nunca mais alli voltára.\n",
            "Gerada:   A cidade lhe apparecia apenas como uma recordação da <unk> . a sua vida . . . . . . . . . . . . . . . . . . . . . . . . .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcula o total de parâmetros da rede"
      ],
      "metadata": {
        "id": "b6DPR58VY019"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de parâmetros extraído do modelo:\n",
        "print(sum(p.numel() for p in model.parameters()))\n",
        "\n",
        "# Total de parâmetros teórico:\n",
        "total_embeddings = vocab_size * m\n",
        "total_camada_1 = context_size * m * h + h # elementos da matriz + bias\n",
        "total_camada_2 = h * vocab_size + vocab_size # elementos da matriz + bias\n",
        "print(total_embeddings + total_camada_1 + total_camada_2)\n",
        "\n",
        "print(f'Total embeddings: {total_embeddings}')\n",
        "print(f'Total camada 1: {total_camada_1}')\n",
        "print(f'Total camada 2: {total_camada_2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks0ZJ0rNjm3P",
        "outputId": "6ca3eb0a-786f-40fe-cb5a-6d42f7260846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "910665\n",
            "910665\n",
            "Total embeddings: 192064\n",
            "Total camada 1: 115400\n",
            "Total camada 2: 603201\n"
          ]
        }
      ]
    }
  ]
}