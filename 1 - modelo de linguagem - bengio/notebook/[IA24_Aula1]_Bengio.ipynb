{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício: Modelo de linguagem (Bengio 2003) - MLP + Embeddings"
      ],
      "metadata": {
        "id": "cJ4M0Jbi7MVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parâmetros"
      ],
      "metadata": {
        "id": "xRm4Ls8Z1sMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Livros (testando com dom casmurro, memórias póstumas e quincas borda, pra dar pelo menos 20.000 palavras)\n",
        "#urls = [\"https://www.gutenberg.org/cache/epub/55752/pg55752.txt\", \"https://www.gutenberg.org/cache/epub/54829/pg54829.txt\", \"https://www.gutenberg.org/cache/epub/55682/pg55682.txt\"]\n",
        "\n",
        "# Livros (O Guarani)\n",
        "urls = [\"https://www.gutenberg.org/ebooks/67724.txt.utf-8\", \"https://www.gutenberg.org/ebooks/67725.txt.utf-8\"]\n",
        "\n",
        "# Dados do vocabulário\n",
        "UNK = \"<unk>\"\n",
        "vocab_size_desejado_sem_UNK = 3000 # Não considera o UNK\n",
        "vocab_size = vocab_size_desejado_sem_UNK + 1\n",
        "\n",
        "# Dados de treinamento\n",
        "context_size = 9 # número de palavras de entrada. O target é a próxima palavra\n",
        "num_epochs = 50 # usado pra fazer overfit no modelo e ajudar na verificação do treinamento\n",
        "test_size = 0.2\n",
        "seed = 18\n",
        "batch_size=128\n",
        "m = 64 # tamanho dos embeddings\n",
        "h = 200 # tamanho da camada oculta\n",
        "lr = 0.03\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "-jgzz8Ds1wAE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamentos dos dados\n",
        "\n",
        "## Download e agrupamento em parágrafos"
      ],
      "metadata": {
        "id": "7q5P64Abv23C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYDt0_9svZye",
        "outputId": "e2df94d2-bace-4109-dd44-93535dc7663a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- Livro 1 ---------------\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK O GUARANY: ROMANCE BRAZILEIRO, VOL. 1 (OF 2) ***\n",
            "J. DE ALENCAR\n",
            "ROMANCE BRAZILEIRO\n",
            "QUINTA EDIÇÃO\n",
            "TOMO PRIMEIRO\n",
            "RIO DE JANEIRO\n",
            "B.-L. GARNIER, LIVREIRO-EDITOR\n",
            "71, RUA DO OUVIDOR, 71\n",
            "PARIS.--E. MELLIER, 17, RUA SÉGUIER.\n",
            "Ficão reservados os direitos de propriedade.\n",
            "Publicando este livro em 1857, se disse ser aquella primeira edição uma prova typographica, que algum dia talvez o autor se dispuzesse a rever.\n",
            "Esta nova edição devia dar satisfação do empenho, que a extrema benevolencia do publico ledor, tão minguado ainda, mudou em bem para divida de reconhecimento.\n",
            "Mais do que podia fiou de si o autor. Relendo a obra depois de annos, achou elle tão mau e incorrecto quando escrevera, que para bem corrigir, fora mister escrever de novo. Para tanto lhe carece o tempo e sobra o tedio de um labor ingrato.\n",
            "Cingio-se pois ás pequenas emendas que toleravão o plano da obra e o desalinho de um estylo não castigado.\n",
            "PRIMEIRA PARTE\n",
            "OS AVENTUREIROS\n",
            "De um dos cabeços da _Serra dos Órgãos_ deslisa um fio d'agua que se dirige para norte, e engrossado com os mananciaes, que recebe no seu curso de dez leguas, torna-se rio caudal.\n",
            "É o _Paquequer_: soltando de cascata em cascata, enroscando-se como uma serpente, vai depois se espreguiçar na varzea e embeber no Parahyba, que rola magestosamente em seu vasto leito.\n",
            "Dir-se-hia que vassallo e tributario desse rei das aguas, o pequeno rio, altivo e sobranceiro contra os rochedos, curva-se humildemente aos pés do suzerano. Perde então a belleza selvatica; suas ondas são calmas e serenas como as de um lago, e não se revoltão contra os barcos e as canôas que resvalão sobre ellas: escravo submisso, soffre o latego do senhor.\n",
            "Não é neste lugar que elle deve ser visto; sim tres ou quatro leguas acima de sua foz, onde é livre ainda, como o filho indomito desta patria da liberdade.\n",
            "-------------- Livro 2 ---------------\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK O GUARANY: ROMANCE BRAZILEIRO, VOL. 2 (OF 2) ***\n",
            "J. DE ALENCAR\n",
            "ROMANCE BRAZILEIRO\n",
            "QUINTA EDIÇÃO\n",
            "TOMO SEGUNDO\n",
            "RIO DE JANEIRO\n",
            "B.-L. GARNIER, LIVREIRO-EDITOR\n",
            "71, RUA DO OUVIDOR, 71\n",
            "PARIS.--E. MELLIER, 17, RUA SÉGUIER.\n",
            "Ficão reservados os direitos de propriedade.\n",
            "TERCEIRA PARTE\n",
            "Na segunda-feira, erão seis horas da manhã, quando D. Antonio de Mariz chamou seu filho.\n",
            "O velho fidalgo velara uma boa parte da noite; ou escrevendo ou reflectindo sobre os perigos que ameaçavão sua familia.\n",
            "Pery lhe havia contado todas as particularidades de seu encontro com os Aymorés; e o cavalheiro, que conhecia a ferocidade e espirito vingativo dessa raça selvagem, esperava a cada momento ser atacado.\n",
            "Por isso, de acordo com Alvaro, D. Diogo, com seu escudeiro Ayres Gomes, tinha tomado todas as medidas de precaução que as circumstancias e sua longa experiencia lhe aconselhavão.\n",
            "Quando seu filho entrou, o velho fidalgo acabava de sellar duas cartas que escrevêra na vespera.\n",
            "--Meu filho, disse elle com uma ligeira emoção, reflecti essa noite sobre o que nos pode acontecer, e assentei que deves partir hoje mesmo para S. Sebastião.\n",
            "--Não é possivel, senhor!... Afastais-me de vós justamente quando correis um perigo?\n",
            "--Sim! É justamente quando um grande perigo nos ameaça, que eu, chefe da casa, entendo ser do meu dever salvar o representante do meu nome e meu herdeiro legitimo, o protector de minha familia orphã.\n",
            "--Confio em Deos, meu pai, que vossos receios serão infundados; mas se elle nos quizesse submetter a tal provança, o unico lugar que compete a vosso filho e herdeiro de vosso nome é nesta casa ameaçada, ao vosso lado, para defender-vos e partilhar a vossa sorte, qualquer que ella seja.\n",
            "-------------- -------------------------\n",
            "Total de parágrafos: 4596\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def paragrafo_valido(paragrafo):\n",
        "  # Remove:\n",
        "  # - parágrafos curtos demais\n",
        "  # - parágrafos do índice (que tem a string ....)\n",
        "  return len(paragrafo) > 10 and '....' not in paragrafo\n",
        "\n",
        "def carregar_paragrafos_livro(url, n_linhas_para_print=20):\n",
        "  # Baixar o arquivo de texto\n",
        "  response = requests.get(url)\n",
        "  texto = response.text\n",
        "\n",
        "  # Encontrar o início e o fim do conteúdo principal do livro\n",
        "  inicio = texto.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")\n",
        "  fim = texto.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
        "\n",
        "  # Extrair o conteúdo principal do livro\n",
        "  conteudo = texto[inicio:fim].replace('\\r','')\n",
        "\n",
        "  # Dividir o conteúdo em parágrafos e processar o conteúdo\n",
        "  paragrafos = []\n",
        "\n",
        "  # Cada parágrafo é separado por dois \\n\n",
        "  # Dentro de cada parágrafo, junta as linhas (remove) e faz um trim\n",
        "  # Apenas considera os parágrafos que tem pelo menos 10 caracteres\n",
        "  for paragrafo in conteudo.split(\"\\n\\n\"):\n",
        "    paragrafo = paragrafo.replace('\\n', ' ').strip()\n",
        "    if paragrafo_valido(paragrafo):\n",
        "      paragrafos.append(paragrafo)\n",
        "\n",
        "  for p in paragrafos[0:n_linhas_para_print]:\n",
        "    print(p)\n",
        "\n",
        "  return paragrafos\n",
        "\n",
        "paragrafos = []\n",
        "for i, url in enumerate(urls, 1):\n",
        "  print(f'-------------- Livro {i} ---------------')\n",
        "  paragrafos.extend(carregar_paragrafos_livro(url))\n",
        "\n",
        "print('-------------- -------------------------')\n",
        "print(f'Total de parágrafos: {len(paragrafos)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragrafos[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FlJPdVMWp2R5",
        "outputId": "a91a1593-3693-42c2-b5ae-32821876c1ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'QUINTA EDIÇÃO'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizador\n",
        "\n",
        "Define um tokenizador simples. A ideia desse tokenizador é manter as palavras e os sinais de pontuação. Quero testar gerar tokens também para os sinais de pontuação.\n",
        "\n",
        "*Gerado com ChatGPT.*"
      ],
      "metadata": {
        "id": "Pa9xkSle06bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenizar(texto):\n",
        "  texto = texto.lower()\n",
        "\n",
        "  # Força os 3 pontos aparecerem juntos\n",
        "  texto = texto.replace('...', 'SUBSTITUIRPORTRESPONTOS')\n",
        "\n",
        "  # Define a expressão regular que captura palavras e sinais de pontuação\n",
        "  padrao = r'\\w+|[^\\w\\s]'\n",
        "\n",
        "  # Usa o método findall para encontrar todas as ocorrências que se encaixam no padrão\n",
        "  tokens = re.findall(padrao, texto)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "print(tokenizar('Teste. Será que vai manter a pontuação?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyRd2ylAyO89",
        "outputId": "e2e17a8d-703f-4292-9d6d-5715a451fe6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['teste', '.', 'será', 'que', 'vai', 'manter', 'a', 'pontuação', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração do vocabulário\n",
        "\n",
        "Agora vamos gerar o vocabulário."
      ],
      "metadata": {
        "id": "py_qYd1b18mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from collections import Counter\n",
        "counter = Counter()\n",
        "\n",
        "def gerar_vocabulario(paragrafos, vocab_size_sem_UNK):\n",
        "  for p in paragrafos:\n",
        "    # Update com os tokens de cada parágrafo\n",
        "    counter.update(tokenizar(p))\n",
        "\n",
        "  # Considera apenas as palavras mais frequentes. Adiciona, na posição 0, o token UNK\n",
        "  most_frequent_words = [UNK] + sorted(counter, key=counter.get, reverse=True)[:vocab_size_sem_UNK]\n",
        "  # vocab é um mapa de palavras para o índice correspondente. O mapa leva a palavra para um índice entre [0, vocab_size]\n",
        "  # (o tamanho é vocab_size + 1), com o índice 0 apontando para UNK\n",
        "  vocab = {word: i for i, word in enumerate(most_frequent_words)}\n",
        "\n",
        "  return len(most_frequent_words), vocab, most_frequent_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYMsMQV919LN",
        "outputId": "a3561467-ecff-43e8-9b1f-9618331cb8d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14 µs, sys: 0 ns, total: 14 µs\n",
            "Wall time: 16.7 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, vocab, most_frequent_words = gerar_vocabulario(paragrafos, vocab_size_desejado_sem_UNK)\n",
        "\n",
        "print('Tamanho do vocabulário (considera UNK): ', vocab_size)\n",
        "\n",
        "print('Posição 0: ', most_frequent_words[0])\n",
        "print('Índice do UNK: ', vocab[UNK])\n",
        "print('------------')\n",
        "print('Posição 200: ', most_frequent_words[200])\n",
        "print(f'Índice de {most_frequent_words[200]}: ', vocab[most_frequent_words[200]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmwhcpZF4hqH",
        "outputId": "6ba0a577-15a4-4ba7-f60e-097c4342e7c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do vocabulário (considera UNK):  3001\n",
            "Posição 0:  <unk>\n",
            "Índice do UNK:  0\n",
            "------------\n",
            "Posição 200:  tambem\n",
            "Índice de tambem:  200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder de frases"
      ],
      "metadata": {
        "id": "RoLvU4XC9IZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sentence, vocab):\n",
        "  # Obs.: tem que usar o mesmo tokenizador que foi gerado o vocabulário\n",
        "  return [vocab.get(word, 0) for word in tokenizar(sentence)]"
      ],
      "metadata": {
        "id": "0JCO2quC6Wtt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sentence(sentence, most_frequent_words):\n",
        "  words = [most_frequent_words[code] for code in sentence]\n",
        "  return ' '.join(words)"
      ],
      "metadata": {
        "id": "OBNbtpkF97sr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do encode/decode\n",
        "frase = \"E ele pegou a árvore e arrancou do chão.\"\n",
        "\n",
        "frase_encodada = encode_sentence(frase, vocab)\n",
        "frase_reconstruida = decode_sentence(frase_encodada, most_frequent_words)\n",
        "\n",
        "print('Original:')\n",
        "print(frase)\n",
        "print('Encodada:')\n",
        "print(frase_encodada)\n",
        "print('Reconstruída:')\n",
        "print(frase_reconstruida)\n",
        "print(\"--------------------------------------\")\n",
        "\n",
        "frase = \"E no seminario me disseram que não.\"\n",
        "\n",
        "frase_encodada = encode_sentence(frase, vocab)\n",
        "frase_reconstruida = decode_sentence(frase_encodada, most_frequent_words)\n",
        "\n",
        "print('Original:')\n",
        "print(frase)\n",
        "print('Encodada:')\n",
        "print(frase_encodada)\n",
        "print('Reconstruída:')\n",
        "print(frase_reconstruida)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-qN55c5-i8Z",
        "outputId": "1fd2b1e1-c35a-48bd-fd02-35daf20297bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "E ele pegou a árvore e arrancou do chão.\n",
            "Encodada:\n",
            "[8, 0, 0, 4, 0, 8, 1640, 12, 378, 3]\n",
            "Reconstruída:\n",
            "e <unk> <unk> a <unk> e arrancou do chão .\n",
            "--------------------------------------\n",
            "Original:\n",
            "E no seminario me disseram que não.\n",
            "Encodada:\n",
            "[8, 25, 0, 45, 0, 5, 13, 3]\n",
            "Reconstruída:\n",
            "e no <unk> me <unk> que não .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "NYphluu6AOnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada parágrafo, é necessário gerar os dados de treinamento. Supondo que a frase é \"eu gosto de pizza.\" e vamos usar uma janela de contexto igual a 2, a ideia é que essa frase gere o seguinte conjunto de treinamento:\n",
        "\n",
        "input -> target\n",
        "\n",
        "[UNK, \"eu\"] -> \"gosto\" (ESSE CASO NÃO SERÁ CONSIDERADO POR ENQUANTO)\n",
        "\n",
        "[\"eu\", \"gosto\"] -> \"de\"\n",
        "\n",
        "[\"gosto\", \"de\"] -> \"pizza\"\n",
        "\n",
        "[\"de\", \"pizza\"] -> \".\""
      ],
      "metadata": {
        "id": "FYjJsO8BByxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gera_inputs_e_targets_para_array(array, n):\n",
        "  # Faz uma janela deslizante de tamanho n no array\n",
        "\n",
        "  janelas = []\n",
        "  targets = []\n",
        "\n",
        "  for i in range(len(array) - n):\n",
        "    janela = array[i:i+n]\n",
        "    janelas.append(janela)\n",
        "    targets.append(array[i+n])\n",
        "\n",
        "  return janelas, targets\n",
        "\n",
        "# Exemplo de uso\n",
        "exemplo = \"eu gosto de pizza .\".split()\n",
        "\n",
        "for n in range(1, 4):\n",
        "  print(f'Testando para janela de tamanho {n}')\n",
        "  inputs, targets = gera_inputs_e_targets_para_array(exemplo, n)\n",
        "\n",
        "  # Testa\n",
        "  for input_target in zip(inputs, targets):\n",
        "    print(f'{input_target[0]} -> {input_target[1]}')\n",
        "  print('------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUUUqSSaCeIO",
        "outputId": "90fd202f-9eeb-4129-f8eb-ee7ad11f8e67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando para janela de tamanho 1\n",
            "['eu'] -> gosto\n",
            "['gosto'] -> de\n",
            "['de'] -> pizza\n",
            "['pizza'] -> .\n",
            "------------------------------\n",
            "Testando para janela de tamanho 2\n",
            "['eu', 'gosto'] -> de\n",
            "['gosto', 'de'] -> pizza\n",
            "['de', 'pizza'] -> .\n",
            "------------------------------\n",
            "Testando para janela de tamanho 3\n",
            "['eu', 'gosto', 'de'] -> pizza\n",
            "['gosto', 'de', 'pizza'] -> .\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa com um parágrafo real e o tamanho do contexto configurado\n",
        "i = 60\n",
        "inputs, targets = gera_inputs_e_targets_para_array(tokenizar(paragrafos[i]), context_size)\n",
        "print(paragrafos[i])\n",
        "for input_target in zip(inputs, targets):\n",
        "  print(f'{input_target[0]} -> {input_target[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlO4K7-WFShp",
        "outputId": "46331df6-cb83-4c58-fbe7-4119098ae84e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Aqui sou portuguez! Aqui pode respirar á vontade um coração leal, que nunca desmentio a fé do juramento. Nesta terra que me foi dada pelo meu rei, e conquistada pelo meu braço, nesta terra livre, tu reinarás, Portugal, como viverás n'alma de teus filhos. Eu o juro!\n",
            "['-', '-', 'aqui', 'sou', 'portuguez', '!', 'aqui', 'pode', 'respirar'] -> á\n",
            "['-', 'aqui', 'sou', 'portuguez', '!', 'aqui', 'pode', 'respirar', 'á'] -> vontade\n",
            "['aqui', 'sou', 'portuguez', '!', 'aqui', 'pode', 'respirar', 'á', 'vontade'] -> um\n",
            "['sou', 'portuguez', '!', 'aqui', 'pode', 'respirar', 'á', 'vontade', 'um'] -> coração\n",
            "['portuguez', '!', 'aqui', 'pode', 'respirar', 'á', 'vontade', 'um', 'coração'] -> leal\n",
            "['!', 'aqui', 'pode', 'respirar', 'á', 'vontade', 'um', 'coração', 'leal'] -> ,\n",
            "['aqui', 'pode', 'respirar', 'á', 'vontade', 'um', 'coração', 'leal', ','] -> que\n",
            "['pode', 'respirar', 'á', 'vontade', 'um', 'coração', 'leal', ',', 'que'] -> nunca\n",
            "['respirar', 'á', 'vontade', 'um', 'coração', 'leal', ',', 'que', 'nunca'] -> desmentio\n",
            "['á', 'vontade', 'um', 'coração', 'leal', ',', 'que', 'nunca', 'desmentio'] -> a\n",
            "['vontade', 'um', 'coração', 'leal', ',', 'que', 'nunca', 'desmentio', 'a'] -> fé\n",
            "['um', 'coração', 'leal', ',', 'que', 'nunca', 'desmentio', 'a', 'fé'] -> do\n",
            "['coração', 'leal', ',', 'que', 'nunca', 'desmentio', 'a', 'fé', 'do'] -> juramento\n",
            "['leal', ',', 'que', 'nunca', 'desmentio', 'a', 'fé', 'do', 'juramento'] -> .\n",
            "[',', 'que', 'nunca', 'desmentio', 'a', 'fé', 'do', 'juramento', '.'] -> nesta\n",
            "['que', 'nunca', 'desmentio', 'a', 'fé', 'do', 'juramento', '.', 'nesta'] -> terra\n",
            "['nunca', 'desmentio', 'a', 'fé', 'do', 'juramento', '.', 'nesta', 'terra'] -> que\n",
            "['desmentio', 'a', 'fé', 'do', 'juramento', '.', 'nesta', 'terra', 'que'] -> me\n",
            "['a', 'fé', 'do', 'juramento', '.', 'nesta', 'terra', 'que', 'me'] -> foi\n",
            "['fé', 'do', 'juramento', '.', 'nesta', 'terra', 'que', 'me', 'foi'] -> dada\n",
            "['do', 'juramento', '.', 'nesta', 'terra', 'que', 'me', 'foi', 'dada'] -> pelo\n",
            "['juramento', '.', 'nesta', 'terra', 'que', 'me', 'foi', 'dada', 'pelo'] -> meu\n",
            "['.', 'nesta', 'terra', 'que', 'me', 'foi', 'dada', 'pelo', 'meu'] -> rei\n",
            "['nesta', 'terra', 'que', 'me', 'foi', 'dada', 'pelo', 'meu', 'rei'] -> ,\n",
            "['terra', 'que', 'me', 'foi', 'dada', 'pelo', 'meu', 'rei', ','] -> e\n",
            "['que', 'me', 'foi', 'dada', 'pelo', 'meu', 'rei', ',', 'e'] -> conquistada\n",
            "['me', 'foi', 'dada', 'pelo', 'meu', 'rei', ',', 'e', 'conquistada'] -> pelo\n",
            "['foi', 'dada', 'pelo', 'meu', 'rei', ',', 'e', 'conquistada', 'pelo'] -> meu\n",
            "['dada', 'pelo', 'meu', 'rei', ',', 'e', 'conquistada', 'pelo', 'meu'] -> braço\n",
            "['pelo', 'meu', 'rei', ',', 'e', 'conquistada', 'pelo', 'meu', 'braço'] -> ,\n",
            "['meu', 'rei', ',', 'e', 'conquistada', 'pelo', 'meu', 'braço', ','] -> nesta\n",
            "['rei', ',', 'e', 'conquistada', 'pelo', 'meu', 'braço', ',', 'nesta'] -> terra\n",
            "[',', 'e', 'conquistada', 'pelo', 'meu', 'braço', ',', 'nesta', 'terra'] -> livre\n",
            "['e', 'conquistada', 'pelo', 'meu', 'braço', ',', 'nesta', 'terra', 'livre'] -> ,\n",
            "['conquistada', 'pelo', 'meu', 'braço', ',', 'nesta', 'terra', 'livre', ','] -> tu\n",
            "['pelo', 'meu', 'braço', ',', 'nesta', 'terra', 'livre', ',', 'tu'] -> reinarás\n",
            "['meu', 'braço', ',', 'nesta', 'terra', 'livre', ',', 'tu', 'reinarás'] -> ,\n",
            "['braço', ',', 'nesta', 'terra', 'livre', ',', 'tu', 'reinarás', ','] -> portugal\n",
            "[',', 'nesta', 'terra', 'livre', ',', 'tu', 'reinarás', ',', 'portugal'] -> ,\n",
            "['nesta', 'terra', 'livre', ',', 'tu', 'reinarás', ',', 'portugal', ','] -> como\n",
            "['terra', 'livre', ',', 'tu', 'reinarás', ',', 'portugal', ',', 'como'] -> viverás\n",
            "['livre', ',', 'tu', 'reinarás', ',', 'portugal', ',', 'como', 'viverás'] -> n\n",
            "[',', 'tu', 'reinarás', ',', 'portugal', ',', 'como', 'viverás', 'n'] -> '\n",
            "['tu', 'reinarás', ',', 'portugal', ',', 'como', 'viverás', 'n', \"'\"] -> alma\n",
            "['reinarás', ',', 'portugal', ',', 'como', 'viverás', 'n', \"'\", 'alma'] -> de\n",
            "[',', 'portugal', ',', 'como', 'viverás', 'n', \"'\", 'alma', 'de'] -> teus\n",
            "['portugal', ',', 'como', 'viverás', 'n', \"'\", 'alma', 'de', 'teus'] -> filhos\n",
            "[',', 'como', 'viverás', 'n', \"'\", 'alma', 'de', 'teus', 'filhos'] -> .\n",
            "['como', 'viverás', 'n', \"'\", 'alma', 'de', 'teus', 'filhos', '.'] -> eu\n",
            "['viverás', 'n', \"'\", 'alma', 'de', 'teus', 'filhos', '.', 'eu'] -> o\n",
            "['n', \"'\", 'alma', 'de', 'teus', 'filhos', '.', 'eu', 'o'] -> juro\n",
            "[\"'\", 'alma', 'de', 'teus', 'filhos', '.', 'eu', 'o', 'juro'] -> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa com um parágrafo real, mas agora ele encodado e o tamanho do contexto configurado\n",
        "inputs, targets = gera_inputs_e_targets_para_array(encode_sentence(paragrafos[i], vocab), context_size)\n",
        "print(paragrafos[i])\n",
        "for input_target in zip(inputs, targets):\n",
        "  print(f'{input_target[0]} -> {input_target[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM9NAFzaGIPf",
        "outputId": "66d908cf-efb9-4c87-870e-a8e88e205c3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Aqui sou portuguez! Aqui pode respirar á vontade um coração leal, que nunca desmentio a fé do juramento. Nesta terra que me foi dada pelo meu rei, e conquistada pelo meu braço, nesta terra livre, tu reinarás, Portugal, como viverás n'alma de teus filhos. Eu o juro!\n",
            "[2, 2, 254, 779, 778, 21, 254, 646, 0] -> 32\n",
            "[2, 254, 779, 778, 21, 254, 646, 0, 32] -> 351\n",
            "[254, 779, 778, 21, 254, 646, 0, 32, 351] -> 11\n",
            "[779, 778, 21, 254, 646, 0, 32, 351, 11] -> 133\n",
            "[778, 21, 254, 646, 0, 32, 351, 11, 133] -> 1294\n",
            "[21, 254, 646, 0, 32, 351, 11, 133, 1294] -> 1\n",
            "[254, 646, 0, 32, 351, 11, 133, 1294, 1] -> 5\n",
            "[646, 0, 32, 351, 11, 133, 1294, 1, 5] -> 246\n",
            "[0, 32, 351, 11, 133, 1294, 1, 5, 246] -> 0\n",
            "[32, 351, 11, 133, 1294, 1, 5, 246, 0] -> 4\n",
            "[351, 11, 133, 1294, 1, 5, 246, 0, 4] -> 931\n",
            "[11, 133, 1294, 1, 5, 246, 0, 4, 931] -> 12\n",
            "[133, 1294, 1, 5, 246, 0, 4, 931, 12] -> 732\n",
            "[1294, 1, 5, 246, 0, 4, 931, 12, 732] -> 3\n",
            "[1, 5, 246, 0, 4, 931, 12, 732, 3] -> 508\n",
            "[5, 246, 0, 4, 931, 12, 732, 3, 508] -> 131\n",
            "[246, 0, 4, 931, 12, 732, 3, 508, 131] -> 5\n",
            "[0, 4, 931, 12, 732, 3, 508, 131, 5] -> 45\n",
            "[4, 931, 12, 732, 3, 508, 131, 5, 45] -> 88\n",
            "[931, 12, 732, 3, 508, 131, 5, 45, 88] -> 0\n",
            "[12, 732, 3, 508, 131, 5, 45, 88, 0] -> 80\n",
            "[732, 3, 508, 131, 5, 45, 88, 0, 80] -> 97\n",
            "[3, 508, 131, 5, 45, 88, 0, 80, 97] -> 550\n",
            "[508, 131, 5, 45, 88, 0, 80, 97, 550] -> 1\n",
            "[131, 5, 45, 88, 0, 80, 97, 550, 1] -> 8\n",
            "[5, 45, 88, 0, 80, 97, 550, 1, 8] -> 0\n",
            "[45, 88, 0, 80, 97, 550, 1, 8, 0] -> 80\n",
            "[88, 0, 80, 97, 550, 1, 8, 0, 80] -> 97\n",
            "[0, 80, 97, 550, 1, 8, 0, 80, 97] -> 204\n",
            "[80, 97, 550, 1, 8, 0, 80, 97, 204] -> 1\n",
            "[97, 550, 1, 8, 0, 80, 97, 204, 1] -> 508\n",
            "[550, 1, 8, 0, 80, 97, 204, 1, 508] -> 131\n",
            "[1, 8, 0, 80, 97, 204, 1, 508, 131] -> 395\n",
            "[8, 0, 80, 97, 204, 1, 508, 131, 395] -> 1\n",
            "[0, 80, 97, 204, 1, 508, 131, 395, 1] -> 60\n",
            "[80, 97, 204, 1, 508, 131, 395, 1, 60] -> 0\n",
            "[97, 204, 1, 508, 131, 395, 1, 60, 0] -> 1\n",
            "[204, 1, 508, 131, 395, 1, 60, 0, 1] -> 1076\n",
            "[1, 508, 131, 395, 1, 60, 0, 1, 1076] -> 1\n",
            "[508, 131, 395, 1, 60, 0, 1, 1076, 1] -> 29\n",
            "[131, 395, 1, 60, 0, 1, 1076, 1, 29] -> 2492\n",
            "[395, 1, 60, 0, 1, 1076, 1, 29, 2492] -> 127\n",
            "[1, 60, 0, 1, 1076, 1, 29, 2492, 127] -> 59\n",
            "[60, 0, 1, 1076, 1, 29, 2492, 127, 59] -> 134\n",
            "[0, 1, 1076, 1, 29, 2492, 127, 59, 134] -> 7\n",
            "[1, 1076, 1, 29, 2492, 127, 59, 134, 7] -> 601\n",
            "[1076, 1, 29, 2492, 127, 59, 134, 7, 601] -> 1080\n",
            "[1, 29, 2492, 127, 59, 134, 7, 601, 1080] -> 3\n",
            "[29, 2492, 127, 59, 134, 7, 601, 1080, 3] -> 86\n",
            "[2492, 127, 59, 134, 7, 601, 1080, 3, 86] -> 6\n",
            "[127, 59, 134, 7, 601, 1080, 3, 86, 6] -> 873\n",
            "[59, 134, 7, 601, 1080, 3, 86, 6, 873] -> 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "class ParagrafosDataset(Dataset):\n",
        "  def __init__(self, paragrafos, vocab, context_size):\n",
        "    # Salva o vocabulário\n",
        "    self.vocab = vocab\n",
        "    # Cria os inputs e target\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for p in paragrafos:\n",
        "      # O primeiro passo é pegar cada frase do parágrafo e encodar\n",
        "      p_tokenizado = encode_sentence(p, self.vocab)\n",
        "      # Só faz sentido considerar frases que tem no mínimo (context_size + 1) tokens\n",
        "      if (len(p_tokenizado) <= context_size):\n",
        "        continue\n",
        "\n",
        "      # Agora vamos gerar os dados de treinamento para esse parágrafo\n",
        "      p_inputs, p_targets = gera_inputs_e_targets_para_array(p_tokenizado, context_size)\n",
        "\n",
        "      # Adiciona independentemente se tiver UKN ou não no input ou target\n",
        "      inputs.extend(p_inputs)\n",
        "      targets.extend(p_targets)\n",
        "\n",
        "      # Apenas adiciona se o input ou o target não tiver nenhum UNK (código 0)\n",
        "      #for p_um_input, p_um_target in zip(p_inputs, p_targets):\n",
        "      #  if (0 not in p_um_input and p_um_target != 0):\n",
        "      #    inputs.append(p_um_input)\n",
        "      #    targets.append(p_um_target)\n",
        "\n",
        "    # Mantém em cache\n",
        "    self.inputs = torch.tensor(inputs)\n",
        "    self.targets = torch.tensor(targets)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5gvB84ZAQyX",
        "outputId": "08706daf-f573-4691-a57a-885d7f37e314"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.88 s, sys: 400 ms, total: 2.28 s\n",
            "Wall time: 5.14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste_paragrafos = [\"Depois, vendo que esta expedição não se realisava, e que seu braço e sua coragem de nada valião ao rei de Portugal\"]\n",
        "teste_dataset = ParagrafosDataset(teste_paragrafos, vocab, context_size)\n",
        "\n",
        "print('Imprimindo o dataset')\n",
        "for dados in teste_dataset:\n",
        "  print(dados)\n",
        "\n",
        "print('-------------------------')\n",
        "print('Como deveria estar (testando se o dataset está considerando corretamente os parágrafos. Tem que descartar os que tem UNK (0)):')\n",
        "for p in teste_paragrafos:\n",
        "  # Faz o encode do parágrafo\n",
        "  p_encodado = encode_sentence(p, vocab)\n",
        "  inputs, targets = gera_inputs_e_targets_para_array(p_encodado, context_size)\n",
        "  for inputs_targets in zip(inputs, targets):\n",
        "    print(torch.tensor(inputs_targets[0]), torch.tensor(inputs_targets[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScJGPiMVH4xs",
        "outputId": "58d5e7ee-daba-4f49-c7fb-24447509283c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imprimindo o dataset\n",
            "(tensor([ 63,   1, 275,   5, 120, 995,  13,   9,   0]), tensor(1))\n",
            "(tensor([  1, 275,   5, 120, 995,  13,   9,   0,   1]), tensor(8))\n",
            "(tensor([275,   5, 120, 995,  13,   9,   0,   1,   8]), tensor(5))\n",
            "(tensor([  5, 120, 995,  13,   9,   0,   1,   8,   5]), tensor(20))\n",
            "(tensor([120, 995,  13,   9,   0,   1,   8,   5,  20]), tensor(204))\n",
            "(tensor([995,  13,   9,   0,   1,   8,   5,  20, 204]), tensor(8))\n",
            "(tensor([ 13,   9,   0,   1,   8,   5,  20, 204,   8]), tensor(18))\n",
            "(tensor([  9,   0,   1,   8,   5,  20, 204,   8,  18]), tensor(363))\n",
            "(tensor([  0,   1,   8,   5,  20, 204,   8,  18, 363]), tensor(7))\n",
            "(tensor([  1,   8,   5,  20, 204,   8,  18, 363,   7]), tensor(252))\n",
            "(tensor([  8,   5,  20, 204,   8,  18, 363,   7, 252]), tensor(0))\n",
            "(tensor([  5,  20, 204,   8,  18, 363,   7, 252,   0]), tensor(28))\n",
            "(tensor([ 20, 204,   8,  18, 363,   7, 252,   0,  28]), tensor(550))\n",
            "(tensor([204,   8,  18, 363,   7, 252,   0,  28, 550]), tensor(7))\n",
            "(tensor([  8,  18, 363,   7, 252,   0,  28, 550,   7]), tensor(1076))\n",
            "-------------------------\n",
            "Como deveria estar (testando se o dataset está considerando corretamente os parágrafos. Tem que descartar os que tem UNK (0)):\n",
            "tensor([ 63,   1, 275,   5, 120, 995,  13,   9,   0]) tensor(1)\n",
            "tensor([  1, 275,   5, 120, 995,  13,   9,   0,   1]) tensor(8)\n",
            "tensor([275,   5, 120, 995,  13,   9,   0,   1,   8]) tensor(5)\n",
            "tensor([  5, 120, 995,  13,   9,   0,   1,   8,   5]) tensor(20)\n",
            "tensor([120, 995,  13,   9,   0,   1,   8,   5,  20]) tensor(204)\n",
            "tensor([995,  13,   9,   0,   1,   8,   5,  20, 204]) tensor(8)\n",
            "tensor([ 13,   9,   0,   1,   8,   5,  20, 204,   8]) tensor(18)\n",
            "tensor([  9,   0,   1,   8,   5,  20, 204,   8,  18]) tensor(363)\n",
            "tensor([  0,   1,   8,   5,  20, 204,   8,  18, 363]) tensor(7)\n",
            "tensor([  1,   8,   5,  20, 204,   8,  18, 363,   7]) tensor(252)\n",
            "tensor([  8,   5,  20, 204,   8,  18, 363,   7, 252]) tensor(0)\n",
            "tensor([  5,  20, 204,   8,  18, 363,   7, 252,   0]) tensor(28)\n",
            "tensor([ 20, 204,   8,  18, 363,   7, 252,   0,  28]) tensor(550)\n",
            "tensor([204,   8,  18, 363,   7, 252,   0,  28, 550]) tensor(7)\n",
            "tensor([  8,  18, 363,   7, 252,   0,  28, 550,   7]) tensor(1076)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gera datasets de treinamento e de teste:\n",
        "\n",
        "- Vou fazer a consideração de que a proporção é no total de parágrafos, e não no total do conjunto de dados. Como cada parágrafo tem um total de frases/palavras diferentes, o conjunto final não ficará com a proporção exatamente conforme esperado inicialmente. Entretanto, pensando que em um texto as coisas são mais ou menos distribuídas, espera-se que, no final, a proporção seja mais ou menos conforme a desejada.\n",
        "\n",
        "- Depois de fazer isso, é necessário gerar novamente o vocabulário, mas considerando apenas o conjunto de treinamento."
      ],
      "metadata": {
        "id": "XdUXho43Jidi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_paragrafos, val_paragrafos = train_test_split(paragrafos, test_size=test_size, random_state=seed)"
      ],
      "metadata": {
        "id": "ru5uXQrcNWSg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera novamente o vocabulário, mas agora usando apenas os parágrafos de treinamento\n",
        "vocab_size, vocab, most_frequent_words = gerar_vocabulario(train_paragrafos, vocab_size_desejado_sem_UNK)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3RenZRsN5VQ",
        "outputId": "d4b735b9-0dde-449a-853e-e5ac8effd3f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera os dataset de treino e validação\n",
        "train_data = ParagrafosDataset(train_paragrafos, vocab, context_size)\n",
        "val_data = ParagrafosDataset(val_paragrafos, vocab, context_size)"
      ],
      "metadata": {
        "id": "VCUUQ7szKRcB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'len(val_data): {len(val_data)}')\n",
        "print(f'len(train_data): {len(train_data)}')\n",
        "print(f'Proporção de teste: {len(val_data)/(len(train_data)+len(val_data))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiaXj6ejONol",
        "outputId": "583d22cd-df64-4efc-bb81-574b40710291"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(val_data): 19009\n",
            "len(train_data): 76020\n",
            "Proporção de teste: 0.20003367393111576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "liF-kSH_On0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzFrxS_uOm2G",
        "outputId": "62c26f2b-c30f-49eb-931d-dce72e338a03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 265 µs, sys: 46 µs, total: 311 µs\n",
            "Wall time: 318 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "jqxPAD1AOuhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LanguageModel(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, context_size, m, h):\n",
        "    super(LanguageModel, self).__init__()\n",
        "\n",
        "    self.C = nn.Embedding(vocab_size, m)\n",
        "    self.d_plus_H = nn.Linear(in_features=context_size*m, out_features=h, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.b_plus_U = nn.Linear(in_features=h, out_features=vocab_size, bias=True)\n",
        "    # Modelo do artigo:\n",
        "    #self.U = nn.Linear(in_features=h, out_features=vocab_size, bias=False)\n",
        "    #self.b_plus_W = nn.Linear(in_features=context_size*m, out_features=vocab_size, bias=True)\n",
        "\n",
        "  def forward(self, w):\n",
        "    # A fórmula é:\n",
        "    # y = b + Wx + U*tanh(d + Hx)\n",
        "    #\n",
        "    # No exercício, o professor pediu para usar ReLU no lugar de tanh. Além disso,\n",
        "    # comentou para usar duas camadas lineares. Então provavelmente estamos\n",
        "    # fazendo é:\n",
        "    # y = b + U*relu(d + Hx)\n",
        "    # Que é similar ao original, mas considerando W = 0\n",
        "\n",
        "    # x é uma entrada de tamanho context_size (no artigo é chamada de n)\n",
        "    # O primeiro passo é manter os embeddings de x\n",
        "    x = self.C(w)\n",
        "    if x.dim() == 3: # Usando batchs\n",
        "      batch_size, _, _ = x.shape\n",
        "      x = x.view(batch_size, -1)\n",
        "    elif x.dim() == 2: # Calculando sem usar batch, usando um tensor direto\n",
        "      x = x.view(-1)\n",
        "    # O segundo passo é fazer (d + Hx). Isso é uma transformação linear\n",
        "    # A entrada é x (tamanho n*m) e a saída vai ser h (definida)\n",
        "    o = self.d_plus_H(x)\n",
        "    # O artigo calcula com tangente hiperbólica, mas o professor pediu com ReLU\n",
        "    o = self.relu(o)\n",
        "    # Passando pela segunda camada\n",
        "    return self.b_plus_U(o)\n",
        "    # return self.U(o) + self.b_plus_W(x) # Modelo do artigo\n",
        "\n",
        "# Model instantiation\n",
        "model = LanguageModel(vocab_size, context_size, m, h)"
      ],
      "metadata": {
        "id": "dovvTW4XOvXI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Testes com as dimensões\n",
        "# Gera um embeddings\n",
        "C = nn.Embedding(vocab_size, m)\n",
        "# Considera que a entrada é um vetor de índice (tem que ser do tamanho de context_size) e calcula os embeddings\n",
        "x = C(torch.tensor(np.random.randint(0, 10, size=context_size)))\n",
        "print(x.shape)\n",
        "# Achata o vetor\n",
        "x = x.view(-1)\n",
        "print(x.shape)\n",
        "# Cria a primeira camada\n",
        "d_plus_H = nn.Linear(in_features=context_size*m, out_features=h, bias=True)\n",
        "o = d_plus_H(x)\n",
        "print(o.shape)\n",
        "# Passa por ReLu\n",
        "o = nn.ReLU()(o)\n",
        "print(o.shape)\n",
        "# Última camada\n",
        "b_plus_U = nn.Linear(in_features=h, out_features=vocab_size, bias=True)\n",
        "o = b_plus_U(o)\n",
        "print(o.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCLjYOiXQNrW",
        "outputId": "d780be6b-ec04-4f49-e53e-ff13d634137e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 64])\n",
            "torch.Size([576])\n",
            "torch.Size([200])\n",
            "torch.Size([200])\n",
            "torch.Size([3001])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "yhu-jQ_eVa3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "  print('GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "else:\n",
        "  print('using CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3SNZIrtVcFn",
        "outputId": "1f8567dc-b100-4009-8ba6-56466f97d86a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calcula_loss_e_perplexidade(model, loader):\n",
        "  criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "  with torch.no_grad(): # Garante que nenhum gradiente seja calculado\n",
        "    model.eval()  # Coloca o modelo no modo de avaliação (não treinamento)\n",
        "    loss = 0.0\n",
        "    acc = 0\n",
        "    for inputs, targets in tqdm(loader, desc='Calculando loss e perplexidade'):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      # Acumula a perda\n",
        "      loss += criterion(outputs, targets)\n",
        "      acc += len(targets)\n",
        "\n",
        "    loss = loss/acc\n",
        "    ppl = math.exp(loss)\n",
        "\n",
        "    return loss, ppl"
      ],
      "metadata": {
        "id": "X0rfAqUuaw3H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálcula a loss e a perplexidade antes do treinamento"
      ],
      "metadata": {
        "id": "ClSr-oYKtP4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_loss_ppl(msg, loss, ppl):\n",
        "  print(f'{msg}. Loss: {loss:.2f}. Perplexidade: {ppl:.2f}\\n')"
      ],
      "metadata": {
        "id": "HrlQb7-9t8Xm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model instantiation\n",
        "model = LanguageModel(vocab_size, context_size, m, h)\n",
        "model.to(device)\n",
        "\n",
        "# Primeiro testa em um dataloader pequeno:\n",
        "dataset_pequeno = ParagrafosDataset(paragrafos[0:15], vocab, context_size)\n",
        "loader_pequeno = DataLoader(dataset_pequeno, batch_size=2, shuffle=False)\n",
        "\n",
        "loss, ppl = calcula_loss_e_perplexidade(model, loader_pequeno)\n",
        "print_loss_ppl('\\nAntes de iniciar o treinamento', loss, ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3ILXfvGvnpA",
        "outputId": "436f0a2d-68be-4c71-df41-c5c47e25d786"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 58/58 [00:01<00:00, 42.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Antes de iniciar o treinamento. Loss: 8.05. Perplexidade: 3127.60\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "print_loss_ppl('\\nAntes de iniciar o treinamento', loss, ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6iJjuQXtUxT",
        "outputId": "d2f90eb2-ffce-42c5-df51-af2109bde1c0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 333.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Antes de iniciar o treinamento. Loss: 8.05. Perplexidade: 3142.88\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "def treina_modelo(model, optimizer, train_loader, val_loader, num_epochs=num_epochs):\n",
        "  print(f'------------------ ANTES DE INICIAR O TREINAMENTO ------------------')\n",
        "  loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "  print_loss_ppl(f'[TRAIN]', loss, ppl)\n",
        "\n",
        "  loss, ppl = calcula_loss_e_perplexidade(model, val_loader)\n",
        "  print_loss_ppl(f'[EVAL]', loss, ppl)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()  # Start time of the epoch\n",
        "    print(f'------------------ [ÉPOCA {epoch+1}/{num_epochs}] ------------------')\n",
        "    estimativa_loss_epoca_i = 0\n",
        "    acc_dados = 0\n",
        "    for inputs, targets in tqdm(train_loader, desc='Treinando modelo'):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      # Calcula loss no batch\n",
        "      loss = criterion(outputs, targets)\n",
        "      # Backward and optimize\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Acumula a loss pra época atual\n",
        "      # Obs.: isso é só uma estimativa para a loss na época i.\n",
        "      # Como os pesos são atualizados após rodar cada batch, ao final da época\n",
        "      # é esperado que a loss no conjunto de treinamento na verdade seja menor\n",
        "      # do que o calculado dessa forma (o ajuste em cada batch tende a ir\n",
        "      # convergindo e, consequentemente, diminuindo a loss)\n",
        "      estimativa_loss_epoca_i += loss.item() * len(train_loader)\n",
        "      acc_dados += len(train_loader)\n",
        "\n",
        "    estimativa_loss_epoca_i = estimativa_loss_epoca_i / acc_dados\n",
        "    end_time = time.time()  # End time of the epoch\n",
        "    epoch_duration = end_time - start_time  # Duration of epoch\n",
        "\n",
        "    print(f'Elapsed time: {epoch_duration:.2f} sec')\n",
        "\n",
        "    loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "    print_loss_ppl(f'[TRAIN]', loss, ppl)\n",
        "    print_loss_ppl(f'[TRAIN ESTIMATIVA]', estimativa_loss_epoca_i, math.exp(estimativa_loss_epoca_i))\n",
        "\n",
        "    loss, ppl = calcula_loss_e_perplexidade(model, val_loader)\n",
        "    print_loss_ppl(f'[EVAL]', loss, ppl)\n",
        "\n",
        "    checkpoint_path = f\"modelo_epoca_{epoch+1}.pth\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, checkpoint_path)"
      ],
      "metadata": {
        "id": "s1WxymABVjIx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def escrever_frase(modelo, vocab, most_frequent_words, entrada, context_size, n_proximas_palavras, descartar_ukn=True):\n",
        "  if (n_proximas_palavras == 0):\n",
        "    return entrada\n",
        "  else:\n",
        "    # Faz o encode da frase de entrada e considera apenas as últimas 'context_size'\n",
        "    inputs = encode_sentence(entrada, vocab)\n",
        "    # Pega só as context_size últimas\n",
        "    inputs = inputs[len(inputs)-context_size:len(inputs)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output = model(torch.tensor(inputs).to(device))\n",
        "      softmax = nn.functional.softmax(output, dim=0)\n",
        "      if descartar_ukn:\n",
        "        valores, indices = softmax.topk(2, dim=0)\n",
        "        melhor_not_ukn = indices[0].item() if indices[0].item() != 0 else indices[1].item()\n",
        "        predicao = most_frequent_words[melhor_not_ukn]\n",
        "      else:\n",
        "        argmax = softmax.argmax(dim=0)\n",
        "        predicao = most_frequent_words[argmax]\n",
        "\n",
        "    # Substitui símbolos que foram trocados manualmente\n",
        "    predicao = predicao.replace('SUBSTITUIRPORTRESPONTOS', '...')\n",
        "\n",
        "  return escrever_frase(modelo, vocab, most_frequent_words, f'{entrada} {predicao}', context_size, n_proximas_palavras-1)"
      ],
      "metadata": {
        "id": "oFm7XMKfOhzf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinicializa o modelo\n",
        "model = LanguageModel(vocab_size, context_size, m, h)\n",
        "model.to(device)\n",
        "\n",
        "# Escreve uma frase com o modelo sem estar treinado\n",
        "frase = \"O espectaculo que se ofereceu aos seus olhos causou\"\n",
        "print(escrever_frase(model, vocab, most_frequent_words, frase, context_size, 10))\n",
        "\n",
        "# Treina o modelo\n",
        "#optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "treina_modelo(model, optimizer, train_loader, val_loader, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkDNWpS5OiZk",
        "outputId": "91726ea9-c7c4-4c07-f489-f10b614575e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O espectaculo que se ofereceu aos seus olhos causou succedeu plumas podesse dito filha labios travessa lutar cheia tremendo\n",
            "------------------ ANTES DE INICIAR O TREINAMENTO ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 561.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 7.99. Perplexidade: 2958.61\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 511.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.99. Perplexidade: 2951.05\n",
            "\n",
            "------------------ [ÉPOCA 1/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 318.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.88 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 887.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.90. Perplexidade: 134.20\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 5.48. Perplexidade: 240.65\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 921.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.09. Perplexidade: 162.32\n",
            "\n",
            "------------------ [ÉPOCA 2/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 466.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 903.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.49. Perplexidade: 88.96\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.86. Perplexidade: 129.35\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 962.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.91. Perplexidade: 136.30\n",
            "\n",
            "------------------ [ÉPOCA 3/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 464.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 875.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.18. Perplexidade: 65.14\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.55. Perplexidade: 94.50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 905.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.87. Perplexidade: 129.86\n",
            "\n",
            "------------------ [ÉPOCA 4/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 459.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 904.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.86. Perplexidade: 47.67\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.29. Perplexidade: 72.62\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 923.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.89. Perplexidade: 133.26\n",
            "\n",
            "------------------ [ÉPOCA 5/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 463.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 875.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.61. Perplexidade: 36.99\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.04. Perplexidade: 57.00\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 560.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.99. Perplexidade: 147.50\n",
            "\n",
            "------------------ [ÉPOCA 6/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 348.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.72 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 887.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.31. Perplexidade: 27.52\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.81. Perplexidade: 45.03\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 948.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.08. Perplexidade: 160.18\n",
            "\n",
            "------------------ [ÉPOCA 7/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 465.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 865.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.07. Perplexidade: 21.63\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.58. Perplexidade: 35.88\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 921.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.24. Perplexidade: 187.97\n",
            "\n",
            "------------------ [ÉPOCA 8/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 459.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 901.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.81. Perplexidade: 16.58\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.36. Perplexidade: 28.69\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 921.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.36. Perplexidade: 212.60\n",
            "\n",
            "------------------ [ÉPOCA 9/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 467.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 888.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.63. Perplexidade: 13.92\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.14. Perplexidade: 23.18\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 942.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.58. Perplexidade: 266.00\n",
            "\n",
            "------------------ [ÉPOCA 10/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 453.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 876.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.37. Perplexidade: 10.72\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.95. Perplexidade: 19.13\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 933.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.70. Perplexidade: 299.69\n",
            "\n",
            "------------------ [ÉPOCA 11/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 368.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.62 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 599.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.27. Perplexidade: 9.65\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.76. Perplexidade: 15.79\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 924.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.98. Perplexidade: 394.68\n",
            "\n",
            "------------------ [ÉPOCA 12/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 461.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 878.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.06. Perplexidade: 7.87\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.60. Perplexidade: 13.45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 914.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.12. Perplexidade: 455.89\n",
            "\n",
            "------------------ [ÉPOCA 13/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 461.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 879.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.92. Perplexidade: 6.81\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.45. Perplexidade: 11.59\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 963.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.27. Perplexidade: 526.31\n",
            "\n",
            "------------------ [ÉPOCA 14/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 445.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.34 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 869.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.80. Perplexidade: 6.05\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.29. Perplexidade: 9.86\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 872.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.50. Perplexidade: 663.01\n",
            "\n",
            "------------------ [ÉPOCA 15/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 451.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 870.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.72. Perplexidade: 5.61\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.18. Perplexidade: 8.89\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 924.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.68. Perplexidade: 799.93\n",
            "\n",
            "------------------ [ÉPOCA 16/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 385.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.55 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 533.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.65. Perplexidade: 5.21\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.08. Perplexidade: 8.00\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 743.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.92. Perplexidade: 1015.58\n",
            "\n",
            "------------------ [ÉPOCA 17/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 463.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 905.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.56. Perplexidade: 4.75\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.99. Perplexidade: 7.31\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 840.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.02. Perplexidade: 1122.17\n",
            "\n",
            "------------------ [ÉPOCA 18/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 464.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 898.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.51. Perplexidade: 4.51\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.92. Perplexidade: 6.84\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 904.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.21. Perplexidade: 1348.25\n",
            "\n",
            "------------------ [ÉPOCA 19/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 460.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 879.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.43. Perplexidade: 4.18\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.83. Perplexidade: 6.24\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 920.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.42. Perplexidade: 1672.62\n",
            "\n",
            "------------------ [ÉPOCA 20/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 470.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.27 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 866.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.37. Perplexidade: 3.95\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.76. Perplexidade: 5.83\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 932.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.58. Perplexidade: 1962.69\n",
            "\n",
            "------------------ [ÉPOCA 21/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 452.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 558.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.34. Perplexidade: 3.80\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.70. Perplexidade: 5.49\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 566.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.75. Perplexidade: 2319.75\n",
            "\n",
            "------------------ [ÉPOCA 22/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 405.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.47 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 897.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.32. Perplexidade: 3.73\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.65. Perplexidade: 5.20\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 952.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.01. Perplexidade: 3003.95\n",
            "\n",
            "------------------ [ÉPOCA 23/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 462.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 875.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.29. Perplexidade: 3.63\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.61. Perplexidade: 4.98\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 936.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.16. Perplexidade: 3509.46\n",
            "\n",
            "------------------ [ÉPOCA 24/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 459.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 905.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.22. Perplexidade: 3.39\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.55. Perplexidade: 4.70\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 960.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.35. Perplexidade: 4235.65\n",
            "\n",
            "------------------ [ÉPOCA 25/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 456.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 886.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.17. Perplexidade: 3.23\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.50. Perplexidade: 4.50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 895.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.48. Perplexidade: 4815.45\n",
            "\n",
            "------------------ [ÉPOCA 26/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 463.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 728.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.10. Perplexidade: 3.00\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.45. Perplexidade: 4.28\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 578.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.65. Perplexidade: 5706.46\n",
            "\n",
            "------------------ [ÉPOCA 27/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 363.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.64 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 886.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.06. Perplexidade: 2.90\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.40. Perplexidade: 4.07\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 849.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.84. Perplexidade: 6939.52\n",
            "\n",
            "------------------ [ÉPOCA 28/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 459.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 885.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.10. Perplexidade: 3.00\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.37. Perplexidade: 3.92\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 902.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.09. Perplexidade: 8850.45\n",
            "\n",
            "------------------ [ÉPOCA 29/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 462.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 868.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.05. Perplexidade: 2.84\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.34. Perplexidade: 3.81\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 941.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.28. Perplexidade: 10679.22\n",
            "\n",
            "------------------ [ÉPOCA 30/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 461.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 899.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.00. Perplexidade: 2.71\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.30. Perplexidade: 3.65\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 944.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.46. Perplexidade: 12841.60\n",
            "\n",
            "------------------ [ÉPOCA 31/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 433.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.38 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 506.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.92. Perplexidade: 2.52\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.26. Perplexidade: 3.52\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 569.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.66. Perplexidade: 15652.68\n",
            "\n",
            "------------------ [ÉPOCA 32/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:02<00:00, 289.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 2.06 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 883.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.97. Perplexidade: 2.64\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.25. Perplexidade: 3.48\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 941.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.85. Perplexidade: 19003.11\n",
            "\n",
            "------------------ [ÉPOCA 33/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 456.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 845.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.91. Perplexidade: 2.49\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.20. Perplexidade: 3.33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 885.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.04. Perplexidade: 23013.00\n",
            "\n",
            "------------------ [ÉPOCA 34/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 466.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 848.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.88. Perplexidade: 2.41\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.17. Perplexidade: 3.21\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 921.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.23. Perplexidade: 27737.68\n",
            "\n",
            "------------------ [ÉPOCA 35/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 463.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 866.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.91. Perplexidade: 2.48\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.13. Perplexidade: 3.10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 927.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.49. Perplexidade: 35922.72\n",
            "\n",
            "------------------ [ÉPOCA 36/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 452.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 893.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.82. Perplexidade: 2.28\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.09. Perplexidade: 2.99\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 781.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.69. Perplexidade: 44071.86\n",
            "\n",
            "------------------ [ÉPOCA 37/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 334.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.79 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 816.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.78. Perplexidade: 2.19\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.06. Perplexidade: 2.89\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 949.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.89. Perplexidade: 53398.51\n",
            "\n",
            "------------------ [ÉPOCA 38/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 450.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.33 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 871.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.81. Perplexidade: 2.25\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.03. Perplexidade: 2.81\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 910.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.13. Perplexidade: 67980.42\n",
            "\n",
            "------------------ [ÉPOCA 39/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 459.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 897.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.74. Perplexidade: 2.10\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.00. Perplexidade: 2.71\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 890.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.34. Perplexidade: 83790.01\n",
            "\n",
            "------------------ [ÉPOCA 40/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 454.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 888.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.73. Perplexidade: 2.09\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.98. Perplexidade: 2.67\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 913.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.57. Perplexidade: 105866.47\n",
            "\n",
            "------------------ [ÉPOCA 41/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 455.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 908.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.73. Perplexidade: 2.08\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.95. Perplexidade: 2.59\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 924.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.81. Perplexidade: 135184.00\n",
            "\n",
            "------------------ [ÉPOCA 42/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 379.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.57 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 562.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.69. Perplexidade: 1.99\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.91. Perplexidade: 2.50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 892.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.05. Perplexidade: 170681.25\n",
            "\n",
            "------------------ [ÉPOCA 43/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 475.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.26 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 898.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.67. Perplexidade: 1.95\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.89. Perplexidade: 2.43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 900.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.30. Perplexidade: 219451.24\n",
            "\n",
            "------------------ [ÉPOCA 44/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 466.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 888.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.65. Perplexidade: 1.92\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.86. Perplexidade: 2.37\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 882.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.54. Perplexidade: 280566.26\n",
            "\n",
            "------------------ [ÉPOCA 45/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 467.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 844.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.61. Perplexidade: 1.84\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.84. Perplexidade: 2.31\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 932.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.78. Perplexidade: 355858.19\n",
            "\n",
            "------------------ [ÉPOCA 46/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 457.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 887.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.61. Perplexidade: 1.85\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.80. Perplexidade: 2.23\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 901.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.00. Perplexidade: 442146.82\n",
            "\n",
            "------------------ [ÉPOCA 47/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 423.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.41 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 568.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.58. Perplexidade: 1.79\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.78. Perplexidade: 2.19\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 500.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.32. Perplexidade: 611099.59\n",
            "\n",
            "------------------ [ÉPOCA 48/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 427.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.40 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 893.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.55. Perplexidade: 1.74\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.76. Perplexidade: 2.14\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 942.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.51. Perplexidade: 737194.29\n",
            "\n",
            "------------------ [ÉPOCA 49/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 464.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 905.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.55. Perplexidade: 1.73\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.74. Perplexidade: 2.09\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 905.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.86. Perplexidade: 1042492.75\n",
            "\n",
            "------------------ [ÉPOCA 50/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 464.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 876.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 0.55. Perplexidade: 1.74\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 0.72. Perplexidade: 2.05\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 832.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 14.12. Perplexidade: 1358629.93\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recupera_modelo(model, epoca):\n",
        "  # Recupera o modelo salvo na época x\n",
        "  checkpoint_path = f\"modelo_epoca_{epoca}.pth\"\n",
        "  # Carregar o estado do checkpoint\n",
        "  checkpoint = torch.load(checkpoint_path)\n",
        "  # Aplicar o estado do modelo e otimizador carregados\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "YURYSHvB6RPj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O conjunto foi treinado com 50 épocas numa tentativa de fazer um overfit do modelo e verificar se ele consegue reproduzir mais ou menos o conjunto de treinamento:"
      ],
      "metadata": {
        "id": "7DdXMftlVkrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfit no modelo pra ver se ele consegue decorar as frases do conjunto de treinamento\n",
        "def completa_frase_do_conjunto(context_size, paragrafos, indices, idx_modelo_overfit):\n",
        "  for i in indices:\n",
        "    frase_esperada = paragrafos[i]\n",
        "    palavras_na_frase = frase_esperada.split(' ')\n",
        "    palavras_na_frase = palavras_na_frase[0:context_size]\n",
        "\n",
        "    if len(palavras_na_frase) == context_size:\n",
        "      frase = ' '.join(palavras_na_frase)\n",
        "      recupera_modelo(model, idx_modelo_overfit)\n",
        "      print('-----------------------------------------------------------------')\n",
        "      print(f'Testando para o índice {i}')\n",
        "      print(f'Modelo da epoca {idx_modelo_overfit}:')\n",
        "      print('Início:  ', frase)\n",
        "      print('Correta: ', frase_esperada)\n",
        "      print('Gerada:  ', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=False))\n",
        "\n",
        "completa_frase_do_conjunto(context_size, train_paragrafos, [0, 1, 2, 3, 55, 61, 76, 78, 388, 555, 1000], num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au0YUwHCSyBU",
        "outputId": "cc6b29b0-d5ff-4d4b-d19b-ee1c668bfdbb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Testando para o índice 0\n",
            "Modelo da epoca 50:\n",
            "Início:   Tambem elle viu a luz das janellas se reflectir\n",
            "Correta:  Tambem elle viu a luz das janellas se reflectir de fronte; e esperou que a noite se adiantasse, e toda a casa dormisse.\n",
            "Gerada:   Tambem elle viu a luz das janellas se reflectir de fronte ; e esperou que o tinha entrar , tão de mais para escura - se do mais do que o puro a morte da força acabava que a\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1\n",
            "Modelo da epoca 50:\n",
            "Início:   --É de Caparica, mas do bom. Deste cá não\n",
            "Correta:  --É de Caparica, mas do bom. Deste cá não vem!\n",
            "Gerada:   --É de Caparica, mas do bom. Deste cá não vem ! elle alvaro desgraça - os de . , cecilia - se ella ! para o alpendre . é - la selvagem , se se o fructo ; tu\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 2\n",
            "Modelo da epoca 50:\n",
            "Início:   --Dava-lhe uma ordem, e um castigo que elle mereceu,\n",
            "Correta:  --Dava-lhe uma ordem, e um castigo que elle mereceu, respondeo o fidalgo.\n",
            "Gerada:   --Dava-lhe uma ordem, e um castigo que elle mereceu, respondeo o fidalgo . quem a tua côr que é impossivel de aymorés , como o mais conhecer italiano ; sua irmã , d o moço , em na alma\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 3\n",
            "Modelo da epoca 50:\n",
            "Início:   Nunca se lembrára que esta affeição podesse passar daquillo\n",
            "Correta:  Nunca se lembrára que esta affeição podesse passar daquillo que era, e produzir outras emoções que não fossem o rubor e o sorriso; o exclusivismo do amor, a ambição de tornar seu e unicamente seu o objecto da paixão, acabava de ser-lhe revelado por sua prima.\n",
            "Gerada:   Nunca se lembrára que esta affeição podesse passar daquillo que era , e produzir outras emoções que não fossem o rubor . pery . tu e sem comprehender que nos olhos . a tarde sem ainda . a cabana\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 55\n",
            "Modelo da epoca 50:\n",
            "Início:   Nesta occasião ouvio-se um tropel de animaes perto da\n",
            "Correta:  Nesta occasião ouvio-se um tropel de animaes perto da casa; Isabel lançou os olhos sobre as margens do rio, e vio uma banda de cavalleiros que entravão a cerca.\n",
            "Gerada:   Nesta occasião ouvio-se um tropel de animaes perto da casa ; isabel lançou os olhos sobre as margens do rio , e vio uma banda de cavalleiros profunda . tudo - vos a bella setta para pai o menor\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 61\n",
            "Modelo da epoca 50:\n",
            "Início:   Cecilia, admirando o reflexo de nobre orgulho que brilhava\n",
            "Correta:  Cecilia, admirando o reflexo de nobre orgulho que brilhava na fronte do indio, sentio que não podia combater a sua resolução dictada por um sentimento elevado. Reconheceu que havia no fundo de suas palavras uma grande verdade, que o seu instincto adivinhava; ella tinha a prova na revolução que se operára no seu espirito, vendo Pery no meio do deserto, livre, grande, magestoso com um rei.\n",
            "Gerada:   Cecilia, admirando o reflexo de nobre orgulho que brilhava na fronte do indio , sentio que não podia combater a sua resolução que havia o seio o seu arco que todos . o moço mais logo sua casa será\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 76\n",
            "Modelo da epoca 50:\n",
            "Início:   --Este papel, D. Diogo, assegura a qualquer Portuguez de\n",
            "Correta:  --Este papel, D. Diogo, assegura a qualquer Portuguez de quem Pery possa ser prisioneiro, que D. Antonio de Mariz e seus herdeiros respondem por elle e pelo seu resgate, qualquer que fôr. É mais um legado que vos deixo a cumprir, meu filho.\n",
            "Gerada:   --Este papel, D. Diogo, assegura a qualquer Portuguez de quem pery possa ser prisioneiro , que d . antonio de mariz e dar - se ; o moço no céo as grandes folhas de alguns olhos ; que seus\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 78\n",
            "Modelo da epoca 50:\n",
            "Início:   Chegando á casa os dous separárão-se; Alvaro ganhou o\n",
            "Correta:  Chegando á casa os dous separárão-se; Alvaro ganhou o aposento que occupava; Pery encaminhou-se para o jardim de Cecilia.\n",
            "Gerada:   Chegando á casa os dous separárão-se; Alvaro ganhou o aposento que occupava ; pery encaminhou - se para o jardim de cecilia . para então a vida se escarlate o homem de uma grande cahia devia seria ha india\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 388\n",
            "Modelo da epoca 50:\n",
            "Início:   Emquanto atravessava o espaço que o separava do seu\n",
            "Correta:  Emquanto atravessava o espaço que o separava do seu aposento, formulou um projecto e tomou uma resolução. Metteu n'uma pequena bolsa de seda uma caixinha de joias; e, envolvendo-se no seu manto, costeou a casa e aproximou-se do pequeno jardim que entestava com o gabinete de Cecilia.\n",
            "Gerada:   Emquanto atravessava o espaço que o separava do seu aposento , formulou um projecto de rochedo uma , que lhe salvára o parte sobre a vida . todos me o escudeiro que estou sabes . mas o tapete é\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1000\n",
            "Modelo da epoca 50:\n",
            "Início:   Sobretudo para quem souber que apenas livre correra á\n",
            "Correta:  Sobretudo para quem souber que apenas livre correra á casa unicamente com o fim de contar o occorrido e pedir a D. Antonio de Mariz licença para esquartejar o indio; resolvido se o fidalgo lh'a negasse despedir-se do seu serviço, no qual se conservava havia trinta annos; mas tinha uma injuria a vingar, e bem que lhe custasse deixar a casa, Ayres Gomes não hesitava.\n",
            "Gerada:   Sobretudo para quem souber que apenas livre correra á casa unicamente com o fim de contar - vos do caracter , lhe os olhos e foi o fidalgo parte sobre o senhor em uma fazia viu . depois de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testa com uma fase qualquer, mas considerando todos os modelos gerados nas primeiras 10 épocas (só pra ver o que ele está gerando):"
      ],
      "metadata": {
        "id": "CI359dZqWgSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase = \"Se se tratasse de sua vida, Pery teria sangue\"\n",
        "print(frase)\n",
        "for epoca in range(1, min(num_epochs+1, 11)):\n",
        "  recupera_modelo(model, epoca)\n",
        "  #print(f'Modelo da epoca {epoca}:', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=False))\n",
        "  print(f'Modelo da epoca {epoca}:', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCcGxi9yAkxS",
        "outputId": "a6a501bf-80bb-472c-a011-851ea5aafab1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se se tratasse de sua vida, Pery teria sangue\n",
            "Modelo da epoca 1: Se se tratasse de sua vida, Pery teria sangue , e que o seu . não se o seu de um , e de um . de sua senhora . de sua senhora , e que o seu que\n",
            "Modelo da epoca 2: Se se tratasse de sua vida, Pery teria sangue , e a sua vida , e o fidalgo , e o seu espirito , e o seu , e que o tinha , e a sua vida , e\n",
            "Modelo da epoca 3: Se se tratasse de sua vida, Pery teria sangue , e de sua senhora , e - se um olhar de uma de que se passava ; a sua senhora de uma grande de uma grande de uma que\n",
            "Modelo da epoca 4: Se se tratasse de sua vida, Pery teria sangue , e de sua familia . de sua familia . da vida de d . antonio de mariz , disse - se , e de sua familia , e a\n",
            "Modelo da epoca 5: Se se tratasse de sua vida, Pery teria sangue , que se havião a sua vida , o indio ; o meu de sua prima , que elle - se de seu pai , e a - lhe a\n",
            "Modelo da epoca 6: Se se tratasse de sua vida, Pery teria sangue , tinha passado , e o que se tinha passado ; sabia que se passava . no meio delles . no meio que elle estava com os seus companheiros ,\n",
            "Modelo da epoca 7: Se se tratasse de sua vida, Pery teria sangue , tinha passado , e o que se passava a ella de um só á luz e que a hora passos a sua senhora , e que a primeira passos\n",
            "Modelo da epoca 8: Se se tratasse de sua vida, Pery teria sangue , não havia tudo a casa o moço , e de um contra os aventureiros para uma especie que o seu dever , e não era um dever de uma\n",
            "Modelo da epoca 9: Se se tratasse de sua vida, Pery teria sangue , tinha passado , e o que se passava a sua physionomia , os labios que o indio era um lindo uma cousa , e que a mão de perto\n",
            "Modelo da epoca 10: Se se tratasse de sua vida, Pery teria sangue de si cecilia , e o italiano o selvagem . não se o ultimo da vida ; mas o que se tinha passado . porque ; o que era o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continua alguns parágrafos da base de avaliação usando o modelo treinado na época que deu menor perplexidade no conjunto de treino."
      ],
      "metadata": {
        "id": "xg_4GKJpYpHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoca_do_modelo = 3\n",
        "completa_frase_do_conjunto(context_size, val_paragrafos, [1, 2, 4, 5, 8, 9, 18, 20, 21, 30], epoca_do_modelo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cam_jypxYqW1",
        "outputId": "ddba7b5c-fda0-437b-d777-8ba83e7fb7de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1\n",
            "Modelo da epoca 3:\n",
            "Início:   O que soffreu quando Cecilia no seu desespero pela\n",
            "Correta:  O que soffreu quando Cecilia no seu desespero pela morte de seu pai o accusava por tê-la salvado, e lhe dava ordem de leva-la ao lugar onde repousavão as cinzas do velho fidalgo, é impossivel de descrever.\n",
            "Gerada:   O que soffreu quando Cecilia no seu desespero pela <unk> . » de mariz , que se tinha de um gesto de sua senhora . e de um homem que de janeiro de uma que havia lhe tinha de\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 4\n",
            "Modelo da epoca 3:\n",
            "Início:   --Ah! nunca! Não me peças uma cousa impossivel, Cecilia!\n",
            "Correta:  --Ah! nunca! Não me peças uma cousa impossivel, Cecilia! Já sabes de mais; não me obrigues a morrer a teus pés de vergonha.\n",
            "Gerada:   --Ah! nunca! Não me peças uma cousa impossivel, Cecilia! ... a moça . antonio de mariz , e não podia o que havia de uma a sua alma . que lhe o seu espirito de cecilia , e que\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 8\n",
            "Modelo da epoca 3:\n",
            "Início:   O carmelita acompanhado pelo selvagem partio: vagou pela floresta\n",
            "Correta:  O carmelita acompanhado pelo selvagem partio: vagou pela floresta e pelo campo em todas as direcções; alguma cousa procurava. Elle avistou depois de duas horas a touca de cardos junto da qual se passou a ultima scena que narrámos; examinou-a por todos os lados e sorrio de satisfeito. Trepando á arvore escorregando pelo cipó, entrárão elle e o selvagem na área que já conhecemos; o sol tinha nascido ha pouco.\n",
            "Gerada:   O carmelita acompanhado pelo selvagem partio: vagou pela floresta . » vos . o escudeiro de cecilia , e de alvaro . quando de mariz que vos de uma arvore de uma expressão de uma que a sua senhora\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 9\n",
            "Modelo da epoca 3:\n",
            "Início:   Cecilia se dirigio a seu pai, levando Isabel, que\n",
            "Correta:  Cecilia se dirigio a seu pai, levando Isabel, que ao aproximar-se do joven cavalheiro sentio fugir-lhe a vida.\n",
            "Gerada:   Cecilia se dirigio a seu pai, levando Isabel, que <unk> de uma cousa de uma vez . mas - me que era um homem que ia um homem de uma cousa que se passava um de que se tinha\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 18\n",
            "Modelo da epoca 3:\n",
            "Início:   Ahi, o _Paquequer_ lança-se rapido sobre o seu leito,\n",
            "Correta:  Ahi, o _Paquequer_ lança-se rapido sobre o seu leito, e atravessa as florestas como o tapir, espumando, deixando o pello esparso pelas pontas de rochedo, e enchendo a solidão com o estampido de sua carreira. De repente, falta-lhe o espaço, foge-lhe a terra; o soberbo rio recúa um momento para concentrar as suas forças e precipita-se de um só arremesso, como o tigre sobre a presa.\n",
            "Gerada:   Ahi, o _Paquequer_ lança-se rapido sobre o seu leito, <unk> . » de mariz , que se tinha de um gesto de sua senhora . e de um homem que de janeiro de uma que havia lhe tinha de\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 20\n",
            "Modelo da epoca 3:\n",
            "Início:   A um canto, pendia da parede um crucifixo em\n",
            "Correta:  A um canto, pendia da parede um crucifixo em alabastro, aos pés do qual havia um escabello de madeira dourada.\n",
            "Gerada:   A um canto, pendia da parede um crucifixo em <unk> de uma a sua de uma grande de uma a sua de uma que lhe - lhe que a sua senhora . não vos de uma , que era\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 21\n",
            "Modelo da epoca 3:\n",
            "Início:   O homem voltou-se, e continuou o seu caminho sem\n",
            "Correta:  O homem voltou-se, e continuou o seu caminho sem dar resposta.\n",
            "Gerada:   O homem voltou-se, e continuou o seu caminho sem <unk> . » de uma grande de de uma . de uma que havia lhe tinha de uma vida ; e não - a uma hora que se tinha a\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 30\n",
            "Modelo da epoca 3:\n",
            "Início:   — Por mim? Daria a minha vida para salva-la:\n",
            "Correta:  — Por mim? Daria a minha vida para salva-la: e morreria feliz!\n",
            "Gerada:   — Por mim? Daria a minha vida para salva-la: d . antonio de mariz , disse - se de uma grande de uma vez . de uma cousa ; e não podia a mão de um momento de uma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcula o total de parâmetros da rede"
      ],
      "metadata": {
        "id": "b6DPR58VY019"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de parâmetros teórico:\n",
        "total_embeddings = vocab_size * m\n",
        "total_camada_1 = context_size * m * h + h # elementos da matriz + bias\n",
        "total_camada_2 = h * vocab_size + vocab_size # elementos da matriz + bias\n",
        "\n",
        "print(f'Total embeddings: {total_embeddings}')\n",
        "print(f'Total camada 1: {total_camada_1}')\n",
        "print(f'Total camada 2: {total_camada_2}')\n",
        "print(total_embeddings + total_camada_1 + total_camada_2, '<- somando tudo')\n",
        "\n",
        "# Total de parâmetros extraído do modelo:\n",
        "print(sum(p.numel() for p in model.parameters()), '<- sum(p.numel() for p in model.parameters())')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks0ZJ0rNjm3P",
        "outputId": "a4acca58-12f4-4d00-e426-ad5f43f9fce1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total embeddings: 192064\n",
            "Total camada 1: 115400\n",
            "Total camada 2: 603201\n",
            "910665 <- somando tudo\n",
            "910665 <- sum(p.numel() for p in model.parameters())\n"
          ]
        }
      ]
    }
  ]
}