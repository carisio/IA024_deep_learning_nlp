{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício: Modelo de linguagem (Bengio 2003) - MLP + Embeddings"
      ],
      "metadata": {
        "id": "cJ4M0Jbi7MVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parâmetros"
      ],
      "metadata": {
        "id": "xRm4Ls8Z1sMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Livros (testando com dom casmurro, memórias póstumas e quincas borda, pra dar pelo menos 20.000 palavras)\n",
        "#urls = [\"https://www.gutenberg.org/cache/epub/55752/pg55752.txt\", \"https://www.gutenberg.org/cache/epub/54829/pg54829.txt\", \"https://www.gutenberg.org/cache/epub/55682/pg55682.txt\"]\n",
        "\n",
        "# Livros (O Guarani)\n",
        "urls = [\"https://www.gutenberg.org/ebooks/67724.txt.utf-8\", \"https://www.gutenberg.org/ebooks/67725.txt.utf-8\"]\n",
        "\n",
        "# Dados do vocabulário\n",
        "UNK = \"<unk>\"\n",
        "vocab_size_desejado_sem_UNK = 3000 # Não considera o UNK\n",
        "vocab_size = vocab_size_desejado_sem_UNK + 1\n",
        "\n",
        "# Dados de treinamento\n",
        "context_size = 9 # número de palavras de entrada. O target é a próxima palavra\n",
        "num_epochs = 50 # usado pra fazer overfit no modelo e ajudar na verificação do treinamento\n",
        "test_size = 0.2\n",
        "seed = 18\n",
        "batch_size=128\n",
        "m = 64 # tamanho dos embeddings\n",
        "h = 200 # tamanho da camada oculta\n",
        "lr = 0.03\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "-jgzz8Ds1wAE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamentos dos dados\n",
        "\n",
        "## Download e agrupamento em parágrafos"
      ],
      "metadata": {
        "id": "7q5P64Abv23C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYDt0_9svZye",
        "outputId": "c74a4858-a101-4366-b8c7-04673f52c55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- Livro 1 ---------------\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK O GUARANY: ROMANCE BRAZILEIRO, VOL. 1 (OF 2) ***\n",
            "J. DE ALENCAR\n",
            "ROMANCE BRAZILEIRO\n",
            "QUINTA EDIÇÃO\n",
            "TOMO PRIMEIRO\n",
            "RIO DE JANEIRO\n",
            "B.-L. GARNIER, LIVREIRO-EDITOR\n",
            "71, RUA DO OUVIDOR, 71\n",
            "PARIS.--E. MELLIER, 17, RUA SÉGUIER.\n",
            "Ficão reservados os direitos de propriedade.\n",
            "Publicando este livro em 1857, se disse ser aquella primeira edição uma prova typographica, que algum dia talvez o autor se dispuzesse a rever.\n",
            "Esta nova edição devia dar satisfação do empenho, que a extrema benevolencia do publico ledor, tão minguado ainda, mudou em bem para divida de reconhecimento.\n",
            "Mais do que podia fiou de si o autor. Relendo a obra depois de annos, achou elle tão mau e incorrecto quando escrevera, que para bem corrigir, fora mister escrever de novo. Para tanto lhe carece o tempo e sobra o tedio de um labor ingrato.\n",
            "Cingio-se pois ás pequenas emendas que toleravão o plano da obra e o desalinho de um estylo não castigado.\n",
            "PRIMEIRA PARTE\n",
            "OS AVENTUREIROS\n",
            "De um dos cabeços da _Serra dos Órgãos_ deslisa um fio d'agua que se dirige para norte, e engrossado com os mananciaes, que recebe no seu curso de dez leguas, torna-se rio caudal.\n",
            "É o _Paquequer_: soltando de cascata em cascata, enroscando-se como uma serpente, vai depois se espreguiçar na varzea e embeber no Parahyba, que rola magestosamente em seu vasto leito.\n",
            "Dir-se-hia que vassallo e tributario desse rei das aguas, o pequeno rio, altivo e sobranceiro contra os rochedos, curva-se humildemente aos pés do suzerano. Perde então a belleza selvatica; suas ondas são calmas e serenas como as de um lago, e não se revoltão contra os barcos e as canôas que resvalão sobre ellas: escravo submisso, soffre o latego do senhor.\n",
            "Não é neste lugar que elle deve ser visto; sim tres ou quatro leguas acima de sua foz, onde é livre ainda, como o filho indomito desta patria da liberdade.\n",
            "-------------- Livro 2 ---------------\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK O GUARANY: ROMANCE BRAZILEIRO, VOL. 2 (OF 2) ***\n",
            "J. DE ALENCAR\n",
            "ROMANCE BRAZILEIRO\n",
            "QUINTA EDIÇÃO\n",
            "TOMO SEGUNDO\n",
            "RIO DE JANEIRO\n",
            "B.-L. GARNIER, LIVREIRO-EDITOR\n",
            "71, RUA DO OUVIDOR, 71\n",
            "PARIS.--E. MELLIER, 17, RUA SÉGUIER.\n",
            "Ficão reservados os direitos de propriedade.\n",
            "TERCEIRA PARTE\n",
            "Na segunda-feira, erão seis horas da manhã, quando D. Antonio de Mariz chamou seu filho.\n",
            "O velho fidalgo velara uma boa parte da noite; ou escrevendo ou reflectindo sobre os perigos que ameaçavão sua familia.\n",
            "Pery lhe havia contado todas as particularidades de seu encontro com os Aymorés; e o cavalheiro, que conhecia a ferocidade e espirito vingativo dessa raça selvagem, esperava a cada momento ser atacado.\n",
            "Por isso, de acordo com Alvaro, D. Diogo, com seu escudeiro Ayres Gomes, tinha tomado todas as medidas de precaução que as circumstancias e sua longa experiencia lhe aconselhavão.\n",
            "Quando seu filho entrou, o velho fidalgo acabava de sellar duas cartas que escrevêra na vespera.\n",
            "--Meu filho, disse elle com uma ligeira emoção, reflecti essa noite sobre o que nos pode acontecer, e assentei que deves partir hoje mesmo para S. Sebastião.\n",
            "--Não é possivel, senhor!... Afastais-me de vós justamente quando correis um perigo?\n",
            "--Sim! É justamente quando um grande perigo nos ameaça, que eu, chefe da casa, entendo ser do meu dever salvar o representante do meu nome e meu herdeiro legitimo, o protector de minha familia orphã.\n",
            "--Confio em Deos, meu pai, que vossos receios serão infundados; mas se elle nos quizesse submetter a tal provança, o unico lugar que compete a vosso filho e herdeiro de vosso nome é nesta casa ameaçada, ao vosso lado, para defender-vos e partilhar a vossa sorte, qualquer que ella seja.\n",
            "-------------- -------------------------\n",
            "Total de parágrafos: 4596\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def paragrafo_valido(paragrafo):\n",
        "  # Remove:\n",
        "  # - parágrafos curtos demais\n",
        "  # - parágrafos do índice (que tem a string ....)\n",
        "  return len(paragrafo) > 10 and '....' not in paragrafo\n",
        "\n",
        "def carregar_paragrafos_livro(url, n_linhas_para_print=20):\n",
        "  # Baixar o arquivo de texto\n",
        "  response = requests.get(url)\n",
        "  texto = response.text\n",
        "\n",
        "  # Encontrar o início e o fim do conteúdo principal do livro\n",
        "  inicio = texto.find(\"*** START OF THE PROJECT GUTENBERG EBOOK\")\n",
        "  fim = texto.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
        "\n",
        "  # Extrair o conteúdo principal do livro\n",
        "  conteudo = texto[inicio:fim].replace('\\r','')\n",
        "\n",
        "  # Dividir o conteúdo em parágrafos e processar o conteúdo\n",
        "  paragrafos = []\n",
        "\n",
        "  # Cada parágrafo é separado por dois \\n\n",
        "  # Dentro de cada parágrafo, junta as linhas (remove) e faz um trim\n",
        "  # Apenas considera os parágrafos que tem pelo menos 10 caracteres\n",
        "  for paragrafo in conteudo.split(\"\\n\\n\"):\n",
        "    paragrafo = paragrafo.replace('\\n', ' ').strip()\n",
        "    if paragrafo_valido(paragrafo):\n",
        "      paragrafos.append(paragrafo)\n",
        "\n",
        "  for p in paragrafos[0:n_linhas_para_print]:\n",
        "    print(p)\n",
        "\n",
        "  return paragrafos\n",
        "\n",
        "paragrafos = []\n",
        "for i, url in enumerate(urls, 1):\n",
        "  print(f'-------------- Livro {i} ---------------')\n",
        "  paragrafos.extend(carregar_paragrafos_livro(url))\n",
        "\n",
        "print('-------------- -------------------------')\n",
        "print(f'Total de parágrafos: {len(paragrafos)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragrafos[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FlJPdVMWp2R5",
        "outputId": "dcab3db9-edb6-4e9b-ecb2-ed48ca66c703"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'QUINTA EDIÇÃO'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizador\n",
        "\n",
        "Define um tokenizador simples. A ideia desse tokenizador é manter as palavras e os sinais de pontuação. Quero testar gerar tokens também para os sinais de pontuação.\n",
        "\n",
        "*Gerado com ChatGPT.*"
      ],
      "metadata": {
        "id": "Pa9xkSle06bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenizar(texto):\n",
        "  texto = texto.lower()\n",
        "\n",
        "  # Força os 3 pontos aparecerem juntos\n",
        "  texto = texto.replace('...', 'SUBSTITUIRPORTRESPONTOS')\n",
        "\n",
        "  # Define a expressão regular que captura palavras e sinais de pontuação\n",
        "  padrao = r'\\w+|[^\\w\\s]'\n",
        "\n",
        "  # Usa o método findall para encontrar todas as ocorrências que se encaixam no padrão\n",
        "  tokens = re.findall(padrao, texto)\n",
        "\n",
        "  return tokens\n",
        "\n",
        "print(tokenizar('Teste. Será que vai manter a pontuação?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyRd2ylAyO89",
        "outputId": "66f53399-330f-4bfe-feed-06796f5cc5fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['teste', '.', 'será', 'que', 'vai', 'manter', 'a', 'pontuação', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração do vocabulário\n",
        "\n",
        "Agora vamos gerar o vocabulário."
      ],
      "metadata": {
        "id": "py_qYd1b18mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from collections import Counter\n",
        "\n",
        "def gerar_vocabulario(paragrafos, vocab_size_sem_UNK):\n",
        "  counter = Counter()\n",
        "  for p in paragrafos:\n",
        "    # Update com os tokens de cada parágrafo\n",
        "    counter.update(tokenizar(p))\n",
        "\n",
        "  # Considera apenas as palavras mais frequentes. Adiciona, na posição 0, o token UNK\n",
        "  most_frequent_words = [UNK] + sorted(counter, key=counter.get, reverse=True)[:vocab_size_sem_UNK]\n",
        "  # vocab é um mapa de palavras para o índice correspondente. O mapa leva a palavra para um índice entre [0, vocab_size]\n",
        "  # (o tamanho é vocab_size + 1), com o índice 0 apontando para UNK\n",
        "  vocab = {word: i for i, word in enumerate(most_frequent_words)}\n",
        "\n",
        "  return len(most_frequent_words), vocab, most_frequent_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYMsMQV919LN",
        "outputId": "3f5cba7d-4dcf-4d1c-ac1a-0ea5f3deeafa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9 µs, sys: 1e+03 ns, total: 10 µs\n",
            "Wall time: 13.4 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, vocab, most_frequent_words = gerar_vocabulario(paragrafos, vocab_size_desejado_sem_UNK)\n",
        "\n",
        "print('Tamanho do vocabulário (considera UNK): ', vocab_size)\n",
        "\n",
        "print('Posição 0: ', most_frequent_words[0])\n",
        "print('Índice do UNK: ', vocab[UNK])\n",
        "print('------------')\n",
        "print('Posição 200: ', most_frequent_words[200])\n",
        "print(f'Índice de {most_frequent_words[200]}: ', vocab[most_frequent_words[200]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmwhcpZF4hqH",
        "outputId": "0b1c18c6-1edb-4932-ac6c-366fac603aed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do vocabulário (considera UNK):  3001\n",
            "Posição 0:  <unk>\n",
            "Índice do UNK:  0\n",
            "------------\n",
            "Posição 200:  tambem\n",
            "Índice de tambem:  200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder de frases"
      ],
      "metadata": {
        "id": "RoLvU4XC9IZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sentence, vocab):\n",
        "  # Obs.: tem que usar o mesmo tokenizador que foi gerado o vocabulário\n",
        "  return [vocab.get(word, 0) for word in tokenizar(sentence)]"
      ],
      "metadata": {
        "id": "0JCO2quC6Wtt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sentence(sentence, most_frequent_words):\n",
        "  words = [most_frequent_words[code] for code in sentence]\n",
        "  return ' '.join(words)"
      ],
      "metadata": {
        "id": "OBNbtpkF97sr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do encode/decode\n",
        "frase = \"E ele pegou a árvore e arrancou do chão.\"\n",
        "\n",
        "frase_encodada = encode_sentence(frase, vocab)\n",
        "frase_reconstruida = decode_sentence(frase_encodada, most_frequent_words)\n",
        "\n",
        "print('Original:')\n",
        "print(frase)\n",
        "print('Encodada:')\n",
        "print(frase_encodada)\n",
        "print('Reconstruída:')\n",
        "print(frase_reconstruida)\n",
        "print(\"--------------------------------------\")\n",
        "\n",
        "frase = \"E no seminario me disseram que não.\"\n",
        "\n",
        "frase_encodada = encode_sentence(frase, vocab)\n",
        "frase_reconstruida = decode_sentence(frase_encodada, most_frequent_words)\n",
        "\n",
        "print('Original:')\n",
        "print(frase)\n",
        "print('Encodada:')\n",
        "print(frase_encodada)\n",
        "print('Reconstruída:')\n",
        "print(frase_reconstruida)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-qN55c5-i8Z",
        "outputId": "6cf1e6da-7097-40ef-aad0-ea7540fc6c6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "E ele pegou a árvore e arrancou do chão.\n",
            "Encodada:\n",
            "[8, 0, 0, 4, 0, 8, 1640, 12, 378, 3]\n",
            "Reconstruída:\n",
            "e <unk> <unk> a <unk> e arrancou do chão .\n",
            "--------------------------------------\n",
            "Original:\n",
            "E no seminario me disseram que não.\n",
            "Encodada:\n",
            "[8, 25, 0, 45, 0, 5, 13, 3]\n",
            "Reconstruída:\n",
            "e no <unk> me <unk> que não .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "NYphluu6AOnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada parágrafo, é necessário gerar os dados de treinamento. Supondo que a frase é \"eu gosto de pizza.\" e vamos usar uma janela de contexto igual a 2, a ideia é que essa frase gere o seguinte conjunto de treinamento:\n",
        "\n",
        "input -> target\n",
        "\n",
        "[UNK, \"eu\"] -> \"gosto\" (ESSE CASO NÃO SERÁ CONSIDERADO POR ENQUANTO)\n",
        "\n",
        "[\"eu\", \"gosto\"] -> \"de\"\n",
        "\n",
        "[\"gosto\", \"de\"] -> \"pizza\"\n",
        "\n",
        "[\"de\", \"pizza\"] -> \".\""
      ],
      "metadata": {
        "id": "FYjJsO8BByxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gera_inputs_e_targets_para_array(array, n):\n",
        "  # Faz uma janela deslizante de tamanho n no array\n",
        "\n",
        "  janelas = []\n",
        "  targets = []\n",
        "\n",
        "  for i in range(len(array) - n):\n",
        "    janela = array[i:i+n]\n",
        "    janelas.append(janela)\n",
        "    targets.append(array[i+n])\n",
        "\n",
        "  return janelas, targets\n",
        "\n",
        "# Exemplo de uso\n",
        "exemplo = \"eu gosto de pizza .\".split()\n",
        "\n",
        "for n in range(1, 4):\n",
        "  print(f'Testando para janela de tamanho {n}')\n",
        "  inputs, targets = gera_inputs_e_targets_para_array(exemplo, n)\n",
        "\n",
        "  # Testa\n",
        "  for input_target in zip(inputs, targets):\n",
        "    print(f'{input_target[0]} -> {input_target[1]}')\n",
        "  print('------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUUUqSSaCeIO",
        "outputId": "023fe13b-76ab-44a0-a2d4-681cafcc9992"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando para janela de tamanho 1\n",
            "['eu'] -> gosto\n",
            "['gosto'] -> de\n",
            "['de'] -> pizza\n",
            "['pizza'] -> .\n",
            "------------------------------\n",
            "Testando para janela de tamanho 2\n",
            "['eu', 'gosto'] -> de\n",
            "['gosto', 'de'] -> pizza\n",
            "['de', 'pizza'] -> .\n",
            "------------------------------\n",
            "Testando para janela de tamanho 3\n",
            "['eu', 'gosto', 'de'] -> pizza\n",
            "['gosto', 'de', 'pizza'] -> .\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa com um parágrafo real e o tamanho do contexto configurado\n",
        "i = 60\n",
        "inputs, targets = gera_inputs_e_targets_para_array(tokenizar(paragrafos[i]), context_size)\n",
        "print(paragrafos[i])\n",
        "for input_target in zip(inputs, targets):\n",
        "  print(f'{input_target[0]} -> {input_target[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlO4K7-WFShp",
        "outputId": "29baf414-ab12-4564-b399-653c7ca8b83e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Aqui sou portuguez! Aqui pode respirar á vontade um coração leal, que nunca desmentio a fé do juramento. Nesta terra que me foi dada pelo meu rei, e conquistada pelo meu braço, nesta terra livre, tu reinarás, Portugal, como viverás n'alma de teus filhos. Eu o juro!\n",
            "['-', '-', 'aqui', 'sou', 'portuguez', '!', 'aqui', 'pode', 'respirar'] -> á\n",
            "['-', 'aqui', 'sou', 'portuguez', '!', 'aqui', 'pode', 'respirar', 'á'] -> vontade\n",
            "['aqui', 'sou', 'portuguez', '!', 'aqui', 'pode', 'respirar', 'á', 'vontade'] -> um\n",
            "['sou', 'portuguez', '!', 'aqui', 'pode', 'respirar', 'á', 'vontade', 'um'] -> coração\n",
            "['portuguez', '!', 'aqui', 'pode', 'respirar', 'á', 'vontade', 'um', 'coração'] -> leal\n",
            "['!', 'aqui', 'pode', 'respirar', 'á', 'vontade', 'um', 'coração', 'leal'] -> ,\n",
            "['aqui', 'pode', 'respirar', 'á', 'vontade', 'um', 'coração', 'leal', ','] -> que\n",
            "['pode', 'respirar', 'á', 'vontade', 'um', 'coração', 'leal', ',', 'que'] -> nunca\n",
            "['respirar', 'á', 'vontade', 'um', 'coração', 'leal', ',', 'que', 'nunca'] -> desmentio\n",
            "['á', 'vontade', 'um', 'coração', 'leal', ',', 'que', 'nunca', 'desmentio'] -> a\n",
            "['vontade', 'um', 'coração', 'leal', ',', 'que', 'nunca', 'desmentio', 'a'] -> fé\n",
            "['um', 'coração', 'leal', ',', 'que', 'nunca', 'desmentio', 'a', 'fé'] -> do\n",
            "['coração', 'leal', ',', 'que', 'nunca', 'desmentio', 'a', 'fé', 'do'] -> juramento\n",
            "['leal', ',', 'que', 'nunca', 'desmentio', 'a', 'fé', 'do', 'juramento'] -> .\n",
            "[',', 'que', 'nunca', 'desmentio', 'a', 'fé', 'do', 'juramento', '.'] -> nesta\n",
            "['que', 'nunca', 'desmentio', 'a', 'fé', 'do', 'juramento', '.', 'nesta'] -> terra\n",
            "['nunca', 'desmentio', 'a', 'fé', 'do', 'juramento', '.', 'nesta', 'terra'] -> que\n",
            "['desmentio', 'a', 'fé', 'do', 'juramento', '.', 'nesta', 'terra', 'que'] -> me\n",
            "['a', 'fé', 'do', 'juramento', '.', 'nesta', 'terra', 'que', 'me'] -> foi\n",
            "['fé', 'do', 'juramento', '.', 'nesta', 'terra', 'que', 'me', 'foi'] -> dada\n",
            "['do', 'juramento', '.', 'nesta', 'terra', 'que', 'me', 'foi', 'dada'] -> pelo\n",
            "['juramento', '.', 'nesta', 'terra', 'que', 'me', 'foi', 'dada', 'pelo'] -> meu\n",
            "['.', 'nesta', 'terra', 'que', 'me', 'foi', 'dada', 'pelo', 'meu'] -> rei\n",
            "['nesta', 'terra', 'que', 'me', 'foi', 'dada', 'pelo', 'meu', 'rei'] -> ,\n",
            "['terra', 'que', 'me', 'foi', 'dada', 'pelo', 'meu', 'rei', ','] -> e\n",
            "['que', 'me', 'foi', 'dada', 'pelo', 'meu', 'rei', ',', 'e'] -> conquistada\n",
            "['me', 'foi', 'dada', 'pelo', 'meu', 'rei', ',', 'e', 'conquistada'] -> pelo\n",
            "['foi', 'dada', 'pelo', 'meu', 'rei', ',', 'e', 'conquistada', 'pelo'] -> meu\n",
            "['dada', 'pelo', 'meu', 'rei', ',', 'e', 'conquistada', 'pelo', 'meu'] -> braço\n",
            "['pelo', 'meu', 'rei', ',', 'e', 'conquistada', 'pelo', 'meu', 'braço'] -> ,\n",
            "['meu', 'rei', ',', 'e', 'conquistada', 'pelo', 'meu', 'braço', ','] -> nesta\n",
            "['rei', ',', 'e', 'conquistada', 'pelo', 'meu', 'braço', ',', 'nesta'] -> terra\n",
            "[',', 'e', 'conquistada', 'pelo', 'meu', 'braço', ',', 'nesta', 'terra'] -> livre\n",
            "['e', 'conquistada', 'pelo', 'meu', 'braço', ',', 'nesta', 'terra', 'livre'] -> ,\n",
            "['conquistada', 'pelo', 'meu', 'braço', ',', 'nesta', 'terra', 'livre', ','] -> tu\n",
            "['pelo', 'meu', 'braço', ',', 'nesta', 'terra', 'livre', ',', 'tu'] -> reinarás\n",
            "['meu', 'braço', ',', 'nesta', 'terra', 'livre', ',', 'tu', 'reinarás'] -> ,\n",
            "['braço', ',', 'nesta', 'terra', 'livre', ',', 'tu', 'reinarás', ','] -> portugal\n",
            "[',', 'nesta', 'terra', 'livre', ',', 'tu', 'reinarás', ',', 'portugal'] -> ,\n",
            "['nesta', 'terra', 'livre', ',', 'tu', 'reinarás', ',', 'portugal', ','] -> como\n",
            "['terra', 'livre', ',', 'tu', 'reinarás', ',', 'portugal', ',', 'como'] -> viverás\n",
            "['livre', ',', 'tu', 'reinarás', ',', 'portugal', ',', 'como', 'viverás'] -> n\n",
            "[',', 'tu', 'reinarás', ',', 'portugal', ',', 'como', 'viverás', 'n'] -> '\n",
            "['tu', 'reinarás', ',', 'portugal', ',', 'como', 'viverás', 'n', \"'\"] -> alma\n",
            "['reinarás', ',', 'portugal', ',', 'como', 'viverás', 'n', \"'\", 'alma'] -> de\n",
            "[',', 'portugal', ',', 'como', 'viverás', 'n', \"'\", 'alma', 'de'] -> teus\n",
            "['portugal', ',', 'como', 'viverás', 'n', \"'\", 'alma', 'de', 'teus'] -> filhos\n",
            "[',', 'como', 'viverás', 'n', \"'\", 'alma', 'de', 'teus', 'filhos'] -> .\n",
            "['como', 'viverás', 'n', \"'\", 'alma', 'de', 'teus', 'filhos', '.'] -> eu\n",
            "['viverás', 'n', \"'\", 'alma', 'de', 'teus', 'filhos', '.', 'eu'] -> o\n",
            "['n', \"'\", 'alma', 'de', 'teus', 'filhos', '.', 'eu', 'o'] -> juro\n",
            "[\"'\", 'alma', 'de', 'teus', 'filhos', '.', 'eu', 'o', 'juro'] -> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testa com um parágrafo real, mas agora ele encodado e o tamanho do contexto configurado\n",
        "inputs, targets = gera_inputs_e_targets_para_array(encode_sentence(paragrafos[i], vocab), context_size)\n",
        "print(paragrafos[i])\n",
        "for input_target in zip(inputs, targets):\n",
        "  print(f'{input_target[0]} -> {input_target[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM9NAFzaGIPf",
        "outputId": "822a9821-f1e5-4c5b-f294-179832cde0e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Aqui sou portuguez! Aqui pode respirar á vontade um coração leal, que nunca desmentio a fé do juramento. Nesta terra que me foi dada pelo meu rei, e conquistada pelo meu braço, nesta terra livre, tu reinarás, Portugal, como viverás n'alma de teus filhos. Eu o juro!\n",
            "[2, 2, 254, 779, 778, 21, 254, 646, 0] -> 32\n",
            "[2, 254, 779, 778, 21, 254, 646, 0, 32] -> 351\n",
            "[254, 779, 778, 21, 254, 646, 0, 32, 351] -> 11\n",
            "[779, 778, 21, 254, 646, 0, 32, 351, 11] -> 133\n",
            "[778, 21, 254, 646, 0, 32, 351, 11, 133] -> 1294\n",
            "[21, 254, 646, 0, 32, 351, 11, 133, 1294] -> 1\n",
            "[254, 646, 0, 32, 351, 11, 133, 1294, 1] -> 5\n",
            "[646, 0, 32, 351, 11, 133, 1294, 1, 5] -> 246\n",
            "[0, 32, 351, 11, 133, 1294, 1, 5, 246] -> 0\n",
            "[32, 351, 11, 133, 1294, 1, 5, 246, 0] -> 4\n",
            "[351, 11, 133, 1294, 1, 5, 246, 0, 4] -> 931\n",
            "[11, 133, 1294, 1, 5, 246, 0, 4, 931] -> 12\n",
            "[133, 1294, 1, 5, 246, 0, 4, 931, 12] -> 732\n",
            "[1294, 1, 5, 246, 0, 4, 931, 12, 732] -> 3\n",
            "[1, 5, 246, 0, 4, 931, 12, 732, 3] -> 508\n",
            "[5, 246, 0, 4, 931, 12, 732, 3, 508] -> 131\n",
            "[246, 0, 4, 931, 12, 732, 3, 508, 131] -> 5\n",
            "[0, 4, 931, 12, 732, 3, 508, 131, 5] -> 45\n",
            "[4, 931, 12, 732, 3, 508, 131, 5, 45] -> 88\n",
            "[931, 12, 732, 3, 508, 131, 5, 45, 88] -> 0\n",
            "[12, 732, 3, 508, 131, 5, 45, 88, 0] -> 80\n",
            "[732, 3, 508, 131, 5, 45, 88, 0, 80] -> 97\n",
            "[3, 508, 131, 5, 45, 88, 0, 80, 97] -> 550\n",
            "[508, 131, 5, 45, 88, 0, 80, 97, 550] -> 1\n",
            "[131, 5, 45, 88, 0, 80, 97, 550, 1] -> 8\n",
            "[5, 45, 88, 0, 80, 97, 550, 1, 8] -> 0\n",
            "[45, 88, 0, 80, 97, 550, 1, 8, 0] -> 80\n",
            "[88, 0, 80, 97, 550, 1, 8, 0, 80] -> 97\n",
            "[0, 80, 97, 550, 1, 8, 0, 80, 97] -> 204\n",
            "[80, 97, 550, 1, 8, 0, 80, 97, 204] -> 1\n",
            "[97, 550, 1, 8, 0, 80, 97, 204, 1] -> 508\n",
            "[550, 1, 8, 0, 80, 97, 204, 1, 508] -> 131\n",
            "[1, 8, 0, 80, 97, 204, 1, 508, 131] -> 395\n",
            "[8, 0, 80, 97, 204, 1, 508, 131, 395] -> 1\n",
            "[0, 80, 97, 204, 1, 508, 131, 395, 1] -> 60\n",
            "[80, 97, 204, 1, 508, 131, 395, 1, 60] -> 0\n",
            "[97, 204, 1, 508, 131, 395, 1, 60, 0] -> 1\n",
            "[204, 1, 508, 131, 395, 1, 60, 0, 1] -> 1076\n",
            "[1, 508, 131, 395, 1, 60, 0, 1, 1076] -> 1\n",
            "[508, 131, 395, 1, 60, 0, 1, 1076, 1] -> 29\n",
            "[131, 395, 1, 60, 0, 1, 1076, 1, 29] -> 2492\n",
            "[395, 1, 60, 0, 1, 1076, 1, 29, 2492] -> 127\n",
            "[1, 60, 0, 1, 1076, 1, 29, 2492, 127] -> 59\n",
            "[60, 0, 1, 1076, 1, 29, 2492, 127, 59] -> 134\n",
            "[0, 1, 1076, 1, 29, 2492, 127, 59, 134] -> 7\n",
            "[1, 1076, 1, 29, 2492, 127, 59, 134, 7] -> 601\n",
            "[1076, 1, 29, 2492, 127, 59, 134, 7, 601] -> 1080\n",
            "[1, 29, 2492, 127, 59, 134, 7, 601, 1080] -> 3\n",
            "[29, 2492, 127, 59, 134, 7, 601, 1080, 3] -> 86\n",
            "[2492, 127, 59, 134, 7, 601, 1080, 3, 86] -> 6\n",
            "[127, 59, 134, 7, 601, 1080, 3, 86, 6] -> 873\n",
            "[59, 134, 7, 601, 1080, 3, 86, 6, 873] -> 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "class ParagrafosDataset(Dataset):\n",
        "  def __init__(self, paragrafos, vocab, context_size):\n",
        "    # Salva o vocabulário\n",
        "    self.vocab = vocab\n",
        "    # Cria os inputs e target\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for p in paragrafos:\n",
        "      # O primeiro passo é pegar cada frase do parágrafo e encodar\n",
        "      p_tokenizado = encode_sentence(p, self.vocab)\n",
        "      # Só faz sentido considerar frases que tem no mínimo (context_size + 1) tokens\n",
        "      if (len(p_tokenizado) <= context_size):\n",
        "        continue\n",
        "\n",
        "      # Agora vamos gerar os dados de treinamento para esse parágrafo\n",
        "      p_inputs, p_targets = gera_inputs_e_targets_para_array(p_tokenizado, context_size)\n",
        "\n",
        "      # Adiciona independentemente se tiver UKN ou não no input ou target\n",
        "      inputs.extend(p_inputs)\n",
        "      targets.extend(p_targets)\n",
        "\n",
        "      # Apenas adiciona se o input ou o target não tiver nenhum UNK (código 0)\n",
        "      #for p_um_input, p_um_target in zip(p_inputs, p_targets):\n",
        "      #  if (0 not in p_um_input and p_um_target != 0):\n",
        "      #    inputs.append(p_um_input)\n",
        "      #    targets.append(p_um_target)\n",
        "\n",
        "    # Mantém em cache\n",
        "    self.inputs = torch.tensor(inputs)\n",
        "    self.targets = torch.tensor(targets)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5gvB84ZAQyX",
        "outputId": "4de27d85-4934-4f8d-ce5b-827aa3144358"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.91 s, sys: 374 ms, total: 2.28 s\n",
            "Wall time: 6.13 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste_paragrafos = [\"Depois, vendo que esta expedição não se realisava, e que seu braço e sua coragem de nada valião ao rei de Portugal\"]\n",
        "teste_dataset = ParagrafosDataset(teste_paragrafos, vocab, context_size)\n",
        "\n",
        "print('Imprimindo o dataset')\n",
        "for dados in teste_dataset:\n",
        "  print(dados)\n",
        "\n",
        "print('-------------------------')\n",
        "print('Como deveria estar (testando se o dataset está considerando corretamente os parágrafos. Tem que descartar os que tem UNK (0)):')\n",
        "for p in teste_paragrafos:\n",
        "  # Faz o encode do parágrafo\n",
        "  p_encodado = encode_sentence(p, vocab)\n",
        "  inputs, targets = gera_inputs_e_targets_para_array(p_encodado, context_size)\n",
        "  for inputs_targets in zip(inputs, targets):\n",
        "    print(torch.tensor(inputs_targets[0]), torch.tensor(inputs_targets[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScJGPiMVH4xs",
        "outputId": "efe0d985-e3f8-4ae1-949b-29677aad92eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imprimindo o dataset\n",
            "(tensor([ 63,   1, 275,   5, 120, 995,  13,   9,   0]), tensor(1))\n",
            "(tensor([  1, 275,   5, 120, 995,  13,   9,   0,   1]), tensor(8))\n",
            "(tensor([275,   5, 120, 995,  13,   9,   0,   1,   8]), tensor(5))\n",
            "(tensor([  5, 120, 995,  13,   9,   0,   1,   8,   5]), tensor(20))\n",
            "(tensor([120, 995,  13,   9,   0,   1,   8,   5,  20]), tensor(204))\n",
            "(tensor([995,  13,   9,   0,   1,   8,   5,  20, 204]), tensor(8))\n",
            "(tensor([ 13,   9,   0,   1,   8,   5,  20, 204,   8]), tensor(18))\n",
            "(tensor([  9,   0,   1,   8,   5,  20, 204,   8,  18]), tensor(363))\n",
            "(tensor([  0,   1,   8,   5,  20, 204,   8,  18, 363]), tensor(7))\n",
            "(tensor([  1,   8,   5,  20, 204,   8,  18, 363,   7]), tensor(252))\n",
            "(tensor([  8,   5,  20, 204,   8,  18, 363,   7, 252]), tensor(0))\n",
            "(tensor([  5,  20, 204,   8,  18, 363,   7, 252,   0]), tensor(28))\n",
            "(tensor([ 20, 204,   8,  18, 363,   7, 252,   0,  28]), tensor(550))\n",
            "(tensor([204,   8,  18, 363,   7, 252,   0,  28, 550]), tensor(7))\n",
            "(tensor([  8,  18, 363,   7, 252,   0,  28, 550,   7]), tensor(1076))\n",
            "-------------------------\n",
            "Como deveria estar (testando se o dataset está considerando corretamente os parágrafos. Tem que descartar os que tem UNK (0)):\n",
            "tensor([ 63,   1, 275,   5, 120, 995,  13,   9,   0]) tensor(1)\n",
            "tensor([  1, 275,   5, 120, 995,  13,   9,   0,   1]) tensor(8)\n",
            "tensor([275,   5, 120, 995,  13,   9,   0,   1,   8]) tensor(5)\n",
            "tensor([  5, 120, 995,  13,   9,   0,   1,   8,   5]) tensor(20)\n",
            "tensor([120, 995,  13,   9,   0,   1,   8,   5,  20]) tensor(204)\n",
            "tensor([995,  13,   9,   0,   1,   8,   5,  20, 204]) tensor(8)\n",
            "tensor([ 13,   9,   0,   1,   8,   5,  20, 204,   8]) tensor(18)\n",
            "tensor([  9,   0,   1,   8,   5,  20, 204,   8,  18]) tensor(363)\n",
            "tensor([  0,   1,   8,   5,  20, 204,   8,  18, 363]) tensor(7)\n",
            "tensor([  1,   8,   5,  20, 204,   8,  18, 363,   7]) tensor(252)\n",
            "tensor([  8,   5,  20, 204,   8,  18, 363,   7, 252]) tensor(0)\n",
            "tensor([  5,  20, 204,   8,  18, 363,   7, 252,   0]) tensor(28)\n",
            "tensor([ 20, 204,   8,  18, 363,   7, 252,   0,  28]) tensor(550)\n",
            "tensor([204,   8,  18, 363,   7, 252,   0,  28, 550]) tensor(7)\n",
            "tensor([  8,  18, 363,   7, 252,   0,  28, 550,   7]) tensor(1076)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gera datasets de treinamento e de teste:\n",
        "\n",
        "- Vou fazer a consideração de que a proporção é no total de parágrafos, e não no total do conjunto de dados. Como cada parágrafo tem um total de frases/palavras diferentes, o conjunto final não ficará com a proporção exatamente conforme esperado inicialmente. Entretanto, pensando que em um texto as coisas são mais ou menos distribuídas, espera-se que, no final, a proporção seja mais ou menos conforme a desejada.\n",
        "\n",
        "- Depois de fazer isso, é necessário gerar novamente o vocabulário, mas considerando apenas o conjunto de treinamento."
      ],
      "metadata": {
        "id": "XdUXho43Jidi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_paragrafos, val_paragrafos = train_test_split(paragrafos, test_size=test_size, random_state=seed)"
      ],
      "metadata": {
        "id": "ru5uXQrcNWSg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera novamente o vocabulário, mas agora usando apenas os parágrafos de treinamento\n",
        "vocab_size, vocab, most_frequent_words = gerar_vocabulario(train_paragrafos, vocab_size_desejado_sem_UNK)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3RenZRsN5VQ",
        "outputId": "bd5d3694-7b0a-4927-8589-dad5018b92b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera os dataset de treino e validação\n",
        "train_data = ParagrafosDataset(train_paragrafos, vocab, context_size)\n",
        "val_data = ParagrafosDataset(val_paragrafos, vocab, context_size)"
      ],
      "metadata": {
        "id": "VCUUQ7szKRcB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'len(val_data): {len(val_data)}')\n",
        "print(f'len(train_data): {len(train_data)}')\n",
        "print(f'Proporção de teste: {len(val_data)/(len(train_data)+len(val_data))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiaXj6ejONol",
        "outputId": "42b47992-57ab-41cd-d861-63b00b00f9a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(val_data): 19009\n",
            "len(train_data): 76020\n",
            "Proporção de teste: 0.20003367393111576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "liF-kSH_On0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzFrxS_uOm2G",
        "outputId": "88abb704-e116-4279-e028-53dfe80bb36a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 274 µs, sys: 42 µs, total: 316 µs\n",
            "Wall time: 322 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo"
      ],
      "metadata": {
        "id": "jqxPAD1AOuhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LanguageModel(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, context_size, m, h):\n",
        "    super(LanguageModel, self).__init__()\n",
        "\n",
        "    self.C = nn.Embedding(vocab_size, m)\n",
        "    self.d_plus_H = nn.Linear(in_features=context_size*m, out_features=h, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.b_plus_U = nn.Linear(in_features=h, out_features=vocab_size, bias=True)\n",
        "    # Modelo do artigo:\n",
        "    #self.W = nn.Linear(in_features=context_size*m, out_features=vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, w):\n",
        "    # A fórmula é:\n",
        "    # y = b + Wx + U*tanh(d + Hx)\n",
        "    #\n",
        "    # No exercício, o professor pediu para usar ReLU no lugar de tanh. Além disso,\n",
        "    # comentou para usar duas camadas lineares. Então provavelmente estamos\n",
        "    # fazendo é:\n",
        "    # y = b + U*relu(d + Hx)\n",
        "    # Que é similar ao original, mas considerando W = 0\n",
        "\n",
        "    # x é uma entrada de tamanho context_size (no artigo é chamada de n)\n",
        "    # O primeiro passo é manter os embeddings de x\n",
        "    x = self.C(w)\n",
        "    if x.dim() == 3: # Usando batchs\n",
        "      batch_size, _, _ = x.shape\n",
        "      x = x.view(batch_size, -1)\n",
        "    elif x.dim() == 2: # Calculando sem usar batch, usando um tensor direto\n",
        "      x = x.view(-1)\n",
        "    # O segundo passo é fazer (d + Hx). Isso é uma transformação linear\n",
        "    # A entrada é x (tamanho n*m) e a saída vai ser h (definida)\n",
        "    o = self.d_plus_H(x)\n",
        "    # O artigo calcula com tangente hiperbólica, mas o professor pediu com ReLU\n",
        "    o = self.relu(o)\n",
        "    # Passando pela segunda camada\n",
        "    return self.b_plus_U(o)\n",
        "    # return self.b_plus_U(o) + self.W(x) # Modelo do artigo\n",
        "\n",
        "# Model instantiation\n",
        "model = LanguageModel(vocab_size, context_size, m, h)"
      ],
      "metadata": {
        "id": "dovvTW4XOvXI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Testes com as dimensões\n",
        "# Gera um embeddings\n",
        "C = nn.Embedding(vocab_size, m)\n",
        "# Considera que a entrada é um vetor de índice (tem que ser do tamanho de context_size) e calcula os embeddings\n",
        "x = C(torch.tensor(np.random.randint(0, 10, size=context_size)))\n",
        "print(x.shape)\n",
        "# Achata o vetor\n",
        "x = x.view(-1)\n",
        "print(x.shape)\n",
        "# Cria a primeira camada\n",
        "d_plus_H = nn.Linear(in_features=context_size*m, out_features=h, bias=True)\n",
        "o = d_plus_H(x)\n",
        "print(o.shape)\n",
        "# Passa por ReLu\n",
        "o = nn.ReLU()(o)\n",
        "print(o.shape)\n",
        "# Última camada\n",
        "b_plus_U = nn.Linear(in_features=h, out_features=vocab_size, bias=True)\n",
        "o = b_plus_U(o)\n",
        "print(o.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCLjYOiXQNrW",
        "outputId": "f95fbb75-e3e5-4cb5-d250-76169d2ba993"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 64])\n",
            "torch.Size([576])\n",
            "torch.Size([200])\n",
            "torch.Size([200])\n",
            "torch.Size([3001])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "yhu-jQ_eVa3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device.type == 'cuda':\n",
        "  print('GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "else:\n",
        "  print('using CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3SNZIrtVcFn",
        "outputId": "26edfd18-1c78-4e3a-fe00-609570d00813"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calcula_loss_e_perplexidade(model, loader):\n",
        "  criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "  with torch.no_grad(): # Garante que nenhum gradiente seja calculado\n",
        "    model.eval()  # Coloca o modelo no modo de avaliação (não treinamento)\n",
        "    loss = 0.0\n",
        "    acc = 0\n",
        "    for inputs, targets in tqdm(loader, desc='Calculando loss e perplexidade'):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      # Acumula a perda\n",
        "      loss += criterion(outputs, targets)\n",
        "      acc += len(targets)\n",
        "\n",
        "    loss = loss/acc\n",
        "    ppl = math.exp(loss)\n",
        "\n",
        "    return loss, ppl"
      ],
      "metadata": {
        "id": "X0rfAqUuaw3H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálcula a loss e a perplexidade antes do treinamento"
      ],
      "metadata": {
        "id": "ClSr-oYKtP4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_loss_ppl(msg, loss, ppl):\n",
        "  print(f'{msg}. Loss: {loss:.2f}. Perplexidade: {ppl:.2f}\\n')"
      ],
      "metadata": {
        "id": "HrlQb7-9t8Xm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model instantiation\n",
        "model = LanguageModel(vocab_size, context_size, m, h)\n",
        "model.to(device)\n",
        "\n",
        "# Primeiro testa em um dataloader pequeno:\n",
        "dataset_pequeno = ParagrafosDataset(paragrafos[0:15], vocab, context_size)\n",
        "loader_pequeno = DataLoader(dataset_pequeno, batch_size=2, shuffle=False)\n",
        "\n",
        "loss, ppl = calcula_loss_e_perplexidade(model, loader_pequeno)\n",
        "print_loss_ppl('\\nAntes de iniciar o treinamento', loss, ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3ILXfvGvnpA",
        "outputId": "b3535bd8-2eca-43a3-8573-8745beb104b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 58/58 [00:02<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Antes de iniciar o treinamento. Loss: 8.04. Perplexidade: 3091.18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "print_loss_ppl('\\nAntes de iniciar o treinamento', loss, ppl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6iJjuQXtUxT",
        "outputId": "5d148991-24b4-4cfd-88af-17263b738bb8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:02<00:00, 274.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Antes de iniciar o treinamento. Loss: 8.05. Perplexidade: 3146.24\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "def treina_modelo(model, optimizer, train_loader, val_loader, num_epochs=num_epochs):\n",
        "  print(f'------------------ ANTES DE INICIAR O TREINAMENTO ------------------')\n",
        "  loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "  print_loss_ppl(f'[TRAIN]', loss, ppl)\n",
        "\n",
        "  loss, ppl = calcula_loss_e_perplexidade(model, val_loader)\n",
        "  print_loss_ppl(f'[EVAL]', loss, ppl)\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()  # Start time of the epoch\n",
        "    print(f'------------------ [ÉPOCA {epoch+1}/{num_epochs}] ------------------')\n",
        "    estimativa_loss_epoca_i = 0\n",
        "    acc_dados = 0\n",
        "    for inputs, targets in tqdm(train_loader, desc='Treinando modelo'):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      # Calcula loss no batch\n",
        "      loss = criterion(outputs, targets)\n",
        "      # Backward and optimize\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Acumula a loss pra época atual\n",
        "      # Obs.: isso é só uma estimativa para a loss na época i.\n",
        "      # Como os pesos são atualizados após rodar cada batch, ao final da época\n",
        "      # é esperado que a loss no conjunto de treinamento na verdade seja menor\n",
        "      # do que o calculado dessa forma (o ajuste em cada batch tende a ir\n",
        "      # convergindo e, consequentemente, diminuindo a loss)\n",
        "      estimativa_loss_epoca_i += loss.item() * len(train_loader)\n",
        "      acc_dados += len(train_loader)\n",
        "\n",
        "    estimativa_loss_epoca_i = estimativa_loss_epoca_i / acc_dados\n",
        "    end_time = time.time()  # End time of the epoch\n",
        "    epoch_duration = end_time - start_time  # Duration of epoch\n",
        "\n",
        "    print(f'Elapsed time: {epoch_duration:.2f} sec')\n",
        "\n",
        "    loss, ppl = calcula_loss_e_perplexidade(model, train_loader)\n",
        "    print_loss_ppl(f'[TRAIN]', loss, ppl)\n",
        "    print_loss_ppl(f'[TRAIN ESTIMATIVA]', estimativa_loss_epoca_i, math.exp(estimativa_loss_epoca_i))\n",
        "\n",
        "    loss, ppl = calcula_loss_e_perplexidade(model, val_loader)\n",
        "    print_loss_ppl(f'[EVAL]', loss, ppl)\n",
        "\n",
        "    checkpoint_path = f\"modelo_epoca_{epoch+1}.pth\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, checkpoint_path)"
      ],
      "metadata": {
        "id": "s1WxymABVjIx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def escrever_frase(modelo, vocab, most_frequent_words, entrada, context_size, n_proximas_palavras, descartar_ukn=True):\n",
        "  if (n_proximas_palavras == 0):\n",
        "    return entrada\n",
        "  else:\n",
        "    # Faz o encode da frase de entrada e considera apenas as últimas 'context_size'\n",
        "    inputs = encode_sentence(entrada, vocab)\n",
        "    # Pega só as context_size últimas\n",
        "    inputs = inputs[len(inputs)-context_size:len(inputs)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output = model(torch.tensor(inputs).to(device))\n",
        "      softmax = nn.functional.softmax(output, dim=0)\n",
        "      if descartar_ukn:\n",
        "        valores, indices = softmax.topk(2, dim=0)\n",
        "        melhor_not_ukn = indices[0].item() if indices[0].item() != 0 else indices[1].item()\n",
        "        predicao = most_frequent_words[melhor_not_ukn]\n",
        "      else:\n",
        "        argmax = softmax.argmax(dim=0)\n",
        "        predicao = most_frequent_words[argmax]\n",
        "\n",
        "    # Substitui símbolos que foram trocados manualmente\n",
        "    predicao = predicao.replace('SUBSTITUIRPORTRESPONTOS', '...')\n",
        "\n",
        "  return escrever_frase(modelo, vocab, most_frequent_words, f'{entrada} {predicao}', context_size, n_proximas_palavras-1)"
      ],
      "metadata": {
        "id": "oFm7XMKfOhzf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinicializa o modelo\n",
        "# Como esse é o modelo que será treinado, seta a seed aqui\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "model = LanguageModel(vocab_size, context_size, m, h)\n",
        "model.to(device)\n",
        "\n",
        "# Escreve uma frase com o modelo sem estar treinado\n",
        "frase = \"O espectaculo que se ofereceu aos seus olhos causou\"\n",
        "print(escrever_frase(model, vocab, most_frequent_words, frase, context_size, 10))\n",
        "\n",
        "# Treina o modelo\n",
        "#optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "treina_modelo(model, optimizer, train_loader, val_loader, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkDNWpS5OiZk",
        "outputId": "b4ba4b25-66cb-41de-98d5-1db9a34f2f53"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O espectaculo que se ofereceu aos seus olhos causou mudado juntos narração mudado descanço vinte aproximando cada ganhou conheço\n",
            "------------------ ANTES DE INICIAR O TREINAMENTO ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 614.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 8.02. Perplexidade: 3037.82\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 580.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.01. Perplexidade: 3013.35\n",
            "\n",
            "------------------ [ÉPOCA 1/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 320.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.86 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 873.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.90. Perplexidade: 134.15\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 5.48. Perplexidade: 240.89\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 877.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.96. Perplexidade: 142.69\n",
            "\n",
            "------------------ [ÉPOCA 2/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 453.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 543.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.51. Perplexidade: 91.04\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.87. Perplexidade: 130.82\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 545.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.80. Perplexidade: 121.52\n",
            "\n",
            "------------------ [ÉPOCA 3/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 406.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.47 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 847.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 4.20. Perplexidade: 66.89\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.57. Perplexidade: 96.33\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 891.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.76. Perplexidade: 116.97\n",
            "\n",
            "------------------ [ÉPOCA 4/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 440.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.36 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 850.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.92. Perplexidade: 50.64\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.31. Perplexidade: 74.63\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 920.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.79. Perplexidade: 120.45\n",
            "\n",
            "------------------ [ÉPOCA 5/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 448.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.33 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 889.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.66. Perplexidade: 38.75\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 4.07. Perplexidade: 58.78\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 844.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.87. Perplexidade: 130.03\n",
            "\n",
            "------------------ [ÉPOCA 6/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 445.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.34 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 865.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.40. Perplexidade: 29.98\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.84. Perplexidade: 46.70\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 835.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 4.99. Perplexidade: 146.21\n",
            "\n",
            "------------------ [ÉPOCA 7/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 460.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 655.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 3.16. Perplexidade: 23.55\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.62. Perplexidade: 37.35\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 556.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.13. Perplexidade: 168.81\n",
            "\n",
            "------------------ [ÉPOCA 8/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 373.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.60 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 893.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.94. Perplexidade: 18.83\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.40. Perplexidade: 30.03\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 902.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.30. Perplexidade: 200.91\n",
            "\n",
            "------------------ [ÉPOCA 9/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 456.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 916.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.74. Perplexidade: 15.43\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 3.19. Perplexidade: 24.35\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 833.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.50. Perplexidade: 245.04\n",
            "\n",
            "------------------ [ÉPOCA 10/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 461.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 871.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.56. Perplexidade: 12.95\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.99. Perplexidade: 19.96\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 843.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.71. Perplexidade: 302.99\n",
            "\n",
            "------------------ [ÉPOCA 11/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 461.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 833.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.41. Perplexidade: 11.11\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.81. Perplexidade: 16.57\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 910.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 5.93. Perplexidade: 375.74\n",
            "\n",
            "------------------ [ÉPOCA 12/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 459.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 871.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.27. Perplexidade: 9.71\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.64. Perplexidade: 13.98\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 555.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.14. Perplexidade: 465.74\n",
            "\n",
            "------------------ [ÉPOCA 13/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 334.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.78 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 889.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.16. Perplexidade: 8.68\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.49. Perplexidade: 12.01\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 859.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.36. Perplexidade: 575.52\n",
            "\n",
            "------------------ [ÉPOCA 14/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 462.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 833.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.07. Perplexidade: 7.93\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.35. Perplexidade: 10.52\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 864.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.57. Perplexidade: 716.05\n",
            "\n",
            "------------------ [ÉPOCA 15/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 457.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 881.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.00. Perplexidade: 7.40\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.24. Perplexidade: 9.38\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 931.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 6.80. Perplexidade: 895.79\n",
            "\n",
            "------------------ [ÉPOCA 16/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 456.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 857.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.95. Perplexidade: 7.01\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.14. Perplexidade: 8.51\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 848.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.02. Perplexidade: 1116.98\n",
            "\n",
            "------------------ [ÉPOCA 17/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 459.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 872.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.91. Perplexidade: 6.73\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.06. Perplexidade: 7.84\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 892.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.24. Perplexidade: 1400.00\n",
            "\n",
            "------------------ [ÉPOCA 18/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 358.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.67 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 653.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.88. Perplexidade: 6.55\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 2.00. Perplexidade: 7.37\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 882.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.47. Perplexidade: 1748.33\n",
            "\n",
            "------------------ [ÉPOCA 19/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 450.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.33 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 872.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.92. Perplexidade: 6.82\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.96. Perplexidade: 7.10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 841.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.72. Perplexidade: 2259.22\n",
            "\n",
            "------------------ [ÉPOCA 20/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 457.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.30 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 876.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.78. Perplexidade: 5.94\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.92. Perplexidade: 6.84\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 828.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 7.81. Perplexidade: 2464.24\n",
            "\n",
            "------------------ [ÉPOCA 21/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 461.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 877.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.77. Perplexidade: 5.89\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.89. Perplexidade: 6.62\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 886.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.00. Perplexidade: 2980.21\n",
            "\n",
            "------------------ [ÉPOCA 22/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 456.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 875.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.73. Perplexidade: 5.62\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.86. Perplexidade: 6.45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 920.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.17. Perplexidade: 3529.93\n",
            "\n",
            "------------------ [ÉPOCA 23/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 398.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.50 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 543.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.79. Perplexidade: 6.00\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.83. Perplexidade: 6.26\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 739.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.42. Perplexidade: 4542.46\n",
            "\n",
            "------------------ [ÉPOCA 24/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 455.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 853.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.75. Perplexidade: 5.76\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.81. Perplexidade: 6.10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 912.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.61. Perplexidade: 5460.58\n",
            "\n",
            "------------------ [ÉPOCA 25/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 452.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 885.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.62. Perplexidade: 5.08\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.75. Perplexidade: 5.74\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 912.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 8.72. Perplexidade: 6139.98\n",
            "\n",
            "------------------ [ÉPOCA 26/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 438.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.36 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 874.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.75. Perplexidade: 5.75\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.76. Perplexidade: 5.80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 847.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.09. Perplexidade: 8899.00\n",
            "\n",
            "------------------ [ÉPOCA 27/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 455.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 890.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.87. Perplexidade: 6.51\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.71. Perplexidade: 5.52\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 863.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.46. Perplexidade: 12857.29\n",
            "\n",
            "------------------ [ÉPOCA 28/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 428.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.39 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 578.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.81. Perplexidade: 6.14\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.64. Perplexidade: 5.16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 566.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.59. Perplexidade: 14673.18\n",
            "\n",
            "------------------ [ÉPOCA 29/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 429.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.40 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 871.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.78. Perplexidade: 5.93\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.64. Perplexidade: 5.16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 817.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 9.70. Perplexidade: 16271.42\n",
            "\n",
            "------------------ [ÉPOCA 30/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 455.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 891.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 2.19. Perplexidade: 8.98\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.73. Perplexidade: 5.64\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 909.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.18. Perplexidade: 26395.21\n",
            "\n",
            "------------------ [ÉPOCA 31/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 451.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 841.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.79. Perplexidade: 6.00\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.75. Perplexidade: 5.75\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 892.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.03. Perplexidade: 22705.75\n",
            "\n",
            "------------------ [ÉPOCA 32/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 454.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 874.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.77. Perplexidade: 5.89\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.68. Perplexidade: 5.35\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 916.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.30. Perplexidade: 29621.37\n",
            "\n",
            "------------------ [ÉPOCA 33/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 454.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.31 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 602.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.68. Perplexidade: 5.35\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.61. Perplexidade: 5.02\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 527.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.48. Perplexidade: 35663.09\n",
            "\n",
            "------------------ [ÉPOCA 34/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:02<00:00, 284.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 2.10 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 658.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.53. Perplexidade: 4.60\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.50. Perplexidade: 4.50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 847.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.59. Perplexidade: 39638.04\n",
            "\n",
            "------------------ [ÉPOCA 35/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 450.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.33 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 859.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.67. Perplexidade: 5.33\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.46. Perplexidade: 4.29\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 859.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 10.95. Perplexidade: 56941.43\n",
            "\n",
            "------------------ [ÉPOCA 36/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 464.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.28 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 879.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.56. Perplexidade: 4.77\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.42. Perplexidade: 4.13\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 905.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.09. Perplexidade: 65461.23\n",
            "\n",
            "------------------ [ÉPOCA 37/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 462.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.29 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 853.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.60. Perplexidade: 4.97\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.41. Perplexidade: 4.10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 892.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.50. Perplexidade: 98240.65\n",
            "\n",
            "------------------ [ÉPOCA 38/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 446.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.34 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 581.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.54. Perplexidade: 4.65\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.46. Perplexidade: 4.30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 540.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.62. Perplexidade: 111439.78\n",
            "\n",
            "------------------ [ÉPOCA 39/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 389.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.53 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 858.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.47. Perplexidade: 4.37\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.46. Perplexidade: 4.31\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 881.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 11.70. Perplexidade: 120916.91\n",
            "\n",
            "------------------ [ÉPOCA 40/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 450.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.33 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 879.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.55. Perplexidade: 4.70\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.43. Perplexidade: 4.19\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 862.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.00. Perplexidade: 162613.61\n",
            "\n",
            "------------------ [ÉPOCA 41/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 445.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.34 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 878.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.58. Perplexidade: 4.85\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.39. Perplexidade: 4.00\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 870.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.28. Perplexidade: 214773.44\n",
            "\n",
            "------------------ [ÉPOCA 42/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 442.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.35 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 878.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.37. Perplexidade: 3.95\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.35. Perplexidade: 3.85\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 913.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.31. Perplexidade: 222224.27\n",
            "\n",
            "------------------ [ÉPOCA 43/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 451.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:01<00:00, 561.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.59. Perplexidade: 4.91\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.32. Perplexidade: 3.73\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 543.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 12.94. Perplexidade: 416161.81\n",
            "\n",
            "------------------ [ÉPOCA 44/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 387.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.54 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 906.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.66. Perplexidade: 5.25\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.30. Perplexidade: 3.68\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 910.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.31. Perplexidade: 605589.82\n",
            "\n",
            "------------------ [ÉPOCA 45/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 453.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 891.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.68. Perplexidade: 5.38\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.25. Perplexidade: 3.48\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 803.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.69. Perplexidade: 881364.99\n",
            "\n",
            "------------------ [ÉPOCA 46/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 452.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.32 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 867.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.50. Perplexidade: 4.50\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.17. Perplexidade: 3.22\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 863.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.80. Perplexidade: 984104.25\n",
            "\n",
            "------------------ [ÉPOCA 47/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 447.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.34 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 860.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.07. Perplexidade: 2.93\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.12. Perplexidade: 3.06\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 897.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.54. Perplexidade: 760302.36\n",
            "\n",
            "------------------ [ÉPOCA 48/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 442.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.35 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 664.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.07. Perplexidade: 2.92\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.06. Perplexidade: 2.88\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 577.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 13.80. Perplexidade: 983045.24\n",
            "\n",
            "------------------ [ÉPOCA 49/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 362.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.64 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 845.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.09. Perplexidade: 2.97\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.01. Perplexidade: 2.76\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 848.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 14.22. Perplexidade: 1500303.61\n",
            "\n",
            "------------------ [ÉPOCA 50/50] ------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelo: 100%|██████████| 594/594 [00:01<00:00, 445.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.34 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 594/594 [00:00<00:00, 850.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]. Loss: 1.10. Perplexidade: 2.99\n",
            "\n",
            "[TRAIN ESTIMATIVA]. Loss: 1.04. Perplexidade: 2.83\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculando loss e perplexidade: 100%|██████████| 149/149 [00:00<00:00, 856.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EVAL]. Loss: 14.55. Perplexidade: 2088911.32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recupera_modelo(model, epoca):\n",
        "  # Recupera o modelo salvo na época x\n",
        "  checkpoint_path = f\"modelo_epoca_{epoca}.pth\"\n",
        "  # Carregar o estado do checkpoint\n",
        "  checkpoint = torch.load(checkpoint_path)\n",
        "  # Aplicar o estado do modelo e otimizador carregados\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "YURYSHvB6RPj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O conjunto foi treinado com 50 épocas numa tentativa de fazer um overfit do modelo e verificar se ele consegue reproduzir mais ou menos o conjunto de treinamento:"
      ],
      "metadata": {
        "id": "7DdXMftlVkrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Overfit no modelo pra ver se ele consegue decorar as frases do conjunto de treinamento\n",
        "def completa_frase_do_conjunto(context_size, paragrafos, indices, idx_modelo_overfit):\n",
        "  for i in indices:\n",
        "    frase_esperada = paragrafos[i]\n",
        "    palavras_na_frase = frase_esperada.split(' ')\n",
        "    palavras_na_frase = palavras_na_frase[0:context_size]\n",
        "\n",
        "    if len(palavras_na_frase) == context_size:\n",
        "      frase = ' '.join(palavras_na_frase)\n",
        "      recupera_modelo(model, idx_modelo_overfit)\n",
        "      print('-----------------------------------------------------------------')\n",
        "      print(f'Testando para o índice {i}')\n",
        "      print(f'Modelo da epoca {idx_modelo_overfit}:')\n",
        "      print('Início:  ', frase)\n",
        "      print('Correta: ', frase_esperada)\n",
        "      print('Gerada:  ', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=False))\n",
        "\n",
        "completa_frase_do_conjunto(context_size, train_paragrafos, [0, 1, 2, 3, 55, 61, 76, 78, 388, 555, 1000], num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au0YUwHCSyBU",
        "outputId": "e22e7a4f-5a34-4d71-ad3f-17b43563398c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Testando para o índice 0\n",
            "Modelo da epoca 50:\n",
            "Início:   Tambem elle viu a luz das janellas se reflectir\n",
            "Correta:  Tambem elle viu a luz das janellas se reflectir de fronte; e esperou que a noite se adiantasse, e toda a casa dormisse.\n",
            "Gerada:   Tambem elle viu a luz das janellas se reflectir para se uma arvore e homem a corrida do lado de suas os selvagens como alvaro , um provisão , que de porta alguns de um homem que a voz\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1\n",
            "Modelo da epoca 50:\n",
            "Início:   --É de Caparica, mas do bom. Deste cá não\n",
            "Correta:  --É de Caparica, mas do bom. Deste cá não vem!\n",
            "Gerada:   --É de Caparica, mas do bom. Deste cá não vem ! uma idéa que lhe uma hora . aqui - te que lhe pedi dos labios . na primeira mão a alma . hoje e essa a elle para\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 2\n",
            "Modelo da epoca 50:\n",
            "Início:   --Dava-lhe uma ordem, e um castigo que elle mereceu,\n",
            "Correta:  --Dava-lhe uma ordem, e um castigo que elle mereceu, respondeo o fidalgo.\n",
            "Gerada:   --Dava-lhe uma ordem, e um castigo que elle mereceu, respondeo o fidalgo . erão livre de ter ; e quando a arvore se a relva os traços . são o cavalheiro bem historia , pery é ella tinha susto\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 3\n",
            "Modelo da epoca 50:\n",
            "Início:   Nunca se lembrára que esta affeição podesse passar daquillo\n",
            "Correta:  Nunca se lembrára que esta affeição podesse passar daquillo que era, e produzir outras emoções que não fossem o rubor e o sorriso; o exclusivismo do amor, a ambição de tornar seu e unicamente seu o objecto da paixão, acabava de ser-lhe revelado por sua prima.\n",
            "Gerada:   Nunca se lembrára que esta affeição podesse passar daquillo que era , e produzir os labios para nos - vos . á - se entre , exclamou eu defender , todas e mais vale é por uma força que\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 55\n",
            "Modelo da epoca 50:\n",
            "Início:   Nesta occasião ouvio-se um tropel de animaes perto da\n",
            "Correta:  Nesta occasião ouvio-se um tropel de animaes perto da casa; Isabel lançou os olhos sobre as margens do rio, e vio uma banda de cavalleiros que entravão a cerca.\n",
            "Gerada:   Nesta occasião ouvio-se um tropel de animaes perto da casa de isabel ; se tivesse toda das suas faces de força e nesse podesse do momento . havia - me aspecto leito respeito ; eu como dous para a\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 61\n",
            "Modelo da epoca 50:\n",
            "Início:   Cecilia, admirando o reflexo de nobre orgulho que brilhava\n",
            "Correta:  Cecilia, admirando o reflexo de nobre orgulho que brilhava na fronte do indio, sentio que não podia combater a sua resolução dictada por um sentimento elevado. Reconheceu que havia no fundo de suas palavras uma grande verdade, que o seu instincto adivinhava; ella tinha a prova na revolução que se operára no seu espirito, vendo Pery no meio do deserto, livre, grande, magestoso com um rei.\n",
            "Gerada:   Cecilia, admirando o reflexo de nobre orgulho que brilhava na fronte do indio , sentio que não havia entre a todos os seus os irmã , e ; para se passava e com o sorriso . a mão e\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 76\n",
            "Modelo da epoca 50:\n",
            "Início:   --Este papel, D. Diogo, assegura a qualquer Portuguez de\n",
            "Correta:  --Este papel, D. Diogo, assegura a qualquer Portuguez de quem Pery possa ser prisioneiro, que D. Antonio de Mariz e seus herdeiros respondem por elle e pelo seu resgate, qualquer que fôr. É mais um legado que vos deixo a cumprir, meu filho.\n",
            "Gerada:   --Este papel, D. Diogo, assegura a qualquer Portuguez de um moço onde se , havia dizer ao mesmo que estava . tu não a mais e a voz tremula ; não havia senão na sua alma , e inabalavel\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 78\n",
            "Modelo da epoca 50:\n",
            "Início:   Chegando á casa os dous separárão-se; Alvaro ganhou o\n",
            "Correta:  Chegando á casa os dous separárão-se; Alvaro ganhou o aposento que occupava; Pery encaminhou-se para o jardim de Cecilia.\n",
            "Gerada:   Chegando á casa os dous separárão-se; Alvaro ganhou o aposento que occupava na pery , a filha , sua senhora , não se ouvio á - se tinha , não viu mais junto ; desejo inimigos e da mais\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 388\n",
            "Modelo da epoca 50:\n",
            "Início:   Emquanto atravessava o espaço que o separava do seu\n",
            "Correta:  Emquanto atravessava o espaço que o separava do seu aposento, formulou um projecto e tomou uma resolução. Metteu n'uma pequena bolsa de seda uma caixinha de joias; e, envolvendo-se no seu manto, costeou a casa e aproximou-se do pequeno jardim que entestava com o gabinete de Cecilia.\n",
            "Gerada:   Emquanto atravessava o espaço que o separava do seu aposento , formulou um projecto e tomou a facto . um indio ao céo , e a mim todos os guerreiros companheiros , sem quem é agora que áquella no\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1000\n",
            "Modelo da epoca 50:\n",
            "Início:   Sobretudo para quem souber que apenas livre correra á\n",
            "Correta:  Sobretudo para quem souber que apenas livre correra á casa unicamente com o fim de contar o occorrido e pedir a D. Antonio de Mariz licença para esquartejar o indio; resolvido se o fidalgo lh'a negasse despedir-se do seu serviço, no qual se conservava havia trinta annos; mas tinha uma injuria a vingar, e bem que lhe custasse deixar a casa, Ayres Gomes não hesitava.\n",
            "Gerada:   Sobretudo para quem souber que apenas livre correra á terra das lançar ; mas não vai posição com deve - me , . d . antonio de mariz não tenho tambem - lo para dar - la em que\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testa com uma fase qualquer, mas considerando todos os modelos gerados nas primeiras 10 épocas (só pra ver o que ele está gerando):"
      ],
      "metadata": {
        "id": "CI359dZqWgSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase = \"Se se tratasse de sua vida, Pery teria sangue\"\n",
        "print(frase)\n",
        "for epoca in range(1, min(num_epochs+1, 11)):\n",
        "  recupera_modelo(model, epoca)\n",
        "  #print(f'Modelo da epoca {epoca}:', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=False))\n",
        "  print(f'Modelo da epoca {epoca}:', escrever_frase(model, vocab, most_frequent_words, frase, context_size, 30, descartar_ukn=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCcGxi9yAkxS",
        "outputId": "a36c09c9-5893-4aa3-bb80-81973fdc6297"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se se tratasse de sua vida, Pery teria sangue\n",
            "Modelo da epoca 1: Se se tratasse de sua vida, Pery teria sangue a sua , e a sua , e a sua que se de sua senhora e a sua de um , e a sua de um , e a sua\n",
            "Modelo da epoca 2: Se se tratasse de sua vida, Pery teria sangue a , e a sua vida . não se o seu plano ; e a sua vida . é - se para o que era uma . . antonio de\n",
            "Modelo da epoca 3: Se se tratasse de sua vida, Pery teria sangue a , e a cabeça de que se passava , e não era mais que o seu espirito . é a mão de um homem que os olhos de um\n",
            "Modelo da epoca 4: Se se tratasse de sua vida, Pery teria sangue a do que não lhe e a sua cabeça . tinha - se para ver a cabeça de pery . antonio , e por a sua senhora e os seus\n",
            "Modelo da epoca 5: Se se tratasse de sua vida, Pery teria sangue a sua clavina ; e a sua vida . é a sua vida . é a sua familia , a quem e a sua vida . é a sua vida\n",
            "Modelo da epoca 6: Se se tratasse de sua vida, Pery teria sangue a sua clavina ; e a sua morte . é a sua vida . é ? perguntou vos ; mas os aymorés de sua mãi ? perguntou , que no\n",
            "Modelo da epoca 7: Se se tratasse de sua vida, Pery teria sangue sua senhora ; a pery e a sua coragem , e o italiano do indio , e eu - se para ver não era possivel a sua voz . mas\n",
            "Modelo da epoca 8: Se se tratasse de sua vida, Pery teria sangue sua senhora ; a pery e a mão e o seu amor , e entretanto - se de sua prima . o mesmo . tinha olhos uma idéa de que\n",
            "Modelo da epoca 9: Se se tratasse de sua vida, Pery teria sangue sua senhora ; a pery não estava e estava de sua mulher : que havia passado , que - lhe com o braço e o seu coração , e a\n",
            "Modelo da epoca 10: Se se tratasse de sua vida, Pery teria sangue sua alma ; a pery não - se em sua prima . para ella me pela primeira vez , um dos labios . o senhor da casa ; o beijo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continua alguns parágrafos da base de avaliação usando o modelo treinado na época que deu menor perplexidade no conjunto de treino."
      ],
      "metadata": {
        "id": "xg_4GKJpYpHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoca_do_modelo = 3\n",
        "completa_frase_do_conjunto(context_size, val_paragrafos, [1, 2, 4, 5, 8, 9, 18, 20, 21, 30], epoca_do_modelo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cam_jypxYqW1",
        "outputId": "247fe615-437d-41bc-abb0-03fbb63412d8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Testando para o índice 1\n",
            "Modelo da epoca 3:\n",
            "Início:   O que soffreu quando Cecilia no seu desespero pela\n",
            "Correta:  O que soffreu quando Cecilia no seu desespero pela morte de seu pai o accusava por tê-la salvado, e lhe dava ordem de leva-la ao lugar onde repousavão as cinzas do velho fidalgo, é impossivel de descrever.\n",
            "Gerada:   O que soffreu quando Cecilia no seu desespero pela <unk> a sua mão e a sua vida . é a sua alma . a sua vida e a sua vida e a sua vida . é a sua vida\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 4\n",
            "Modelo da epoca 3:\n",
            "Início:   --Ah! nunca! Não me peças uma cousa impossivel, Cecilia!\n",
            "Correta:  --Ah! nunca! Não me peças uma cousa impossivel, Cecilia! Já sabes de mais; não me obrigues a morrer a teus pés de vergonha.\n",
            "Gerada:   --Ah! nunca! Não me peças uma cousa impossivel, Cecilia! ... do seu plano e e a sua vida . não se um só , e a sua mão , e o seu plano de seu pai e a sua\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 8\n",
            "Modelo da epoca 3:\n",
            "Início:   O carmelita acompanhado pelo selvagem partio: vagou pela floresta\n",
            "Correta:  O carmelita acompanhado pelo selvagem partio: vagou pela floresta e pelo campo em todas as direcções; alguma cousa procurava. Elle avistou depois de duas horas a touca de cardos junto da qual se passou a ultima scena que narrámos; examinou-a por todos os lados e sorrio de satisfeito. Trepando á arvore escorregando pelo cipó, entrárão elle e o selvagem na área que já conhecemos; o sol tinha nascido ha pouco.\n",
            "Gerada:   O carmelita acompanhado pelo selvagem partio: vagou pela floresta . e o seu plano , e a sua alma . é um olhar de um homem , e de um do que de sua vida . é a sua\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 9\n",
            "Modelo da epoca 3:\n",
            "Início:   Cecilia se dirigio a seu pai, levando Isabel, que\n",
            "Correta:  Cecilia se dirigio a seu pai, levando Isabel, que ao aproximar-se do joven cavalheiro sentio fugir-lhe a vida.\n",
            "Gerada:   Cecilia se dirigio a seu pai, levando Isabel, que lhe era o seu de pery , e a um do que se passava , e a sua mão e não se um só para que se passava . diogo\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 18\n",
            "Modelo da epoca 3:\n",
            "Início:   Ahi, o _Paquequer_ lança-se rapido sobre o seu leito,\n",
            "Correta:  Ahi, o _Paquequer_ lança-se rapido sobre o seu leito, e atravessa as florestas como o tapir, espumando, deixando o pello esparso pelas pontas de rochedo, e enchendo a solidão com o estampido de sua carreira. De repente, falta-lhe o espaço, foge-lhe a terra; o soberbo rio recúa um momento para concentrar as suas forças e precipita-se de um só arremesso, como o tigre sobre a presa.\n",
            "Gerada:   Ahi, o _Paquequer_ lança-se rapido sobre o seu leito, e não se um olhar de sua senhora e a sua vida . não se um olhar para uma flôr de uma vida . é a pery ; e não\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 20\n",
            "Modelo da epoca 3:\n",
            "Início:   A um canto, pendia da parede um crucifixo em\n",
            "Correta:  A um canto, pendia da parede um crucifixo em alabastro, aos pés do qual havia um escabello de madeira dourada.\n",
            "Gerada:   A um canto, pendia da parede um crucifixo em que se passava ; e a sua vida e a sua vida . é a sua vida . é a sua senhora , e o fidalgo de um momento para\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 21\n",
            "Modelo da epoca 3:\n",
            "Início:   O homem voltou-se, e continuou o seu caminho sem\n",
            "Correta:  O homem voltou-se, e continuou o seu caminho sem dar resposta.\n",
            "Gerada:   O homem voltou-se, e continuou o seu caminho sem <unk> e o que era uma força . antonio de mariz , não se a mais do seu amor . e o seu plano de seu pai e a sua\n",
            "-----------------------------------------------------------------\n",
            "Testando para o índice 30\n",
            "Modelo da epoca 3:\n",
            "Início:   — Por mim? Daria a minha vida para salva-la:\n",
            "Correta:  — Por mim? Daria a minha vida para salva-la: e morreria feliz!\n",
            "Gerada:   — Por mim? Daria a minha vida para salva-la: e a sua vida . a sua vida e a sua vida e a sua vida . é a sua vida . é a sua senhora , e o fidalgo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcula o total de parâmetros da rede"
      ],
      "metadata": {
        "id": "b6DPR58VY019"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de parâmetros teórico:\n",
        "total_embeddings = vocab_size * m\n",
        "total_camada_1 = context_size * m * h + h # elementos da matriz + bias\n",
        "total_camada_2 = h * vocab_size + vocab_size # elementos da matriz + bias\n",
        "\n",
        "print(f'Total embeddings: {total_embeddings}')\n",
        "print(f'Total camada 1: {total_camada_1}')\n",
        "print(f'Total camada 2: {total_camada_2}')\n",
        "print(total_embeddings + total_camada_1 + total_camada_2, '<- somando tudo')\n",
        "\n",
        "# Total de parâmetros extraído do modelo:\n",
        "print(sum(p.numel() for p in model.parameters()), '<- sum(p.numel() for p in model.parameters())')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks0ZJ0rNjm3P",
        "outputId": "4bf0259c-81d2-45b0-d968-c20492b52123"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total embeddings: 192064\n",
            "Total camada 1: 115400\n",
            "Total camada 2: 603201\n",
            "910665 <- somando tudo\n",
            "910665 <- sum(p.numel() for p in model.parameters())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checando a similaridade entre algumas palavras. De acordo com o artigo, com W = 0 (o simulado aqui), os embeddings supostamente não tem relação entre o papel que eles tem numa frase (por exemplo, um e uma poderia dar qualquer similaridade, gato e cachorro também etc)."
      ],
      "metadata": {
        "id": "TibJ44aluWLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(model, vocab, palavra):\n",
        "  posicao = torch.tensor(vocab[palavra])\n",
        "  return model.C(posicao.to(device))\n",
        "\n",
        "def similaridade(emb1, emb2):\n",
        "  return F.cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0))\n",
        "\n",
        "edificio_emb = get_embedding(model, vocab, 'edificio')\n",
        "casa_emb = get_embedding(model, vocab, 'casa')\n",
        "animal_emb = get_embedding(model, vocab, 'animal')\n",
        "a_emb = get_embedding(model, vocab, 'a')\n",
        "um_emb = get_embedding(model, vocab, 'um')\n",
        "uma_emb = get_embedding(model, vocab, 'uma')\n",
        "pery_emb = get_embedding(model, vocab, 'pery')\n",
        "cecilia_emb = get_embedding(model, vocab, 'cecilia')\n",
        "homem_emb = get_embedding(model, vocab, 'homem')\n",
        "mulher_emb = get_embedding(model, vocab, 'mulher')\n",
        "mostrou_emb = get_embedding(model, vocab, 'mostrou')\n",
        "correu_emb = get_embedding(model, vocab, 'correu')\n",
        "\n",
        "# Calcula similaridade de cosseno entre cada tensor:\n",
        "print('Edificio x casa', similaridade(edificio_emb, casa_emb))\n",
        "print('Edificio x animal', similaridade(edificio_emb, animal_emb))\n",
        "print('Casa x animal', similaridade(casa_emb, animal_emb))\n",
        "print('um x uma', similaridade(um_emb, uma_emb))\n",
        "print('um x a', similaridade(a_emb, um_emb))\n",
        "print('uma x a', similaridade(a_emb, uma_emb))\n",
        "print('cecilia x pery', similaridade(cecilia_emb, pery_emb))\n",
        "print('mulher x homem', similaridade(mulher_emb, homem_emb))\n",
        "print('mostrou x andou', similaridade(mostrou_emb, correu_emb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmUBxb5euWay",
        "outputId": "691787b9-c026-4d66-f4e4-5a4370704d60"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edificio x casa tensor([-0.2437], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "Edificio x animal tensor([0.2535], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "Casa x animal tensor([-0.0839], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "um x uma tensor([0.1371], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "um x a tensor([0.2365], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "uma x a tensor([0.2728], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "cecilia x pery tensor([-0.1842], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "mulher x homem tensor([-0.1227], device='cuda:0', grad_fn=<SumBackward1>)\n",
            "mostrou x andou tensor([0.0290], device='cuda:0', grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    }
  ]
}